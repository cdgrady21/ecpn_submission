#binary outcome, logit
glm.dist<-function()
{
td$newz<-shuffle(td$Z)
td$yobs<-td$newz*td$ybin1+(1-td$newz)*td$ybin0
glm<-glm(yobs~newz+C,data=td,family="binomial")
return(coef(glm)['newz'])
}
#test.lm<-do(1000)*lm.dist()
#test.glm<-do(1000)*glm.dist()
#function compare ols to logit
glm.bias<-function()
{
lm.test<-do(100)*lm.dist()
glm.test<-do(100)*glm.dist()
lm.z<-mean(lm.test$newz)
glm.z<-mean(glm.test$newz)
return(cbind(lm.z,glm.z))
}
# repeat the function to get an average of the average
test<-do(20)*glm.bias()
(ols.truth<-cbind(mean(test$lm.z),tau.bin))
(logit.truth<-cbind(mean(test$glm.z),log.odds))
test$glm.z
install.packages("optmatch")
library(optmatch)
names(wrk.df)
thecovs <- c("agenum", "citysize", "educ", "employment", "gender", "hausa", "identity",
"inc2", "int", "koranic", "muslimwelfare", "radio", #"region",
"religion2", "rural.urban", "samepot", "ses", #"state",
"suffvio", "tv", "tvfreq", "voted")
wrkdffmla <- reformulate(thecovs,response="a24")
# only 2015 ppl who watch
wrk.df<-wrk.df[wrk.df$year==2013 | wrk.df$year==2015 & wrk.df$a24 == 1,]
knitr::opts_chunk$set(echo = TRUE)
load("soc2013-2015.Rdata")
library(mosaic)
library(optmatch)
library(RItools)
library(arm)
names(wrk.df)
thecovs <- c("agenum", "citysize", "educ", "employment", "gender", "hausa", "identity",
"inc2", "int", "koranic", "muslimwelfare", "radio", #"region",
"religion2", "rural.urban", "samepot", "ses", #"state",
"suffvio", "tv", "tvfreq", "voted")
wrkdffmla <- reformulate(thecovs,response="a24")
# only 2015 ppl who watch
wrk.df<-wrk.df[wrk.df$year==2013 | wrk.df$year==2015 & wrk.df$a24 == 1,]
load(url("http://jakebowers.org/PS531Data/nes08gini.df.rda"))
library(car)
## Recode this variable into 1= ``college or more'' versus 0=``less than college'' category:
nes08gini.df$BAplus<-recode(nes08gini.df$V083218x,"6:7=1;0:5=0")
## Recode GiniH2009 to run from 0 at the minimum to 1 at the maximum so that we can talk about
## differences between the most and least equal places using our coefficients
nes08gini.df$GiniH200901<-with(nes08gini.df,(Gini.H2009-min(Gini.H2009))/(max(Gini.H2009)-min(Gini.H2009)))
##summary(nes08gini.df$Gini.H2009.01) ## check the recode
##cor(nes08gini.df[,c("GiniH200901","Gini.H2009")]) ## check the recode
nes08gini.df$voted<-as.numeric(nes08gini.df$V085036x==1)
## with(nes08gini.df,table(voted,V085036x,useNA='ifany'))
nes08gini.df$milserv<-ifelse(nes08gini.df$V083221 %in% c(1,2),1,0)
## with(nes08gini.df,table(milserv,V083221,useNA='ifany'))
## summary(nes08gini.df[,c("voted","milserv")])
nes08small<-na.omit(nes08gini.df[,c("GiniH200901","BAplus","protest","StateAb","voted","milserv")])
X<-model.matrix(~GiniH200901,data=nes08small)
y<-nes08small$protest
X
?model.matrix
dim(X)
dim(nes08small)
head(nes08small)
?solve
b<- solve( t(X) %*% X ) %*% t(X) %*% y
b
t(X) %*% X
X
t(X) %*% y
b
head(X)
head(y)
t(X)
head(t(X))
head(X)
t(X)[,1:5]
t(X) %*% X
0.39*2090
mean(nes08small$GiniH200901)
.326067*2090
sum(nes08small$GiniH200901)
0.39*0.39+0.39+0.39
mean(nes08small$GiniH200901)
meang=mean(nes08small$GiniH200901)
meang*meang
meang*meang*2090
ehat<-y - (X %*% b)
ehat
head(ehat)
(X %*% b)
X
b
b<- solve( t(X) %*% X ) %*% t(X) %*% y
b
t(X) %*% X
t(X) %*% y
names(ehat)<-row.names(nes08small)
sigma2<-sum(ehat^2)/(nrow(nes08small)-length(b))
vcovb<- sigma2 * solve( t(X) %*% X )
seb<-sqrt(diag(vcovb))
cbind(b,seb)
warnings()
?Startup
Sys.getenv("PATH")
system('g++ -v')
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR))
dir.create(dotR)
M <- file.path(dotR, "Makevars")
if (!file.exists(M))
file.create(M)
cat("\nCXXFLAGS=-O3 -mtune=native -march=native -Wno-unused-variable -Wno-unused-function",
file = M, sep = "\n", append = TRUE)
cat('Sys.setenv(BINPREF = "C:/Rtools/mingw_$(WIN)/bin/")',
file = file.path(Sys.getenv("HOME"), ".Rprofile"),
sep = "\n", append = TRUE)
cat("\nCXXFLAGS += -Wno-ignored-attributes -Wno-deprecated-declarations",
file = M, sep = "\n", append = TRUE)
cat(readLines(M), sep = "\n")
cat(M)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies=TRUE)
rm(list=ls())
fx <- inline::cxxfunction( signature(x = "integer", y = "numeric" ) , '
return ScalarReal( INTEGER(x)[0] * REAL(y)[0] ) ;
' )
fx( 2L, 5 ) # should be 10
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
data {
int<lower=0> J; // number of schools
real y[J]; // estimated treatment effects
real<lower=0> sigma[J]; // s.e. of effect estimates
}
parameters {
real mu;
real<lower=0> tau;
real eta[J];
}
transformed parameters {
real theta[J];
for (j in 1:J)
theta[j] = mu + tau * eta[j];
}
model {
target += normal_lpdf(eta | 0, 1);
target += normal_lpdf(y | theta, sigma);
}
data {
int<lower=0> J; // number of schools
real y[J]; // estimated treatment effects
real<lower=0> sigma[J]; // s.e. of effect estimates
}
rm(list=ls())
data {
int<lower=0> J; // number of schools
real y[J]; // estimated treatment effects
real<lower=0> sigma[J]; // s.e. of effect estimates
}
data {
int<lower=0> J; // number of schools
real y[J]; // estimated treatment effects
real<lower=0> sigma[J]; // s.e. of effect estimates
}
parameters {
real mu;
real<lower=0> tau;
real eta[J];
}
data {
int<lower=0> J; // number of schools
real y[J]; // estimated treatment effects
real<lower=0> sigma[J]; // s.e. of effect estimates
}
parameters {
real mu;
real<lower=0> tau;
real eta[J];
}
transformed parameters {
real theta[J];
for (j in 1:J)
theta[j] <- mu + tau * eta[j];
}
model {
eta ~ normal(0, 1);
y ~ normal(theta, sigma);
}
library(rstan)
rm(list=ls())
library("rstan")
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
data {
int<lower=0> J; // number of schools
real y[J]; // estimated treatment effects
real<lower=0> sigma[J]; // s.e. of effect estimates
}
parameters {
real mu;
real<lower=0> tau;
real eta[J];
}
transformed parameters {
real theta[J];
for (j in 1:J)
theta[j] = mu + tau * eta[j];
}
model {
target += normal_lpdf(eta | 0, 1);
target += normal_lpdf(y | theta, sigma);
}
?rstan
stanmodelcode <- "
data {
int<lower=0> N;
real y[N];
}
parameters {
real mu;
}
model {
target += normal_lpdf(mu | 0, 10);
target += normal_lpdf(y  | mu, 1);
}
"
y <- rnorm(20)
dat <- list(N = 20, y = y);
fit <- stan(model_code = stanmodelcode, model_name = "example",
data = dat, iter = 2012, chains = 3, sample_file = 'norm.csv',
verbose = TRUE)
1000*2*0.05
100*1000*6
(100*1000*6)/315
3528+1905+2500
8000/4
60/2000
.52*58
library(swirl)
swirl()
5+7
x<-5+7
x
x-3
exit()
exit
bye
swirl()
swirl()
swirl()
swirl()
install_course("Data_Analysis")
install.packages("swirl")
install.packages("swirl")
library(swirl)
rm(list=ls())
swirl()
library(swirl)
install_course("Data_Analysis")
install_course("Getting_and_Cleaning_Data")
install_course("Regression_Models")
swirl()
install_course("Exploratory_Data_Analysis")
swirl()
539*25
6.5+31+39.5+71
148*25
3700-2912.5
787.5/25
71-31.5
140*3
180*4
720+420
install.packages("rdrobust")
install.packages("rdlocrand")
install.packages("rddensity")
install.packages("rdpower")
install.packages("rdpower")
install.packages(c("AER", "arm", "assertthat", "backports", "bayesplot", "brglm", "car", "checkmate", "coda", "coin", "colorspace", "curl", "DBI", "deldir", "devtools", "digest", "dplyr", "evaluate", "expm", "fields", "formatR", "Formula", "gdata", "git2r", "glmnet", "Hmisc", "hms", "htmltools", "htmlwidgets", "httpuv", "httr", "igraph", "installr", "irlba", "jsonlite", "knitr", "lme4", "lmtest", "mapproj", "maps", "maptools", "markdown", "MASS", "miscTools", "mosaic", "nlme", "pbkrtest", "plm", "psych", "pwr", "quantreg", "R6", "randomizr", "Rcpp", "RcppEigen", "readr", "readstata13", "reshape", "rms", "rsconnect", "rstan", "rstanarm", "rstantools", "sandwich", "shiny", "shinyjs", "shinystan", "sp", "spam", "SparseM", "spdep", "spgwr", "StanHeaders", "statmod", "stringdist", "stringi", "survey", "survival", "TH.data", "threejs", "tibble", "tidyr", "viridis", "visNetwork", "withr", "XML", "xts", "zoo"))
4000 * 0.05
33*60
1000*2*0.05
1500*2*0.05
library(kable)
install.packages("kable")
library(kable)
?kable
??kable
news_df <- read.csv("http://jakebowers.org/PS531Data/news.df.csv")
names(news_df)
head(news.df)
head(news_df)
news_df %<>% rename(y = r) %>%
mutate(yc = ifelse(test = z == 0,
yes = y,
no = NA),
yt = ifelse(test = z == 1,
yes = y,
no = NA))
library(plyr)
library(dplyr)
news_df %<>% rename(y = r) %>%
mutate(yc = ifelse(test = z == 0,
yes = y,
no = NA),
yt = ifelse(test = z == 1,
yes = y,
no = NA))
kable(news_df[, c(1, 3:4, 8:9, 7)])
knitr::kable(news_df[, c(1, 3:4, 8:9, 7)])
head(news_df)
news_df %<>% mutate(true_tau = c(6, 4, 19, 3, 9, 9, 13, 15),
yc = ifelse(test = is.na(yc),
yes = yt - true_tau,
no = yc),
yt = ifelse(test = is.na(yt),
yes = yc + true_tau,
no = yt))
news_df %<>% mutate(true_tau = c(6, 4, 19, 3, 9, 9, 13, 15),
yc = ifelse(test = is.na(yc),
yes = yt - true_tau,
no = yc),
yt = ifelse(test = is.na(yt),
yes = yc + true_tau,
no = yt))
library(dplyr)
news_df %<>% mutate(true_tau = c(6, 4, 19, 3, 9, 9, 13, 15),
yc = ifelse(test = is.na(yc),
yes = yt - true_tau,
no = yc),
yt = ifelse(test = is.na(yt),
yes = yc + true_tau,
no = yt))
news_df <- read.csv("http://jakebowers.org/PS531Data/news.df.csv")
news_df %<>% rename(y = r) %>%
mutate(yc = ifelse(test = z == 0,
yes = y,
no = NA),
yt = ifelse(test = z == 1,
yes = y,
no = NA))
news_df %<>% mutate(true_tau = c(6, 4, 19, 3, 9, 9, 13, 15),
yc = ifelse(test = is.na(yc),
yes = yt - true_tau,
no = yc),
yt = ifelse(test = is.na(yt),
yes = yc + true_tau,
no = yt))
120/4
rm(list=ls())
## Install necessary libraries locally
.libPaths('libraries')
installedlibs <- installed.packages(lib='libraries')
reqlibs1 <- c('devtools','withr')
toinstall1 <- setdiff(reqlibs1,installedlibs[,'Package'])
if(length(toinstall1)>0){
install.packages(toinstall1,repos='http://cran.rstudio.com')
} else {
message('No preliminary libraries need to be installed')
}
## Here we installed development/cutting edge versions of packages
library('devtools')
library('withr')
with_libpaths("libraries", install_github('markmfredrickson/RItools',lib='libraries'), 'prefix')
## Here are the other ordinary packages
reqlibs <- c('xtable','rmarkdown','knitr','lmtest','sandwich','lubridate','car','NPC')
installedlibs <- installed.packages(lib='libraries')
toinstall <- setdiff(reqlibs,installedlibs[,'Package'])
if(length(toinstall)>0){
install.packages(toinstall,repos='http://cran.rstudio.com',lib=)
} else {
message('No libraries need to be installed')
}
install.packages(toinstall1, repos = "http://cran.rstudio.com")
done<-'done'
write.table(file='libraries.done',done)
rm(list=ls())
.libPaths("analysis/libraries")
library(knitr)
# Chunk 1
set.seed(20160208)
the.questions<-1:10
graded<-sample(the.questions,1)
# Chunk 2: initialize
##First, just setup the \R environment for today:
library(knitr)
opts_chunk$set(eval=T,echo=T,message=F,warning=F,cache=F,fig.pos="H",wrapper=T)
options(error=function(){options(prompt="> ",continue="+ ");NULL},scipen=10)
# Chunk 3: loadmosaic
rm(list=ls())# Clean up anything left over in workspace
##Load a small version of Dr. Page Fortna's data.
load(url("http://jakebowers.org/PS230/pk.df.rda"))
library(mosaic) ## the mosaic library might be useful
# Chunk 4
## Run these next lines
## First get rid of missing data to make life easier in class
pk.good<-na.omit(subset(pk.df,select=c('ridp','wardur','id')))
lm1<-lm(ridp~wardur,data=pk.good) ## fit the model
coef(lm1) ## print coeficients
##Code for plotting
xyplot(ridp+fitted(lm1)~wardur, data=pk.good,
pch=c(1,19),col=c('black','black'),
ylab='Number of Refugees/Displaced Persons',
xlab='Civil War Duration (Years)',
scales=list(x=list(tick.number=10)))
# Chunk 6
# Write you code here:
ref1<-582291+51603*1
# Chunk 7
##Function that takes duration of a civil war as input and produces refugees as output
makemv<-function(yrs){582291 + 51603 * yrs }
# Chunk 8
# Write you code here:
# ref10<-makemv(?) # uncomment and fill in ?
(ref10<-makemv(yrs=10))
(ref20<-makemv(yrs=20))
# Chunk 9
# Write you code here:
(ref20-ref10)
(ref20-ref10)
makemv<-function(yrs){582291 + 51603 * yrs }
(ref10<-makemv(yrs=10))
(ref20<-makemv(yrs=20))
with(pk.good,ridp[abs(wardur-10)<1])
with(pk.good,summary(ridp[abs(wardur-10)<1]))
print(ref10)
with(pk.good,ref10<ridp[abs(wardur-10)<1])
bosniaResiduals<-with(pk.df,ridp[id=="Bosnia"])-refBosnia
bosniaResiduals
bosniaWarDur<-with(pk.df,wardur[id=="Bosnia"])
refBosnia<-makemv(bosniaWarDur)
makemv
with(pk.good,ridp[abs(wardur-10)<1])
with(pk.good,summary(ridp[abs(wardur-10)<1]))
print(ref10)
with(pk.good,ref10<ridp[abs(wardur-10)<1])
with(pk.good,ridp[abs(wardur-10)<1])
with(pk.good,summary(ridp[abs(wardur-10)<1]))
print(ref10)
with(pk.good,ref10<ridp[abs(wardur-10)<1])
with(pk.good,summary(ridp[abs(wardur-10)<1]))
sum(rbinom(1,100))
?rbinom
rbinom(100,prob=0.5)
rbinom(1,1,prob=0.5)
rbinom(1,10,prob=0.5)
rbinom(1,10,prob=0.5)
rbinom(100,1,prob=0.5)
sum(rbinom(100,1,prob=0.5))
sum(rbinom(100,1,prob=0.5))
sum(rbinom(100,1,prob=0.5))
sum(rbinom(100,1,prob=0.5))
sum(rbinom(100,1,prob=0.5))
104+93+97
sum(rbinom(294,2,prob=0.5))
sum(rbinom(294,2,prob=0.5))
sum(rbinom(294,1,prob=0.5))
sum(rbinom(294,1,prob=0.5))
rbinom(294,1,prob=0.5)
rep(1:3,294)
rep(1:3,1)
test<-rep(1:3,1)
sample(test, 294, replace=TRUE)
table(sample(test, 294, replace=TRUE))
table(sample(test, 294, replace=TRUE))
table(sample(test, 294, replace=TRUE))
table(sample(test, 294, replace=TRUE))
table(sample(test, 294, replace=TRUE))
table(sample(test, 294, replace=TRUE))
table(sample(test, 294, replace=TRUE))
4000/28000
100/5
12*5
18000/12
1500/40
40*4
1500/160
536*.02
124.83+2.5
127.33*.02
format(Sys.Date(), "%B %d, %Y")
5*350
5*359
250*360
15000*360
0.3*0.5*0.6
0.3*0.5*0.7
2014-1989
2800*25
12*6*3
40*50
40*200
10000*100
16*4
2000/5
5*50*30
250*30
500*30
2000/250
24*7
168-20
250-201
200-151
150-100
setwd("C:/Users/cdgra/Google Drive/Africa/Nigeria - Farmer-Pastoralist/Design&Power/FinalEval")
