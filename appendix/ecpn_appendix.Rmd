---
title: "Promoting Peace Amid Intergroup Conflict: An Intergroup Contact Field Experiment in Nigeria_Supplementary Information"
output:
  pdf_document:
    toc: true
    toc_depth: 2
  html_document:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
rm(list=ls())

# data
load("../data_and_code/survey_dat/d_analysis/list_of_coefs_and_ps.Rda")
load("../data_and_code/survey_dat/d_analysis/list_of_rank_bin_raw.Rda")


# not included: Individual-levl balance between part/nonpart/control == unneeded because exploratory & no assumption of balance.
```

# Supplementary Information

## Appendix A: Randomization Inference and Bootstrapping

Randomization inference and bootstrapping are nonparametric methods to generate $p$-values (randomization inference) and confidence intervals (bootstrapping).  With *randomization inference*, we first shuffle the treatment variable to break the relationship between treatment and outcomes.  Next we regress outcomes on treatment using our regression equation and store the resulting coefficient.  Lastly, we repeat that process 10,000 times to create the distribution of coefficients we would observe if treatment had no effect on outcomes -- the null hypothesis.  Our $p$-value is the proportion of the null distribution that is greater than or equal to our observed coefficient.  

*Bootstrapping* for standard errors is similar, but instead of shuffling the treatment indicator we resample units with replacement.  By resampling with replacement, we create the empirical distribution of our data and the range of possible treatment effects we might observe if we repeated the experiment 10,000 times.  The treatment effect at the 2.5th percentile and at the 97.5th percentile are equivalent to a 95\% confidence interval <!--[@efron1994introduction]-->.

In each of these procedures, we mimic our randomization process by randomizing/resampling the intervention to communities in site-level clusters and within state blocks. This means that both communities in an implementation site (farmers and pastoralists) will always be treated/sampled together and that assignment to the intervention and resampling are conducted separately in Nassarawa and Benue, just as the intervention was assigned in this study.  This procedure ensures that our null distribution (for $p$-values) is created by randomizing the intervention between exchangeable units and that our empirical distribution (for confidence intervals) is created by resampling units as they were sampled.

**********

## Appendix B: Robustness checks for community analysis

These tables shows results with different ways of making indices (additive vs inverse-covariance weighted), different models for estimating effects (differencing vs controlling-for), and different ways of coding count variables (raw vs ranked).  Each table is an outcome.  Rows are results for different ways of creating the outcomes.  Columns show the coefficient from OLS regression, true p-value from randomization inference, and a binary "base" indicator showing which method was used in the paper.  

The base method is always inverse-covariance weighted indices; the estimation method is controlling-for unless the baseline difference between the treatment and control groups is 0.20 standard deviations or more; the base method of handling count variables is dense rank. Only contact outcomes use count variables, only survey outcomes have a baseline and an endline and are measured with indices.

```{r, echo=F}
# data
## newList is list of coefs and ps for outcomes
## var_tab is coefs and ps for the various ways to calculate self-reported contact outside of the intervention

#newList[[3]]
#var_tab

attitude_tab <- newList[[1]][,c(1:2,4)]
colnames(attitude_tab) <- c("coefficient", "p-value", "base")
rownames(attitude_tab) <- c("Controlling-for & ICW", "Controlling-for & Additive",
                            "Differencing & ICW", "Differencing & Additive")
attitude_tab <- round(attitude_tab,3)
attitude_tab <- knitr::kable(attitude_tab, format="latex")
```

\begin{table}[H]
\begin{center}
\label{tab:attitude_tab}
\caption{\textbf{Community Attitudes.} Effect of ECPN on attitudes using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r attitude_tab`
\end{center}
\end{table}

```{r}
security_tab <- newList[[2]][,c(1:2,4)]
colnames(security_tab) <- c("coefficient", "p-value", "base")
rownames(security_tab) <- c("Controlling-for & ICW", "Controlling-for & Additive",
                            "Differencing & ICW", "Differencing & Additive")
security_tab <- round(security_tab,3)
security_tab <- knitr::kable(security_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:security_tab}
\caption{\textbf{Community Perceptions of Security} Effect of ECPN on perceptions of security using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r security_tab`
\end{center}
\end{table}


```{r}
contact_tab <- newList[[3]][,c(1:2,4)]
var_tab$base <- c(0,0,0,1,0,0)
var_tab <- var_tab[c(2,3,5,6),]
contact_tab <- rbind(contact_tab, var_tab)
colnames(contact_tab) <- c("coefficient", "p-value", "base")
rownames(contact_tab) <- c("Controlling-for & ICW & Ranks", "Controlling-for & Additive & Ranks",
                            "Differencing & ICW & Ranks", "Differencing & Additive & Ranks",
                           "Controlling-for & ICW & Categories",
                           "Controlling-for & ICW & Raw",
                           "Differencing & ICW & Categories",
                           "Differencing & ICW & Raw")
contact_tab <- round(contact_tab,3)
contact_tab <- knitr::kable(contact_tab, format="latex")


```

\begin{table}[H]
\begin{center}
\label{tab:contact_tab}
\caption{\textbf{Community Contact} Effect of ECPN on contact using alternative methods of estimation, index construction, and measuring count variables. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r contact_tab`
\end{center}
\end{table}

```{r}
percExp_tab <- newList[[4]][c(1,3),c(1:2,4)]
colnames(percExp_tab) <- c("coefficient", "p-value", "base")
rownames(percExp_tab) <- c("Controlling-for",
                            "Differencing")
percExp_tab <- round(percExp_tab,3)
percExp_tab <- knitr::kable(percExp_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:percExp_tab}
\caption{\textbf{Community Contact Willingness (Percent Experiment)} Effect of ECPN on willingness to have contact with the outgroup using alternative methods of estimation. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r percExp_tab`
\end{center}
\end{table}
<!--
\begin{figure}[H]
\begin{center}
\includegraphics[width=.8\textwidth]{figs/randComm_plot.png}
\caption{\label{fig:percExp_plot_comm} \textbf{Community Percent Experiment} This figure shows the proportion of each experimental group who would join a group or live in a community with increasing percentages of outgroup members. The outcome is the mean response of those two questions so that a respondent saying yes to both was assigned a 1, a respondent saying yes to one was assigned a 0.5, and a respondent saying no to both was assigned a 0. Red shows the treatment communities; blue shows control communities.  Light colors are values at baseline; dark colors are values at endline.}
\end{center}
\end{figure}
-->

```{r}
endExp_tab <- newList[[5]][c(1,3),c(1:2,4)]
colnames(endExp_tab) <- c("coefficient", "p-value", "base")
rownames(endExp_tab) <- c("Controlling-for",
                            "Differencing")
endExp_tab <- round(endExp_tab,3)
endExp_tab <- knitr::kable(endExp_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:endExp_tab}
\caption{\textbf{Community Endorsement Experiment} Effect of ECPN on endorsement experiment using alternative methods of estimation. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r endExp_tab`
\end{center}
\end{table}

```{r}
pgg_tab <- rbind(newList[[6]][1,c(1:2)], newList[[7]][1,c(1:2)])
colnames(pgg_tab) <- c("coefficient", "p-value")
rownames(pgg_tab) <- c("Donation (binary)",
                            "Donation amount")
pgg_tab <- round(pgg_tab,3)
pgg_tab <- knitr::kable(pgg_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:pgg_tab}
\caption{\textbf{Community Public Goods Game} Effect of ECPN on probability of donating and on donation amount. The first column shows coefficients from OLS regression and the second column shows $p$-values from randomization inference.}
\smallskip
`r pgg_tab`
\end{center}
\end{table}
<!--
\begin{figure}[H]
\begin{center}
\includegraphics[width=.8\textwidth]{figs/pggComm_plot.png}
\caption{\label{fig:pgg_plot_comm} \textbf{Community Public Goods Game} This figure shows the proportion of each experimental group who donated and their average donation amount. Orange shows the treatment communities; blue shows control communities.}
\end{center}
\end{figure}
-->

**********

## Appendix C: Robustness checks for individual analysis

These tables shows results with different ways of making indices (additive vs inverse-covariance weighted), different models for estimating effects (differencing vs controlling-for), and different ways of coding count variables (raw vs ranked).  Each table is an outcome.  Rows are results for different ways of creating the outcomes.  Columns show the coefficient from OLS regression, true p-value from randomization inference, and a binary "base" indicator showing which method was used in the paper.  

The base method is always inverse-covariance weighted indices; the estimation method is controlling-for unless the baseline difference between the participants and control groups is 0.20 standard deviations or more; the base method of handling count variables is dense rank. Only contact outcomes use count variables, only survey outcomes have a baseline and an endline and are measured with indices.

```{r, echo=F}
load("../data_and_code/survey_dat/d_analysis/list_of_coefs_and_ps_ind.Rda")
load("../data_and_code/survey_dat/d_analysis/list_of_rank_bin_raw_ind.Rda")

# Data
# newList_ind is list of coefs and ps for individual-level observational analysis. rows are part or nonpart vs CO.
# var_tab_ind is coefs and ps for the various ways to calculate self-reported contact outside the intervention, in the individual-level data. rows are participants or nonparticipants vs CO.

#newList_ind[[3]]
#var_tab_ind

attitude_tab_ind <- newList_ind[[1]][,c(1:2,4)]
colnames(attitude_tab_ind) <- c("coefficient", "p-value", "base")
rownames(attitude_tab_ind) <- c("Non: Controlling-for & ICW", "Part: Controlling-for & ICW", 
                                "Non: Controlling-for & Additive", "Part: Controlling-for & Additive",
                                "Non: Differencing & ICW", "Part: Differencing & ICW", 
                                "Non: Differencing & Additive", "Part: Differencing & Additive")
attitude_tab_ind <- round(attitude_tab_ind,3)
attitude_tab_ind <- knitr::kable(attitude_tab_ind, format="latex")
```

\begin{table}[H]
\begin{center}
\label{tab:attitude_tab_ind}
\caption{\textbf{Individual Attitudes.} Effect of ECPN on attitudes using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r attitude_tab_ind`
\end{center}
\end{table}

```{r}
security_tab_ind <- newList_ind[[2]][,c(1:2,4)]
colnames(security_tab_ind) <- c("coefficient", "p-value", "base")
rownames(security_tab_ind) <- c("Non: Controlling-for & ICW", "Part: Controlling-for & ICW", 
                                "Non: Controlling-for & Additive", "Part: Controlling-for & Additive",
                                "Non: Differencing & ICW", "Part: Differencing & ICW", 
                                "Non: Differencing & Additive", "Part: Differencing & Additive")
security_tab_ind <- round(security_tab_ind,3)
security_tab_ind <- knitr::kable(security_tab_ind, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:security_tab_ind}
\caption{\textbf{Individual Perceptions of Security} Effect of ECPN on perceptions of security using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r security_tab_ind`
\end{center}
\end{table}


```{r}
contact_tab_ind <- newList_ind[[3]][,c(1:2,4)]
var_tab_ind$base <- c(0,0,0,0,0,0,1,1,0,0,0,0)
var_tab_ind <- var_tab_ind[c(3:6,9:nrow(var_tab_ind)),]
contact_tab_ind <- rbind(contact_tab_ind, var_tab_ind)
colnames(contact_tab_ind) <- c("coefficient", "p-value", "base")
rownames(contact_tab_ind) <- c("Non: Controlling-for & ICW & Ranks", "Part: Controlling-for & ICW & Ranks",
                               "Non: Controlling-for & Additive & Ranks", "Part: Controlling-for & Additive & Ranks",
                               "Non: Differencing & ICW & Ranks", "Part: Differencing & ICW & Ranks",
                               "Non: Differencing & Additive & Ranks", "Part: Differencing & Additive & Ranks",
                               "Non: Controlling-for & ICW & Categories", "Part: Controlling-for & ICW & Categories",
                               "Non: Controlling-for & ICW & Raw", "Part: Controlling-for & ICW & Raw",
                               "Non: Differencing & ICW & Categories", "Part: Differencing & ICW & Categories",
                               "Non: Differencing & ICW & Raw", "Part: Differencing & ICW & Raw")
contact_tab_ind <- round(contact_tab_ind,3)
contact_tab_ind <- knitr::kable(contact_tab_ind, format="latex")


```

\begin{table}[H]
\begin{center}
\label{tab:contact_tab_ind}
\caption{\textbf{Individual Contact} Effect of ECPN on contact using alternative methods of estimation, index construction, and measuring count variables. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r contact_tab_ind`
\end{center}
\end{table}

```{r}
pgg_tab_ind <- rbind(newList_ind[[4]][c(1,2),c(1:2)], newList_ind[[5]][c(1,2),c(1:2)])
colnames(pgg_tab_ind) <- c("coefficient", "p-value")
rownames(pgg_tab_ind) <- c("Non: Donation (binary)", "Part: Donation (binary)",
                            "Non: Donation amount", "Part: Donation amount")
pgg_tab_ind <- round(pgg_tab_ind,3)
pgg_tab_ind <- knitr::kable(pgg_tab_ind, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:pgg_tab_ind}
\caption{\textbf{Individual Publid Goods Game} Effect of ECPN on probability of donating and on donation amount. The first column shows coefficients from OLS regression and the second column shows $p$-values from randomization inference.}
\smallskip
`r pgg_tab_ind`
\end{center}
\end{table}
<!--
\begin{figure}[H]
\begin{center}
\includegraphics[width=.8\textwidth]{figs/pggPan_plot.png}
\caption{\label{fig:pgg_plot_ind} \textbf{Individual Public Goods Game} This figure shows the proportion of each experimental group who donated and their average donation amount. Orange shows the full participants; red shows the nonparticipants in intervention communities; blue shows people in control communities.}
\end{center}
\end{figure}


\begin{figure}[H]
\begin{center}
\includegraphics[width=.8\textwidth]{figs/randPan_plot.png}
\caption{\label{fig:percExp_plot_ind} \textbf{Individual Percent Experiment} This figure shows the proportion of each experimental group who would join a group or live in a community with increasing percentages of outgroup members. The outcome is the mean response of those two questions so that a respondent saying yes to both was assigned a 1, a respondent saying yes to one was assigned a 0.5, and a respondent saying no to both was assigned a 0. Red shows the full participants; green shows participants in intervention communities; blue shows control communities.  Light colors are values at baseline; dark colors are values at endline.}
\end{center}
\end{figure}
-->

**********

## Appendix D: Balance Tests

```{r}
load("balTests.rda")
#bal_obs
bal_obs_tab1 <- knitr::kable(round(bal_obs$results, 3), format="latex")
bal_obs_tab2 <- knitr::kable(round(bal_obs$overall, 3), format="latex")

#bal_svy
bal_svy_tab1 <- knitr::kable(round(bal_svy$results, 3), format="latex")
bal_svy_tab2 <- knitr::kable(round(bal_svy$overall, 3), format="latex")
```

\begin{table}[H]
\begin{center}
\label{tab:bal_obs_tab1}
\caption{\textbf{Balance: Observational Data All Outcomes}}
\smallskip
`r bal_obs_tab1`
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\label{tab:bal_obs_tab2}
\caption{\textbf{Balance: Observational Data Omnibus P-value}}
\smallskip
`r bal_obs_tab2`
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\label{tab:bal_svy_tab1}
\caption{\textbf{Balance: Survey Data All Outcomes}}
\smallskip
`r bal_svy_tab1`
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\label{tab:bal_svy_tab2}
\caption{\textbf{Balance: Survey Data Omnibus P-value}}
\smallskip
`r bal_svy_tab2`
\end{center}
\end{table}

**********

## Appendix E: Placebo tests

Several of our outcomes are survey self-reports, and self-reports could be affected by factors other than the intervntion. For example, our survey results are suspect if respondents in treatment communities learned the ``correct'' answers better than respondents in control communities (social desirability bias). If social desirability accounts for the effect in survey self-reports, we would also expect differences between treatment and control for other normatively desirable attitudes. 

To test social desirability effects, we conduct a placebo analysis using attitudes about violence as a placebo. Attitudes about violence are a good candidate for this placebo because intergroup contact should not affect general attitudes about violence, but respondents may feel social pressure to answer violence questions in a desirable way. We measure attitudes about violence with a six question index asking respondents if it is always, sometimes, rarely, or never justified to use violence in certain situations, such as retaliating against violence or bringing criminals to justice.

Respondents in treatment communities might also express more positive attitudes towards the outgroup if attitudes were becoming more tolerant in treatment villages in a way that was unrelated to the intervention.  If attitudes towards any outgroup were becoming more tolerant in treatment communities compared to control communities, we would expect attitudes towards religious outgroups to improve more in treatment communities than control communities.  The contact intervention should not affect attitudes towards people from other religions because the farmers and pastoralists are often the same religion.

Respondents in treatment communities also might have had better access to information, and that information changed their attitudes/perceptions.  To measure access to information, we use frequency of radio listening.  If the treatment communities increased their amount of radio listening significantly more than control communities, it is possible their attitudes/perceptions changed due to information and not the contact intervention.

Coefficients come from OLS regression equation specified in the paper (using state-level blocked fixed effects).  P-values come from the randomization inference described in the paper and in Appendix A; they are one-sided "greater-than" p-values. The base method used in the paper always constructs indices using inverse-covariance weighting; it uses the controlling-for method of difference-in-differences estimation when an outcome's baseline difference between treatment and control is less than 0.20 standard deviations; it uses the differencing method when the baseline difference is 0.20 standard deviations or larger.

```{r}
load("../data_and_code/survey_dat/d_analysis/pl_list_of_coefs_and_ps.Rda")
load("../data_and_code/survey_dat/d_analysis/pl_list_of_coefs_and_ps_ind.Rda")
#placeboList
#placeboList_ind
```

### Community.

```{r}
# vio
pl_vio_tab <- placeboList[[1]][,c(1:2,4)]
colnames(pl_vio_tab) <- c("coefficient", "p-value", "base")
rownames(pl_vio_tab) <- c("Controlling-for & ICW", "Controlling-for & Additive",
                            "Differencing & ICW", "Differencing & Additive")
pl_vio_tab <- round(pl_vio_tab,3)
pl_vio_tab <- knitr::kable(pl_vio_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:pl_vio_tab}
\caption{\textbf{Community Placebo: Attitudes towards violence index.} Effect of ECPN on placebo outcome using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r pl_vio_tab`
\end{center}
\end{table}

```{r}
# components of vio index
pl_vio_tab1 <- rbind(placeboList[[2]][c(1,3),c(1:2,4)],
                     placeboList[[3]][c(1,3),c(1:2,4)],
                     placeboList[[4]][c(1,3),c(1:2,4)],
                     placeboList[[5]][c(1,3),c(1:2,4)],
                     placeboList[[6]][c(1,3),c(1:2,4)],
                     placeboList[[7]][c(1,3),c(1:2,4)])
colnames(pl_vio_tab1) <- c("coefficient", "p-value", "base")
rownames(pl_vio_tab1) <- c("Bring criminals to justice: Controlling-for", "Bring criminals to justice: Differencing",
                           "Defend ones group: Controlling-for", "Defend ones group: Differencing",
                           "Defend ones religion: Controlling-for", "Defend ones religion: Differencing",
                           "Force the government to change their policies: Controlling-for", "Force the government to change their policies: Differencing",
                           "Maintain culture and traditions: Controlling-for", "Maintain culture and traditions: Differencing",
                           "Retaliate against violence: Controlling-for", "Retaliate against violence: Differencing")
pl_vio_tab1 <- round(pl_vio_tab1,3)
pl_vio_tab1 <- knitr::kable(pl_vio_tab1, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:pl_vio_tab1}
\caption{\textbf{Community Placebo: Components of violence index.} Effect of ECPN on components of placebo index (attitudes towards violence) using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r pl_vio_tab1`
\end{center}
\end{table}


```{r}
# outgroup trust
pl_out_tab <- placeboList[[8]][c(1,3),c(1:2,4)]
colnames(pl_out_tab) <- c("coefficient", "p-value", "base")
rownames(pl_out_tab) <- c("Controlling-for", "Differencing")
pl_out_tab <- round(pl_out_tab,3)
pl_out_tab <- knitr::kable(pl_out_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:pl_out_tab}
\caption{\textbf{Community Placebo: Trust towards religious outgroups.} Effect of ECPN on placebo outcome using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r pl_out_tab`
\end{center}
\end{table}

```{r}
# radio listening
pl_rad_tab <- placeboList[[9]][c(1,3),c(1:2,4)]
colnames(pl_rad_tab) <- c("coefficient", "p-value", "base")
rownames(pl_rad_tab) <- c("Controlling-for", "Differencing")
pl_rad_tab <- round(pl_rad_tab,3)
pl_rad_tab <- knitr::kable(pl_rad_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:pl_rad_tab}
\caption{\textbf{Community Placebo: Radio listening frequency.} Effect of ECPN on placebo outcome using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r pl_rad_tab`
\end{center}
\end{table}

### Individual

```{r}
# vio
pl_vio_ind <- placeboList_ind[[1]][,c(1:2,4)]
colnames(pl_vio_ind) <- c("coefficient", "p-value", "base")
rownames(pl_vio_ind) <- c("Non: Controlling-for & ICW", "Part: Controlling-for & ICW", 
                                "Non: Controlling-for & Additive", "Part: Controlling-for & Additive",
                                "Non: Differencing & ICW", "Part: Differencing & ICW", 
                                "Non: Differencing & Additive", "Part: Differencing & Additive")
pl_vio_ind <- round(pl_vio_ind,3)
pl_vio_ind <- knitr::kable(pl_vio_ind, format="latex")
```

\begin{table}[H]
\begin{center}
\label{tab:pl_vio_ind}
\caption{\textbf{Individual Placebo: Attitudes towards violence index.} Effect of ECPN on placebo outcome using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r pl_vio_ind`
\end{center}
\end{table}


```{r}
# vio components
pl_vio_ind1 <- rbind(placeboList_ind[[2]][c(1,2,5,6),c(1:2,4)],
                     placeboList_ind[[3]][c(1,2,5,6),c(1:2,4)],
                     placeboList_ind[[4]][c(1,2,5,6),c(1:2,4)],
                     placeboList_ind[[5]][c(1,2,5,6),c(1:2,4)],
                     placeboList_ind[[6]][c(1,2,5,6),c(1:2,4)],
                     placeboList_ind[[7]][c(1,2,5,6),c(1:2,4)])
colnames(pl_vio_ind1) <- c("coefficient", "p-value", "base")
rownames(pl_vio_ind1) <- c("Non: Bring criminals to justice: Controlling-for", "Part: Bring criminals to justice: Controlling-for",
                           "Non: Bring criminals to justice: Differencing", "Part: Bring criminals to justice: Differencing",
                           "Non: Defend ones group: Controlling-for", "Part: Defend ones group: Controlling-for",
                           "Non: Defend ones group: Differencing", "Part: Defend ones group: Differencing",
                           "Non: Defend ones religion: Controlling-for", "Part: Defend ones religion: Controlling-for",
                           "Non: Defend ones religion: Differencing", "Part: Defend ones religion: Differencing",
                           "Non: Force the government to change their policies: Controlling-for", "Part: Force the government to change their policies: Controlling-for",
                           "Non: Force the government to change their policies: Differencing", "Part: Force the government to change their policies: Differencing",
                           "Non: Maintain culture and traditions: Controlling-for", "Part: Maintain culture and traditions: Controlling-for",
                           "Non: Maintain culture and traditions: Differencing", "Part: Maintain culture and traditions: Differencing",
                           "Non: Retaliate against violence: Controlling-for", "Part: Retaliate against violence: Controlling-for", 
                           "Non: Retaliate against violence: Differencing", "Part: Retaliate against violence: Differencing")
pl_vio_ind1 <- round(pl_vio_ind1,3)
pl_vio_ind1 <- knitr::kable(pl_vio_ind1, format="latex")
```

\begin{table}[H]
\begin{center}
\label{tab:pl_vio_ind1}
\caption{\textbf{Individual Placebo: Components of violence index.} Effect of ECPN on components of placebo index (attitudes towards violence) using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r pl_vio_ind1`
\end{center}
\end{table}


```{r}
# outgroup trust
pl_out_ind <- placeboList_ind[[8]][c(1,2,5,6),c(1:2,4)]
colnames(pl_out_ind) <- c("coefficient", "p-value", "base")
rownames(pl_out_ind) <- c("Non: Controlling-for", "Part: Controlling-for",
                          "Non: Differencing", "Part: Differencing")
pl_out_ind <- round(pl_out_ind,3)
pl_out_ind <- knitr::kable(pl_out_ind, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:pl_out_ind}
\caption{\textbf{Individual Placebo: Trust towards religious outgroups.} Effect of ECPN on placebo outcome using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r pl_out_ind`
\end{center}
\end{table}

```{r}
# outgroup trust
pl_rad_ind <- placeboList_ind[[8]][c(1,2,5,6),c(1:2,4)]
colnames(pl_rad_ind) <- c("coefficient", "p-value", "base")
rownames(pl_rad_ind) <- c("Non: Controlling-for", "Part: Controlling-for",
                          "Non: Differencing", "Part: Differencing")
pl_rad_ind <- round(pl_rad_ind,3)
pl_rad_ind <- knitr::kable(pl_rad_ind, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:pl_rad_ind}
\caption{\textbf{Individual Placebo: Radio listening frequency.} Effect of ECPN on placebo outcome using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r pl_rad_ind`
\end{center}
\end{table}

**********

## Appendix F: State-level differences

Coefficients and p-values estimating state-level heterogeneous effects were calculated with robust OLS regression using site-level clusters. The regression interacted the treatment indicator with the state indicator.  This is a low-power analysis.  There are no significant differences in treatment effect by state. Benue was the reference category so this table shows differences for Nasarawa.

```{r}
load("../data_and_code/survey_dat/d_analysis/state_list.Rda")
#stateList

state_tab <- rbind(stateList[[1]][4,c(2,3)],
                       stateList[[2]][4,c(2,3)],
                       stateList[[3]][4,c(2,3)],
                       stateList[[4]][4,c(2,3)],
                       stateList[[5]][4,c(2,3)],
                       stateList[[6]][4,c(2,3)],
                       stateList[[7]][4,c(2,3)])
colnames(state_tab) <- c("coefficient", "p-value")
rownames(state_tab) <- c("Attitudes", "Perceptions of security",
                          "Contact", "Percent Experiment",
                          "Endorsement Experiment",
                          "PGG donation", "PGG amount")
state_tab <- round(state_tab,3)
state_tab <- knitr::kable(state_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:state_tab}
\caption{\textbf{State-level differences in community-level analysis.} There are not significant differences between the effect of the contact intervention by state. The first column shows coefficients from OLS regression, the second column shows $p$-values from OLS regression.}
\smallskip
`r state_tab`
\end{center}
\end{table}

**********

## Appendix G: Farmer-pastoralist differences

Coefficients and p-values estimating farmer/pastoralist heterogeneous effects were calculated with robust OLS regression using site-level clusters and fixed effects for state. The regression interacted the treatment indicator with the state indicator. There are no significant differences in treatment effect by farmer/pastoralist. Farmers were the reference category so this table shows differences for pastoralists.

```{r}
load("../data_and_code/survey_dat/d_analysis/farm_list.Rda")
#farmList

farm_tab <- rbind(farmList[[1]][3,c(2,3)],
                       farmList[[2]][3,c(2,3)],
                       farmList[[3]][3,c(2,3)],
                       farmList[[4]][3,c(2,3)],
                       farmList[[5]][3,c(2,3)],
                       farmList[[6]][3,c(2,3)],
                       farmList[[7]][3,c(2,3)])
colnames(farm_tab) <- c("coefficient", "p-value")
rownames(farm_tab) <- c("Attitudes", "Perceptions of security",
                          "Contact", "Percent Experiment",
                          "Endorsement Experiment",
                          "PGG donation", "PGG amount")
farm_tab <- round(farm_tab,3)
farm_tab <- knitr::kable(farm_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:farm_tab}
\caption{\textbf{Farmer-pastoralist differences in community-level analysis.} There are not significant differences between the effect of the contact intervention by farmer/pastoralist. The first column shows coefficients from OLS regression, the second column shows $p$-values from OLS regression.}
\smallskip
`r farm_tab`
\end{center}
\end{table}

**********

## Appendix H: Survey Questions

**Attitudes**

- With regards to someone from [X GROUP], would you feel comfortable:
    - if they worked in your field?
    - paying them to watch your animals?
    - trading goods with them?
    - sharing a meal with them?
    - with a close relative marrying a person from [X GROUP]?
- From 1-5, how much do you trust people from [X GROUP] in your area?
- Now I’m going to ask you questions about your community here in Benue/Nassarawa, including [X GROUP].  Please tell me how strongly you agree/disagree with each of the following statements: People in this area can be trusted.

**Contact**

- Now I’m going to ask you questions about your contact with [X GROUP] in your area.
    - Think of the market you go to most frequently. During the past month, have members of X GROUP gone to that market too?  In the past month, how many times did you interact with X group in the market?
- In the past month, have you:
    - Joined a member of X group for a social event outside the home?  How often?
    - Hosted a member of X group for a ceremony in your home?  How often?
    - Gone to the home of a member of X group for a ceremony?  How often?
    - Have you interacted with members of X group in any other way in the past month?

**Insecurity**

- In the last year were there any areas that you avoided going to or through because of insecurity during the night? 
- In the last year were there any areas that you avoided going to or through because of insecurity, during the day?
- In the last year, did insecurity ever prevent you from: 
    - Working when you wanted to work? About how many days were you unable to work?
    - Going to the market?
    - Getting water for the household?
    - Going to your field/farm?
    - Moving your animals to grazing areas?
    - Moving your animals to water?
    - Earning money or going to work?
    - Going to school?

**Endorsement Experiment**

- Imagine that there is a proposal by [**the Farmer’s Cooperative Society**/**MACBAN**] for action to enhance access to clean water in rural areas.  Though expensive, the proposal aims to bring fresh, clean water to hundreds of areas without access to it, including this one.  If this were proposed, how would you feel about it?

**Percent Experiemnt**

- Think about groups that you might join in your leisure time.  Would you join a group that had **5/25/50/75**% X Group members?
- Think about the community you live in.  Would you live in a community that had **5/25/50/75**% X Group members?


**Violence Placebo**

- Now I am going to ask you some questions about the use of violence.  Is it always, sometimes, rarely, or never justified to use violence to do each of the following:
    - Retaliate against violence
    - Defend one's group
    - Maintain culture and traditions
    - Defend one's religion
    - Bring criminals to justice
    - Force the government to change their policies

**Public Goods Game**

"Thank you very much for participating in our survey.  Before I go, there is one last thing.  As you may have heard, we have development funds to use in this community.  We have randomly selected you as one of the 50 people to receive these funds.  These funds are not for a Mercy Corps project, but rather for you to keep personally or to donate to a community fund.   

We have 1,000 Naira to give to you.  It is yours, and you can use it either way--for yourself or for a community good.

Your community and [joint farmer/pastoralist community] have created a project committee to whom you can donate this money so that it may be used to help both communities.  The project committee has 4  people from each community.  We have found a donor that will match the funds that you all contribute to the project committee, so that if you donate 100 Naira the project committee receives 300 Naira, and if you donate all 1,000 Naira the project committee receives 3,000 Naira.  You are welcome to donate none, some, or all of the money to the project committee.

These are your individual donation envelopes.  All the donations will be private -- only you will know how much money you donated. It essential that you keep how much you give private -- please do not tell anyone.  I have with me a donation envelope to collect donations.  Please go into your home, put however much of the 1,000 Naira you wish to donate to the project committee in the envelope, take whatever amount you want to keep for yourself, and come back to place your envelope in the donation envelope.  Remember, you are welcome to donate none, some, or all of the money to the project committee.  After that we are finished and you may continue your day.  We will come back and publicly announce how much money your community's project committee will receive."





















################################################

******

################################################

# Review appendix

## Appendix I: Effect of Contact vs. effect of development projects and mediation

It is possible that the effects of our intervention are due to impact of the development project around which the contact was organized, rather than intergroup contact itself. The effect could also be due to mediation provided to some community leaders. We ran three analyses to disentangle the effects of contact from the effects of the development projects and mediation.

The first was to determine if treatment effects were significantly larger for communities where larger proportions of people were aware of, used, and perceived benefit from the projects. In treatment communities, we predicted outcome change with (1) awareness of boreholes, (2) use of boreholes, (3) awareness of quick-impact projects, and (4) perceived benefit from quick-impact projects. If treatment effects are due to development projects and not contact, we would expect larger effects where a greater proportion of respondents were aware of, used, and benefited from the development projects.

```{r}
load("../data_and_code/review/benefit_df.Rda")
load("../data_and_code/review/benefitVar_df.Rda")
load("../data_and_code/review/benefitVar_df_svy.Rda")

benefit_df_tab <- knitr::kable(benefit_df)
benefitVar_df_tab <- knitr::kable(benefitVar_df)
benefitVar_df_svy_tab <- knitr::kable(benefitVar_df_svy)
```

Our analysis shows that awareness, use, and benefit from the projects is not significantly related to any outcome (the mean p-value is ~0.32). It's also not the case that any of those variables separately (awareness, use, and benefit) are related to improvements on any outcome. Though the p-values are insignificant, the mean t-statistic for the awareness/use/benefit variables is positive, possibly suggesting that the development projects, while not explaining the bulk of the treatment effect, may have increased the effect. The tables show the mean coefficient, $p$-value, and t-statistic for each outcome being predicted by each "benefit" variable.

\begin{table}[H]
\begin{center}
\label{tab:benefit_df_tab}
\caption{\textbf{Benefit variables affect on outcomes.} Mean coefficient, $p$-value, and t-statistic for each outcome, across benefit variables. Benefit variables are not significantly related to any outcome.}
\smallskip
`r benefit_df_tab`
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\label{tab:benefitVar_df_svy_tab}
\caption{\textbf{Benefit variables affect on outcomes.} Mean coefficient, $p$-value, and t-statistic for each benefit variables, across outcomes. This tables removes Public Goods Game outcomes because (1) their coefficients are on a different scale than the survey outcomes and (2) the coefficients and t-statistics are negative, which could hide the effect of benefit variables on the other outcomes. However, this table shows that benefit variables are not significantly related to any survey outcome.}
\smallskip
`r benefitVar_df_svy_tab`
\end{center}
\end{table}

Second, we looked at whether pastoralists in Benue differed from the rest of the sample. Pastoralists in Benue benefited least from the development projects (especially the main project that built boreholes) because they became displaced from where the boreholes were constructed prior to the endline survey. Here we (1) confirm that pastoralists in Benue were less likely to be aware of, use, or benefit from the development projects and (2) see no significant outcome differences between pastoralists in Benue and the rest of the sample (mean p-value ~0.58).

```{r}
load("../data_and_code/review/BenPast_Benefit.Rda")
load("../data_and_code/review/benPast_tab.Rda")

BenPast_Benefit_tab <- knitr::kable(BenPast_Benefit)
benPast_tab <- knitr::kable(benPast_tab)
```

\begin{table}[H]
\begin{center}
\label{tab:BenPast_Benefit_tab}
\caption{\textbf{Benefit pastoralists awareness and benefit from development projects.} Coefficients, t-statistics, and $p$-values comparing Benue pastoralists in the treatment group to the rest of the treatment group. Benue pastoralists were significantly less likely to be aware of the boreholes or use the boreholes; they were marginally less likely to be aware of the quick-impact projects.}
\smallskip
`r BenPast_Benefit_tab`
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\label{tab:benPast_tab}
\caption{\textbf{Outcomes of Benefit pastoralists in the treatment group.} Coefficients, $p$-values, and t-statistics comparing Benue pastoralists in the treatment group to the rest of the treatment group. Treatment effects are not smaller among Benue pastoralists than the rest of the treatment group. Note: the mean coefficient excludes the Public Goods Game, which is on a different scale than the other variables; it is included in the $p$-value and t-statistic.}
\smallskip
`r benPast_tab`
\end{center}
\end{table}


```{r}
load("../data_and_code/review/mediat_tab.Rda")
```

The third analysis concerned mediation.  While we cannot rule out that the effect was due to the meditation training, only 52 of the over 1000 endline respondents in treatment sites were aware of the mediation intervention.

\begin{table}[H]
\begin{center}
\label{tab:mediat_tab}
\caption{\textbf{Mediation Exposure.} Exposure to mediation in treatment and control sites in endline survey. Only 52 randomly selected respondents in treatment had any exposure to mediation. No control respondents had exposure to mediation.}
\smallskip
`r mediat_tab`
\end{center}
\end{table}


## Appendix J: Family-Wise Error Rate (FWER)

To control the FWER, we conducted within-family hypothesis corrections using the Holm correction.  For two of our outcomes (pastoralists in market and perceptions of insecurity), the findings remain statistically significant. For the two other outcomes (self-reported contact and attitudes), significance levels shift from statistically significant to marginally significant (.04 to .08). This means we have a significant $p$-value for our hypothesis families about intergroup contact and about insecurity; we have a marginally significant $p$-value for our hypothesis family about attitudes; we have no signifcant $p$-value for our hypothesis family about cooperation.

Note: the outcome measuring pastoralists in the market remains statistically significant even if using the bonferonni correction to correct for all (vs. within family) hypothesis tests in the analysis.

The exploratory individual-level data has only one outcome per family (except for the Cooperation family, for which no $p$-values were significant without correction). We therefore do not show "corrected" individual-level $p$-values.  If we put all individual-level hypotheses into a single family and use the Holm correction, the _Self-reported contact_ outcome changes from significant ($p$=0.018) to marginally significant($p$=0.088). None of the other outcomes were significant or marginally significant before correction.

```{r}
load("../data_and_code/review/holm_tab.Rda")
holm_tab <- knitr::kable(holm_tab)
```

\begin{table}[H]
\begin{center}
\label{tab:holm_tab}
\caption{\textbf{P-values controlling the family-wise error rate.}}
\smallskip
`r holm_tab`
\end{center}
\end{table}

## Appendix K: Power Analysis

```{r}
load("../data_and_code/review/power_figure.png")

```

At community level, we could detect effects of ~0.60 SDs with 0.80 power. We expected better power for our actual analysis because our power analysis does not use randomization inference to generate true p-values.  We simulated our community-level power analysis with the following code.

```{r, eval=F, echo=T}
# using insecurity as the default outcome, as it is our strongest survey outcome at the community level. outcome_list_qip[2] = "in_cw".
bigPow.fn <-function(nsims, var=outcome_list_qip[2], tau)
{
  newPow.fn <- function(var, tau)
{
    # 6 TR sites from Nas, 4 from Ben
    newtr_nas <- sample(unique(ag.df$psu[ag.df$state %in% "nas"]), size=6)
    newtr_ben <- sample(unique(ag.df$psu[ag.df$state %in% "ben"]), size=4)
    newtr <- c(as.character(newtr_nas), as.character(newtr_ben))
    df <- ag.df
    df[,"newtr"] <- ifelse(df$psu %in% newtr, 1, 0)
  
  # make endline outcome with TR effect tau
  df[, paste0(var,"_end")] <- (df[,paste0(var,"_end")]-mean(df[,paste0(var,"_end")]))/sd(df[,paste0(var,"_end")])
  #scale(df[,paste0(var,"_end")])
  df[df$newtr %in% 1, paste0(var,"_end")] <- df[df$newtr %in% 1, paste0(var,"_end")]+tau
  
  # for baseline control, also scale
  df[, paste0(var,"_base")] <- (df[,paste0(var,"_base")]-mean(df[,paste0(var,"_base")]))/sd(df[,paste0(var,"_base")])
  
  # lm
  lm1 <- lm_robust(df[,paste0(var,"_end")]~df[,'newtr']+df[,paste0(var,"_base")]+state, 
                   clusters = psu, data=df)
  
  want <- tidy(lm1)[2,5]
  return(want)
  }
  
  check <- do(nsims)*newPow.fn(var=var, tau=tau)
  pval <- mean(check<0.05)
  return(pval)
}

# run power analysis for tau 0-1
possibleTaus <- seq(0,1,0.1)
possibleTaus <- as.data.frame(possibleTaus)
system.time(
for(i in 1:nrow(possibleTaus))
{
  possibleTaus[i, "pow"] <- bigPow.fn(nsims=3000, tau=possibleTaus[i,1])
}
)
possibleTaus

```

\begin{figure}%[\sidecaptionrelwidth][t]
\centering
\includegraphics[width=\linewidth]{../data_and_code/review/power_figure.png}
\caption{Community-level power analysis.}\label{fig:pow_comm}
\end{figure}

At individual level, we could detect effects of ~0.40 SDs with 0.80 power. We expected better power for our actual analysis because our power analysis does not use randomization inference to generate true p-values. We used the [EGAP power calculator](https://egap.shinyapps.io/power-app/) for the individual-level power analysis.  The parameters were: Alpha = 0.05, Tau = 0.40 SD, ICC=0.05, 15 clusters per arm, up to 300 respondents per cluster.

\begin{figure}%[\sidecaptionrelwidth][t]
\centering
\includegraphics[width=\linewidth]{../data_and_code/review/power_figure_ind.png}
\caption{Individual-level power analysis.}\label{fig:pow_ind}
\end{figure}


## Appendix L: Small-j checks

Many effects in Figure 1 are driven by worsening conditions in control communities rather than improved relations in treatment communities. Given the small number of control communities (5), I worry that the effects could be driven by a particularly bad period in a single control community. Do similar patterns hold for other outcomes?


