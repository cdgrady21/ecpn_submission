---
title: "How Contact Can Promote Societal Change Amid Intergroup Conflict: An Intergroup Contact Field Experiment in Nigeria - Supplementary Information"
output:
  pdf_document:
    toc: true
    toc_depth: 1
  html_document:
    toc: true
    toc_depth: 1
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
rm(list=ls())

# data
load("../data_and_code/survey_dat/d_analysis/list_of_coefs_and_ps.Rda")
load("../data_and_code/survey_dat/d_analysis/list_of_rank_bin_raw.Rda")


# not included: Individual-levl balance between part/nonpart/control == unneeded because exploratory & no assumption of balance.
```

**********
\newpage

# Appendix A: Randomization Inference and Bootstrapping

Randomization inference and bootstrapping are nonparametric methods to generate $p$-values (randomization inference) and confidence intervals (bootstrapping).  With *randomization inference*, we first shuffle the treatment variable to break the relationship between treatment and outcomes.  Next we regress outcomes on treatment using our regression equation and store the resulting coefficient.  Lastly, we repeat that process 10,000 times to create the distribution of coefficients we would observe if treatment had no effect on outcomes -- the null hypothesis.  Our $p$-value is the proportion of the null distribution that is greater than or equal to our observed coefficient.  

*Bootstrapping* for standard errors is similar, but instead of shuffling the treatment indicator we resample units with replacement.  By resampling with replacement, we create the empirical distribution of our data and the range of possible treatment effects we might observe if we repeated the experiment 10,000 times.  The treatment effect at the 2.5th percentile and at the 97.5th percentile are equivalent to a 95\% confidence interval <!--[@efron1994introduction]-->.

In each of these procedures, we mimic our randomization process by randomizing/resampling the intervention to communities in site-level clusters and within state blocks. This means that both communities in an implementation site (farmers and pastoralists) will always be treated/sampled together and that assignment to the intervention and resampling are conducted separately in Nassarawa and Benue, just as the intervention was assigned in this study.  This procedure ensures that our null distribution (for $p$-values) is created by randomizing the intervention between exchangeable units and that our empirical distribution (for confidence intervals) is created by resampling units as they were sampled.

**********
\newpage

# Appendix B: Robustness checks for community analysis

## Survey outcomes

These tables shows results with different ways of making indices (additive vs inverse-covariance weighted), different models for estimating effects (differencing vs controlling-for), and different ways of coding count variables (raw vs ranked).  Each table is an outcome.  Rows are results for different ways of creating the outcomes.  Columns show the coefficient from OLS regression, true p-value from randomization inference, and a binary "base" indicator showing which method was used in the paper.  

The base method is always inverse-covariance weighted indices; the estimation method is controlling-for unless the baseline difference between the treatment and control groups is 0.20 standard deviations or more; the base method of handling count variables is dense rank. Only contact outcomes use count variables, only survey outcomes have a baseline and an endline and are measured with indices.

```{r, echo=F}
# data
## newList is list of coefs and ps for outcomes
## var_tab is coefs and ps for the various ways to calculate self-reported contact outside of the intervention

#newList[[3]]
#var_tab

attitude_tab <- newList[[1]][,c(1:2,4)]
colnames(attitude_tab) <- c("coefficient", "p-value", "base")
rownames(attitude_tab) <- c("Controlling-for & ICW", "Controlling-for & Additive",
                            "Differencing & ICW", "Differencing & Additive")
attitude_tab <- round(attitude_tab,3)
attitude_tab <- knitr::kable(attitude_tab, format="latex")
```

\begin{table}[H]
\begin{center}
\label{tab:attitude_tab}
\caption{\textbf{Community Attitudes.} Effect of ECPN on attitudes using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r attitude_tab`
\end{center}
\end{table}

```{r}
security_tab <- newList[[2]][,c(1:2,4)]
colnames(security_tab) <- c("coefficient", "p-value", "base")
rownames(security_tab) <- c("Controlling-for & ICW", "Controlling-for & Additive",
                            "Differencing & ICW", "Differencing & Additive")
security_tab <- round(security_tab,3)
security_tab <- knitr::kable(security_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:security_tab}
\caption{\textbf{Community Perceptions of Security} Effect of ECPN on perceptions of security using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r security_tab`
\end{center}
\end{table}


```{r}
contact_tab <- newList[[3]][,c(1:2,4)]
var_tab$base <- c(0,0,0,1,0,0)
var_tab <- var_tab[c(2,3,5,6),]
contact_tab <- rbind(contact_tab, var_tab)
colnames(contact_tab) <- c("coefficient", "p-value", "base")
rownames(contact_tab) <- c("Controlling-for & ICW & Ranks", "Controlling-for & Additive & Ranks",
                            "Differencing & ICW & Ranks", "Differencing & Additive & Ranks",
                           "Controlling-for & ICW & Categories",
                           "Controlling-for & ICW & Raw",
                           "Differencing & ICW & Categories",
                           "Differencing & ICW & Raw")
contact_tab <- round(contact_tab,3)
contact_tab <- knitr::kable(contact_tab, format="latex")


```

\begin{table}[H]
\begin{center}
\label{tab:contact_tab}
\caption{\textbf{Community Contact} Effect of ECPN on contact using alternative methods of estimation, index construction, and measuring count variables. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r contact_tab`
\end{center}
\end{table}

```{r}
percExp_tab <- newList[[4]][c(1,3),c(1:2,4)]
colnames(percExp_tab) <- c("coefficient", "p-value", "base")
rownames(percExp_tab) <- c("Controlling-for",
                            "Differencing")
percExp_tab <- round(percExp_tab,3)
percExp_tab <- knitr::kable(percExp_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:percExp_tab}
\caption{\textbf{Community Contact Willingness (Percent Experiment)} Effect of ECPN on willingness to have contact with the outgroup using alternative methods of estimation. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r percExp_tab`
\end{center}
\end{table}


```{r}
endExp_tab <- newList[[5]][c(1,3),c(1:2,4)]
colnames(endExp_tab) <- c("coefficient", "p-value", "base")
rownames(endExp_tab) <- c("Controlling-for",
                            "Differencing")
endExp_tab <- round(endExp_tab,3)
endExp_tab <- knitr::kable(endExp_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:endExp_tab}
\caption{\textbf{Community Endorsement Experiment} Effect of ECPN on endorsement experiment using alternative methods of estimation. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r endExp_tab`
\end{center}
\end{table}

```{r}
pgg_tab <- rbind(newList[[6]][1,c(1:2)], newList[[7]][1,c(1:2)])
colnames(pgg_tab) <- c("coefficient", "p-value")
rownames(pgg_tab) <- c("Donation (binary)",
                            "Donation amount")
pgg_tab <- round(pgg_tab,3)
pgg_tab <- knitr::kable(pgg_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:pgg_tab}
\caption{\textbf{Community Public Goods Game} Effect of ECPN on probability of donating and on donation amount. The first column shows coefficients from OLS regression and the second column shows $p$-values from randomization inference.}
\smallskip
`r pgg_tab`
\end{center}
\end{table}
<!-- plot unneeded, just takes up space.
\begin{figure}[H]
\begin{center}
\includegraphics[width=.8\textwidth]{figs/pggComm_plot.png}
\caption{\label{fig:pgg_plot_comm} \textbf{Community Public Goods Game} This figure shows the proportion of each experimental group who donated and their average donation amount. Orange shows the treatment communities; blue shows control communities.}
\end{center}
\end{figure}
-->

## Behvioral outcomes

```{r}
load("../data_and_code/review/behObs_enumsCheck_tab.Rda")
load("../data_and_code/review/behObs_enumsOnly_tab.Rda")
```

Enumerators (for surveys and for behavioral observation) were not informed of a community's treatment status, but two of the enumerators for behavioral observations interacted with the research team frequently and may have intuited the study's hypotheses. They also only made observations at treatment sites. If their intuition of program aims affected their observations (or if their observations became more positive over time for other reasons), our estimates of the treatment effect could be inflated.

We first checked the change over time in outcomes they reported. Descriptively, the two senior enumerators observed _less_ interaction in treatment sites over time, suggesting that they were not influenced by knowledge of the study's hypotheses. As a robustness check, we then repeated the main analysis but removed observations from these two enumerators.   Coefficients with their data removed are very similar to coefficients with their data included; $p$-values are higher mainly as a result of fewer observations (and therefore degrees of freedom). 
\begin{table}[H]
\begin{center}
\label{tab:behObs_enumsOnly_tab}
\caption{\textbf{Robustness check for behavioral observations} This table shows the baseline-endline change in outcomes for the two senior enumerators who may have intuited the study's hypotheses. The first column shows coefficients from OLS regression, the second column shows $p$-values. The row names show outcomes (pastoralists in the market, farmers in the market, and outgroup attending events). The two enumerators reported decreases in market outcomes in treatment sites and no change to event outcomes in treatment sites, suggesting that they were not influenced by knowledge of the study's hypotheses.}
\smallskip
`r behObs_enumsOnly_tab`
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\label{tab:behObs_enumsCheck_tab}
\caption{\textbf{Robustness check for behavioral observations} This table shows behavioral observation outcomes with two senior enumerators removed. The first column shows coefficients from OLS regression, the second column shows $p$-values. The row names show outcomes (pastoralists in the market, farmers in the market, and outgroup attending events) and subsets of the data (all data, data without two enumerators, and data from only those two enumerators).}
\smallskip
`r behObs_enumsCheck_tab`
\end{center}
\end{table}


**********
\newpage

# Appendix C: Robustness checks for individual analysis

These tables shows results with different ways of making indices (additive vs inverse-covariance weighted), different models for estimating effects (differencing vs controlling-for), and different ways of coding count variables (raw vs ranked).  Each table is an outcome.  Rows are results for different ways of creating the outcomes.  Columns show the coefficient from OLS regression, true p-value from randomization inference, and a binary "base" indicator showing which method was used in the paper.  

The base method is always inverse-covariance weighted indices; the estimation method is controlling-for unless the baseline difference between the participants and control groups is 0.20 standard deviations or more; the base method of handling count variables is dense rank. Only contact outcomes use count variables, only survey outcomes have a baseline and an endline and are measured with indices.

```{r, echo=F}
load("../data_and_code/survey_dat/d_analysis/list_of_coefs_and_ps_ind.Rda")
load("../data_and_code/survey_dat/d_analysis/list_of_rank_bin_raw_ind.Rda")

# Data
# newList_ind is list of coefs and ps for individual-level observational analysis. rows are part or nonpart vs CO.
# var_tab_ind is coefs and ps for the various ways to calculate self-reported contact outside the intervention, in the individual-level data. rows are participants or nonparticipants vs CO.

#newList_ind[[3]]
#var_tab_ind

attitude_tab_ind <- newList_ind[[1]][,c(1:2,4)]
colnames(attitude_tab_ind) <- c("coefficient", "p-value", "base")
rownames(attitude_tab_ind) <- c("Non: Controlling-for & ICW", "Part: Controlling-for & ICW", 
                                "Non: Controlling-for & Additive", "Part: Controlling-for & Additive",
                                "Non: Differencing & ICW", "Part: Differencing & ICW", 
                                "Non: Differencing & Additive", "Part: Differencing & Additive")
attitude_tab_ind <- round(attitude_tab_ind,3)
attitude_tab_ind <- knitr::kable(attitude_tab_ind, format="latex")
```

\begin{table}[H]
\begin{center}
\label{tab:attitude_tab_ind}
\caption{\textbf{Individual Attitudes.} Effect of ECPN on attitudes using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r attitude_tab_ind`
\end{center}
\end{table}

```{r}
security_tab_ind <- newList_ind[[2]][,c(1:2,4)]
colnames(security_tab_ind) <- c("coefficient", "p-value", "base")
rownames(security_tab_ind) <- c("Non: Controlling-for & ICW", "Part: Controlling-for & ICW", 
                                "Non: Controlling-for & Additive", "Part: Controlling-for & Additive",
                                "Non: Differencing & ICW", "Part: Differencing & ICW", 
                                "Non: Differencing & Additive", "Part: Differencing & Additive")
security_tab_ind <- round(security_tab_ind,3)
security_tab_ind <- knitr::kable(security_tab_ind, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:security_tab_ind}
\caption{\textbf{Individual Perceptions of Security} Effect of ECPN on perceptions of security using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r security_tab_ind`
\end{center}
\end{table}


```{r}
contact_tab_ind <- newList_ind[[3]][,c(1:2,4)]
var_tab_ind$base <- c(0,0,0,0,0,0,1,1,0,0,0,0)
var_tab_ind <- var_tab_ind[c(3:6,9:nrow(var_tab_ind)),]
contact_tab_ind <- rbind(contact_tab_ind, var_tab_ind)
colnames(contact_tab_ind) <- c("coefficient", "p-value", "base")
rownames(contact_tab_ind) <- c("Non: Controlling-for & ICW & Ranks", "Part: Controlling-for & ICW & Ranks",
                               "Non: Controlling-for & Additive & Ranks", "Part: Controlling-for & Additive & Ranks",
                               "Non: Differencing & ICW & Ranks", "Part: Differencing & ICW & Ranks",
                               "Non: Differencing & Additive & Ranks", "Part: Differencing & Additive & Ranks",
                               "Non: Controlling-for & ICW & Categories", "Part: Controlling-for & ICW & Categories",
                               "Non: Controlling-for & ICW & Raw", "Part: Controlling-for & ICW & Raw",
                               "Non: Differencing & ICW & Categories", "Part: Differencing & ICW & Categories",
                               "Non: Differencing & ICW & Raw", "Part: Differencing & ICW & Raw")
contact_tab_ind <- round(contact_tab_ind,3)
contact_tab_ind <- knitr::kable(contact_tab_ind, format="latex")


```

\begin{table}[H]
\begin{center}
\label{tab:contact_tab_ind}
\caption{\textbf{Individual Contact} Effect of ECPN on contact using alternative methods of estimation, index construction, and measuring count variables. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r contact_tab_ind`
\end{center}
\end{table}

```{r}
pgg_tab_ind <- rbind(newList_ind[[4]][c(1,2),c(1:2)], newList_ind[[5]][c(1,2),c(1:2)])
colnames(pgg_tab_ind) <- c("coefficient", "p-value")
rownames(pgg_tab_ind) <- c("Non: Donation (binary)", "Part: Donation (binary)",
                            "Non: Donation amount", "Part: Donation amount")
pgg_tab_ind <- round(pgg_tab_ind,3)
pgg_tab_ind <- knitr::kable(pgg_tab_ind, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:pgg_tab_ind}
\caption{\textbf{Individual Publid Goods Game} Effect of ECPN on probability of donating and on donation amount. The first column shows coefficients from OLS regression and the second column shows $p$-values from randomization inference.}
\smallskip
`r pgg_tab_ind`
\end{center}
\end{table}
<!--
\begin{figure}[H]
\begin{center}
\includegraphics[width=.8\textwidth]{figs/pggPan_plot.png}
\caption{\label{fig:pgg_plot_ind} \textbf{Individual Public Goods Game} This figure shows the proportion of each experimental group who donated and their average donation amount. Orange shows the full participants; red shows the nonparticipants in intervention communities; blue shows people in control communities.}
\end{center}
\end{figure}


\begin{figure}[H]
\begin{center}
\includegraphics[width=.8\textwidth]{figs/randPan_plot.png}
\caption{\label{fig:percExp_plot_ind} \textbf{Individual Percent Experiment} This figure shows the proportion of each experimental group who would join a group or live in a community with increasing percentages of outgroup members. The outcome is the mean response of those two questions so that a respondent saying yes to both was assigned a 1, a respondent saying yes to one was assigned a 0.5, and a respondent saying no to both was assigned a 0. Red shows the full participants; green shows participants in intervention communities; blue shows control communities.  Light colors are values at baseline; dark colors are values at endline.}
\end{center}
\end{figure}
-->

**********
\newpage

# Appendix D: Balance Tests

```{r}
load("balTests.rda")
#bal_obs
bal_obs_tab1 <- knitr::kable(round(bal_obs$results, 3), format="latex")
bal_obs_tab2 <- knitr::kable(round(bal_obs$overall, 3), format="latex")

#bal_svy
bal_svy_tab1 <- knitr::kable(round(bal_svy$results, 3), format="latex")
bal_svy_tab2 <- knitr::kable(round(bal_svy$overall, 3), format="latex")
```

\begin{table}[H]
\begin{center}
\label{tab:bal_obs_tab1}
\caption{\textbf{Balance: Observational Data All Outcomes}}
\smallskip
`r bal_obs_tab1`
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\label{tab:bal_obs_tab2}
\caption{\textbf{Balance: Observational Data Omnibus P-value}}
\smallskip
`r bal_obs_tab2`
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\label{tab:bal_svy_tab1}
\caption{\textbf{Balance: Survey Data All Outcomes}}
\smallskip
`r bal_svy_tab1`
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\label{tab:bal_svy_tab2}
\caption{\textbf{Balance: Survey Data Omnibus P-value}}
\smallskip
`r bal_svy_tab2`
\end{center}
\end{table}

**********
\newpage

# Appendix E: Placebo tests

Several of our outcomes are survey self-reports, and self-reports could be affected by factors other than the intervntion. For example, our survey results are suspect if respondents in treatment communities learned the ``correct'' answers better than respondents in control communities (social desirability bias). If social desirability accounts for the effect in survey self-reports, we would also expect differences between treatment and control for other normatively desirable attitudes. 

To test social desirability effects, we conduct a placebo analysis using attitudes about violence as a placebo. Attitudes about violence are a good candidate for this placebo because intergroup contact should not affect general attitudes about violence, but respondents may feel social pressure to answer violence questions in a desirable way. We measure attitudes about violence with a six question index asking respondents if it is always, sometimes, rarely, or never justified to use violence in certain situations, such as retaliating against violence or bringing criminals to justice.

Respondents in treatment communities might also express more positive attitudes towards the outgroup if attitudes were becoming more tolerant in treatment villages in a way that was unrelated to the intervention.  If attitudes towards any outgroup were becoming more tolerant in treatment communities compared to control communities, we would expect attitudes towards religious outgroups to improve more in treatment communities than control communities.  The contact intervention should not affect attitudes towards people from other religions because the farmers and pastoralists are often the same religion.

Respondents in treatment communities also might have had better access to information, and that information changed their attitudes/perceptions.  To measure access to information, we use frequency of radio listening.  If the treatment communities increased their amount of radio listening significantly more than control communities, it is possible their attitudes/perceptions changed due to information and not the contact intervention.

Coefficients come from OLS regression equation specified in the paper (using state-level blocked fixed effects).  P-values come from the randomization inference described in the paper and in Appendix A; they are one-sided "greater-than" p-values. The base method used in the paper always constructs indices using inverse-covariance weighting; it uses the controlling-for method of difference-in-differences estimation when an outcome's baseline difference between treatment and control is less than 0.20 standard deviations; it uses the differencing method when the baseline difference is 0.20 standard deviations or larger.

```{r}
load("../data_and_code/survey_dat/d_analysis/pl_list_of_coefs_and_ps.Rda")
load("../data_and_code/survey_dat/d_analysis/pl_list_of_coefs_and_ps_ind.Rda")
#placeboList
#placeboList_ind
```

## Community.

```{r}
# vio
pl_vio_tab <- placeboList[[1]][,c(1:2,4)]
colnames(pl_vio_tab) <- c("coefficient", "p-value", "base")
rownames(pl_vio_tab) <- c("Controlling-for & ICW", "Controlling-for & Additive",
                            "Differencing & ICW", "Differencing & Additive")
pl_vio_tab <- round(pl_vio_tab,3)
pl_vio_tab <- knitr::kable(pl_vio_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:pl_vio_tab}
\caption{\textbf{Community Placebo: Attitudes towards violence index.} Effect of ECPN on placebo outcome using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r pl_vio_tab`
\end{center}
\end{table}

```{r}
# components of vio index
pl_vio_tab1 <- rbind(placeboList[[2]][c(1,3),c(1:2,4)],
                     placeboList[[3]][c(1,3),c(1:2,4)],
                     placeboList[[4]][c(1,3),c(1:2,4)],
                     placeboList[[5]][c(1,3),c(1:2,4)],
                     placeboList[[6]][c(1,3),c(1:2,4)],
                     placeboList[[7]][c(1,3),c(1:2,4)])
colnames(pl_vio_tab1) <- c("coefficient", "p-value", "base")
rownames(pl_vio_tab1) <- c("Bring criminals to justice: Controlling-for", "Bring criminals to justice: Differencing",
                           "Defend ones group: Controlling-for", "Defend ones group: Differencing",
                           "Defend ones religion: Controlling-for", "Defend ones religion: Differencing",
                           "Force the government to change their policies: Controlling-for", "Force the government to change their policies: Differencing",
                           "Maintain culture and traditions: Controlling-for", "Maintain culture and traditions: Differencing",
                           "Retaliate against violence: Controlling-for", "Retaliate against violence: Differencing")
pl_vio_tab1 <- round(pl_vio_tab1,3)
pl_vio_tab1 <- knitr::kable(pl_vio_tab1, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:pl_vio_tab1}
\caption{\textbf{Community Placebo: Components of violence index.} Effect of ECPN on components of placebo index (attitudes towards violence) using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r pl_vio_tab1`
\end{center}
\end{table}


```{r}
# outgroup trust
pl_out_tab <- placeboList[[8]][c(1,3),c(1:2,4)]
colnames(pl_out_tab) <- c("coefficient", "p-value", "base")
rownames(pl_out_tab) <- c("Controlling-for", "Differencing")
pl_out_tab <- round(pl_out_tab,3)
pl_out_tab <- knitr::kable(pl_out_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:pl_out_tab}
\caption{\textbf{Community Placebo: Trust towards religious outgroups.} Effect of ECPN on placebo outcome using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r pl_out_tab`
\end{center}
\end{table}

```{r}
# radio listening
pl_rad_tab <- placeboList[[9]][c(1,3),c(1:2,4)]
colnames(pl_rad_tab) <- c("coefficient", "p-value", "base")
rownames(pl_rad_tab) <- c("Controlling-for", "Differencing")
pl_rad_tab <- round(pl_rad_tab,3)
pl_rad_tab <- knitr::kable(pl_rad_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:pl_rad_tab}
\caption{\textbf{Community Placebo: Radio listening frequency.} Effect of ECPN on placebo outcome using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r pl_rad_tab`
\end{center}
\end{table}

## Individual

```{r}
# vio
pl_vio_ind <- placeboList_ind[[1]][,c(1:2,4)]
colnames(pl_vio_ind) <- c("coefficient", "p-value", "base")
rownames(pl_vio_ind) <- c("Non: Controlling-for & ICW", "Part: Controlling-for & ICW", 
                                "Non: Controlling-for & Additive", "Part: Controlling-for & Additive",
                                "Non: Differencing & ICW", "Part: Differencing & ICW", 
                                "Non: Differencing & Additive", "Part: Differencing & Additive")
pl_vio_ind <- round(pl_vio_ind,3)
pl_vio_ind <- knitr::kable(pl_vio_ind, format="latex")
```

\begin{table}[H]
\begin{center}
\label{tab:pl_vio_ind}
\caption{\textbf{Individual Placebo: Attitudes towards violence index.} Effect of ECPN on placebo outcome using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r pl_vio_ind`
\end{center}
\end{table}


```{r}
# vio components
pl_vio_ind1 <- rbind(placeboList_ind[[2]][c(1,2,5,6),c(1:2,4)],
                     placeboList_ind[[3]][c(1,2,5,6),c(1:2,4)],
                     placeboList_ind[[4]][c(1,2,5,6),c(1:2,4)],
                     placeboList_ind[[5]][c(1,2,5,6),c(1:2,4)],
                     placeboList_ind[[6]][c(1,2,5,6),c(1:2,4)],
                     placeboList_ind[[7]][c(1,2,5,6),c(1:2,4)])
colnames(pl_vio_ind1) <- c("coefficient", "p-value", "base")
rownames(pl_vio_ind1) <- c("Non: Bring criminals to justice: Controlling-for", "Part: Bring criminals to justice: Controlling-for",
                           "Non: Bring criminals to justice: Differencing", "Part: Bring criminals to justice: Differencing",
                           "Non: Defend ones group: Controlling-for", "Part: Defend ones group: Controlling-for",
                           "Non: Defend ones group: Differencing", "Part: Defend ones group: Differencing",
                           "Non: Defend ones religion: Controlling-for", "Part: Defend ones religion: Controlling-for",
                           "Non: Defend ones religion: Differencing", "Part: Defend ones religion: Differencing",
                           "Non: Force the government to change their policies: Controlling-for", "Part: Force the government to change their policies: Controlling-for",
                           "Non: Force the government to change their policies: Differencing", "Part: Force the government to change their policies: Differencing",
                           "Non: Maintain culture and traditions: Controlling-for", "Part: Maintain culture and traditions: Controlling-for",
                           "Non: Maintain culture and traditions: Differencing", "Part: Maintain culture and traditions: Differencing",
                           "Non: Retaliate against violence: Controlling-for", "Part: Retaliate against violence: Controlling-for", 
                           "Non: Retaliate against violence: Differencing", "Part: Retaliate against violence: Differencing")
pl_vio_ind1 <- round(pl_vio_ind1,3)
pl_vio_ind1 <- knitr::kable(pl_vio_ind1, format="latex")
```

\begin{table}[H]
\begin{center}
\label{tab:pl_vio_ind1}
\caption{\textbf{Individual Placebo: Components of violence index.} Effect of ECPN on components of placebo index (attitudes towards violence) using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r pl_vio_ind1`
\end{center}
\end{table}


```{r}
# outgroup trust
pl_out_ind <- placeboList_ind[[8]][c(1,2,5,6),c(1:2,4)]
colnames(pl_out_ind) <- c("coefficient", "p-value", "base")
rownames(pl_out_ind) <- c("Non: Controlling-for", "Part: Controlling-for",
                          "Non: Differencing", "Part: Differencing")
pl_out_ind <- round(pl_out_ind,3)
pl_out_ind <- knitr::kable(pl_out_ind, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:pl_out_ind}
\caption{\textbf{Individual Placebo: Trust towards religious outgroups.} Effect of ECPN on placebo outcome using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r pl_out_ind`
\end{center}
\end{table}

```{r}
# outgroup trust
pl_rad_ind <- placeboList_ind[[8]][c(1,2,5,6),c(1:2,4)]
colnames(pl_rad_ind) <- c("coefficient", "p-value", "base")
rownames(pl_rad_ind) <- c("Non: Controlling-for", "Part: Controlling-for",
                          "Non: Differencing", "Part: Differencing")
pl_rad_ind <- round(pl_rad_ind,3)
pl_rad_ind <- knitr::kable(pl_rad_ind, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:pl_rad_ind}
\caption{\textbf{Individual Placebo: Radio listening frequency.} Effect of ECPN on placebo outcome using alternative methods of estimation and index construction. The first column shows coefficients from OLS regression, the second column shows $p$-values from randomization inference, and the third column shows which method was used in the paper.}
\smallskip
`r pl_rad_ind`
\end{center}
\end{table}

**********
\newpage

# Appendix F: State-level heterogeneous effects

This looks at heterogeneous effects by state. This is a low-power analysis.  There are no significant differences in treatment effect by state.

Coefficients and p-values estimating state-level heterogeneous effects were calculated with robust OLS regression using site-level clusters. The regression interacted the treatment indicator with the state indicator. Benue was the reference category so this table shows differences for Nasarawa.

```{r}
load("../data_and_code/survey_dat/d_analysis/state_list.Rda")
#stateList

state_tab <- rbind(stateList[[1]][4,c(2,3)],
                       stateList[[2]][4,c(2,3)],
                       stateList[[3]][4,c(2,3)],
                       stateList[[4]][4,c(2,3)],
                       stateList[[5]][4,c(2,3)],
                       stateList[[6]][4,c(2,3)],
                       stateList[[7]][4,c(2,3)])
colnames(state_tab) <- c("coefficient", "p-value")
rownames(state_tab) <- c("Attitudes", "Perceptions of security",
                          "Contact", "Percent Experiment",
                          "Endorsement Experiment",
                          "PGG donation", "PGG amount")
state_tab <- round(state_tab,3)
state_tab <- knitr::kable(state_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:state_tab}
\caption{\textbf{State-level differences in community-level analysis.} There are not significant differences between the effect of the contact intervention by state. The first column shows coefficients from OLS regression, the second column shows $p$-values from OLS regression.}
\smallskip
`r state_tab`
\end{center}
\end{table}

**********
\newpage

# Appendix G: Farmer-pastoralist differences

We show demographic differences between farmers and pastoralists. We also shows regressions using demographic characteristics as control variables to confirm that accounting for these variables does not change the study's results.

```{r}
load("../data_and_code/review/demo_tab_overall1.Rda")
load("../data_and_code/review/demo_tab_state1.Rda")

load("../data_and_code/review/comp_df1.Rda")
load("../data_and_code/review/comp_df_ind1.Rda")
```

\begin{table}[H]
\begin{center}
\label{tab:demo_tab_overall1}
\caption{\textbf{Farmer and Pastoralist Demographics} This table shows demographic characteristics for farming groups and pastoralist groups}
\smallskip
`r demo_tab_overall1`
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\label{tab:demo_tab_state1}
\caption{\textbf{Farmer and Pastoralist Demographics by State} This table shows demographic characteristics for farming groups and pastoralist groups, separating respondents from Nasarawa and Benue}
\smallskip
`r demo_tab_state1`
\end{center}
\end{table}


\begin{table}[H]
\begin{center}
\label{tab:comp_df1}
\caption{\textbf{Regressions with community-average demographic variables} This table shows coefficients from each survey regression either (1) the version in the paper that does not control for demographic characteristics, or (2) a regression that aggregated demographic characteristics to the community-level and included them as control variables. The coefficients are similar -- the sum of the coefficients when controlling for demographic characteristics is slightly larger.}
\smallskip
`r comp_df1`
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\label{tab:comp_df_ind1}
\caption{\textbf{Regressions with individual demographic variables} This table shows coefficients from each survey regression either (1) the version in the paper that does not control for demographic characteristics, or (2) a regression that includes individual-level demographic characteristics as control variables. The coefficients are similar -- the sum of the coefficients when controlling for demographic characteristics is slightly smaller.}
\smallskip
`r comp_df_ind1`
\end{center}
\end{table}

This looks at heterogeneous effects by group (farmers and pastoralists). This is a low-power analysis. There are no significant differences in treatment effect by farmer/pastoralist.

Coefficients and p-values estimating farmer/pastoralist heterogeneous effects were calculated with robust OLS regression using site-level clusters and fixed effects for state. The regression interacted the treatment indicator with the state indicator. Farmers were the reference category so this table shows differences for pastoralists.

```{r}
load("../data_and_code/survey_dat/d_analysis/farm_list.Rda")
#farmList

farm_tab <- rbind(farmList[[1]][3,c(2,3)],
                       farmList[[2]][3,c(2,3)],
                       farmList[[3]][3,c(2,3)],
                       farmList[[4]][3,c(2,3)],
                       farmList[[5]][3,c(2,3)],
                       farmList[[6]][3,c(2,3)],
                       farmList[[7]][3,c(2,3)])
colnames(farm_tab) <- c("coefficient", "p-value")
rownames(farm_tab) <- c("Attitudes", "Perceptions of security",
                          "Contact", "Percent Experiment",
                          "Endorsement Experiment",
                          "PGG donation", "PGG amount")
farm_tab <- round(farm_tab,3)
farm_tab <- knitr::kable(farm_tab, format="latex")

```

\begin{table}[H]
\begin{center}
\label{tab:farm_tab}
\caption{\textbf{Farmer-pastoralist differences in community-level analysis.} There are not significant differences between the effect of the contact intervention by farmer/pastoralist. The first column shows coefficients from OLS regression, the second column shows $p$-values from OLS regression.}
\smallskip
`r farm_tab`
\end{center}
\end{table}

**********
\newpage

# Appendix H: Survey Questions

**Attitudes**

- With regards to someone from [X GROUP], would you feel comfortable:
    - if they worked in your field?
    - paying them to watch your animals?
    - trading goods with them?
    - sharing a meal with them?
    - with a close relative marrying a person from [X GROUP]?
- From 1-5, how much do you trust people from [X GROUP] in your area?
- Now I’m going to ask you questions about your community here in Benue/Nassarawa, including [X GROUP].  Please tell me how strongly you agree/disagree with each of the following statements: People in this area can be trusted.

**Contact**

- Now I’m going to ask you questions about your contact with [X GROUP] in your area.
    - Think of the market you go to most frequently. During the past month, have members of X GROUP gone to that market too?  In the past month, how many times did you interact with X group in the market?
- In the past month, have you:
    - Joined a member of X group for a social event outside the home?  How often?
    - Hosted a member of X group for a ceremony in your home?  How often?
    - Gone to the home of a member of X group for a ceremony?  How often?
    - Have you interacted with members of X group in any other way in the past month?

**Insecurity**

- In the last year were there any areas that you avoided going to or through because of insecurity during the night? 
- In the last year were there any areas that you avoided going to or through because of insecurity, during the day?
- In the last year, did insecurity ever prevent you from: 
    - Working when you wanted to work? About how many days were you unable to work?
    - Going to the market?
    - Getting water for the household?
    - Going to your field/farm?
    - Moving your animals to grazing areas?
    - Moving your animals to water?
    - Earning money or going to work?
    - Going to school?

**Endorsement Experiment**

- Imagine that there is a proposal by [**the Farmer’s Cooperative Society**/**MACBAN**] for action to enhance access to clean water in rural areas.  Though expensive, the proposal aims to bring fresh, clean water to hundreds of areas without access to it, including this one.  If this were proposed, how would you feel about it?

**Percent Experiemnt**

- Think about groups that you might join in your leisure time.  Would you join a group that had **5/25/50/75**% X Group members?
- Think about the community you live in.  Would you live in a community that had **5/25/50/75**% X Group members?


**Violence Placebo**

- Now I am going to ask you some questions about the use of violence.  Is it always, sometimes, rarely, or never justified to use violence to do each of the following:
    - Retaliate against violence
    - Defend one's group
    - Maintain culture and traditions
    - Defend one's religion
    - Bring criminals to justice
    - Force the government to change their policies

**Public Goods Game**

"Thank you very much for participating in our survey.  Before I go, there is one last thing.  As you may have heard, we have development funds to use in this community.  We have randomly selected you as one of the 50 people to receive these funds.  These funds are not for a Mercy Corps project, but rather for you to keep personally or to donate to a community fund.   

We have 1,000 Naira to give to you.  It is yours, and you can use it either way--for yourself or for a community good.

Your community and [joint farmer/pastoralist community] have created a project committee to whom you can donate this money so that it may be used to help both communities.  The project committee has 4  people from each community.  We have found a donor that will match the funds that you all contribute to the project committee, so that if you donate 100 Naira the project committee receives 300 Naira, and if you donate all 1,000 Naira the project committee receives 3,000 Naira.  You are welcome to donate none, some, or all of the money to the project committee.

These are your individual donation envelopes.  All the donations will be private -- only you will know how much money you donated. It essential that you keep how much you give private -- please do not tell anyone.  I have with me a donation envelope to collect donations.  Please go into your home, put however much of the 1,000 Naira you wish to donate to the project committee in the envelope, take whatever amount you want to keep for yourself, and come back to place your envelope in the donation envelope.  Remember, you are welcome to donate none, some, or all of the money to the project committee.  After that we are finished and you may continue your day.  We will come back and publicly announce how much money your community's project committee will receive."

**********
\newpage

# Appendix I: Alternative explanations

It is possible that the effects of our intervention are due to impact of the development project around which the contact was organized, rather than intergroup contact itself. The effect could also be due to mediation provided to some community leaders. We ran three analyses to disentangle the effects of contact from the effects of the development projects and mediation.

## Effect of contact vs. effect of development projects

The first was to determine if treatment effects were significantly larger for communities where larger proportions of people were aware of, used, and perceived benefit from the projects. In treatment communities, we predicted outcome change with (1) awareness of boreholes, (2) use of boreholes, (3) awareness of quick-impact projects, and (4) perceived benefit from quick-impact projects. If treatment effects are due to development projects and not contact, we would expect larger effects where a greater proportion of respondents were aware of, used, and benefited from the development projects.

```{r}
load("../data_and_code/review/benefit_df.Rda")
load("../data_and_code/review/benefitVar_df.Rda")
load("../data_and_code/review/benefitVar_df_svy.Rda")

benefit_df_tab <- knitr::kable(benefit_df, format="latex")
benefitVar_df_tab <- knitr::kable(benefitVar_df, format="latex")
benefitVar_df_svy_tab <- knitr::kable(benefitVar_df_svy, format="latex")
```

Our analysis shows that awareness, use, and benefit from the projects is not significantly related to any outcome (the mean p-value is ~0.32). It's also not the case that any of those variables separately (awareness, use, and benefit) are related to improvements on any outcome. Though the p-values are insignificant, the mean t-statistic for the awareness/use/benefit variables is positive, possibly suggesting that the development projects, while not explaining the bulk of the treatment effect, may have increased the effect. The tables show the mean coefficient, $p$-value, and t-statistic for each outcome being predicted by each "benefit" variable.

\begin{table}[H]
\begin{center}
\label{tab:benefit_df_tab}
\caption{\textbf{Benefit variables affect on outcomes.} Mean coefficient, $p$-value, and t-statistic for each outcome, across benefit variables. Benefit variables are not significantly related to any outcome.}
\smallskip
`r benefit_df_tab`
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\label{tab:benefitVar_df_svy_tab}
\caption{\textbf{Benefit variables affect on outcomes.} Mean coefficient, $p$-value, and t-statistic for each benefit variables, across outcomes. This tables removes Public Goods Game outcomes because (1) their coefficients are on a different scale than the survey outcomes and (2) the coefficients and t-statistics are negative, which could hide the effect of benefit variables on the other outcomes. However, this table shows that benefit variables are not significantly related to any survey outcome.}
\smallskip
`r benefitVar_df_svy_tab`
\end{center}
\end{table}

Second, we looked at whether pastoralists in Benue differed from the rest of the sample. Pastoralists in Benue benefited least from the development projects (especially the main project that built boreholes) because they became displaced from where the boreholes were constructed prior to the endline survey. Here we (1) confirm that pastoralists in Benue were less likely to be aware of, use, or benefit from the development projects and (2) see no significant outcome differences between pastoralists in Benue and the rest of the sample (mean p-value ~0.58).

```{r}
load("../data_and_code/review/BenPast_Benefit.Rda")
load("../data_and_code/review/benPast_tab.Rda")

BenPast_Benefit_tab <- knitr::kable(BenPast_Benefit, format="latex")
benPast_tab <- knitr::kable(benPast_tab, format="latex")
```

\begin{table}[H]
\begin{center}
\label{tab:BenPast_Benefit_tab}
\caption{\textbf{Benefit pastoralists awareness and benefit from development projects.} Coefficients, t-statistics, and $p$-values comparing Benue pastoralists in the treatment group to the rest of the treatment group. Benue pastoralists were significantly less likely to be aware of the boreholes or use the boreholes; they were marginally less likely to be aware of the quick-impact projects.}
\smallskip
`r BenPast_Benefit_tab`
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\label{tab:benPast_tab}
\caption{\textbf{Benefit outcomes for pastoralists in the treatment group.} Coefficients, $p$-values, and t-statistics comparing Benue pastoralists in the treatment group to the rest of the treatment group. Treatment effects are not smaller among Benue pastoralists than the rest of the treatment group. Note: the mean coefficient excludes the Public Goods Game, which is on a different scale than the other variables; it is included in the $p$-value and t-statistic.}
\smallskip
`r benPast_tab`
\end{center}
\end{table}

## Effect of contact vs. effect of mediation

```{r}
load("../data_and_code/review/mediat_tab.Rda")
```

The third analysis concerned mediation.  While we cannot rule out that the effect was due to the meditation training, only 52 of the over 1000 endline respondents in treatment sites were aware of the mediation intervention.

\begin{table}[H]
\begin{center}
\label{tab:mediat_tab}
\caption{\textbf{Mediation Exposure.} Exposure to mediation in treatment and control sites in endline survey. Only 52 randomly selected respondents in treatment had any exposure to mediation. No control respondents had exposure to mediation.}
\smallskip
`r mediat_tab`
\end{center}
\end{table}

**********
\newpage

# Appendix J: Family-Wise Error Rate (FWER)

To control the FWER, we conducted within-family hypothesis corrections using the Holm correction.  For two of our outcomes (pastoralists in market and perceptions of insecurity), the findings remain statistically significant. For the two other outcomes (self-reported contact and attitudes), significance levels shift from statistically significant to marginally significant (.04 to .08). This means we have a significant $p$-value for our hypothesis families about intergroup contact and about insecurity; we have a marginally significant $p$-value for our hypothesis family about attitudes; we have no signifcant $p$-value for our hypothesis family about cooperation.

Note: the outcome measuring pastoralists in the market remains statistically significant even if using the bonferonni correction to correct for all (vs. within family) hypothesis tests in the analysis.

The exploratory individual-level data has only one outcome per family (except for the Cooperation family, for which no $p$-values were significant without correction). We therefore do not show "corrected" individual-level $p$-values.  If we put all individual-level hypotheses into a single family and use the Holm correction, the _Self-reported contact_ outcome changes from significant ($p$=0.018) to marginally significant($p$=0.088). None of the other outcomes were significant or marginally significant before correction.

```{r}
load("../data_and_code/review/holm_tab.Rda")
holm_tab <- knitr::kable(holm_tab, format="latex")
```

\begin{table}[H]
\begin{center}
\label{tab:holm_tab}
\caption{\textbf{P-values controlling the family-wise error rate.}}
\smallskip
`r holm_tab`
\end{center}
\end{table}

**********
\newpage

# Appendix K: Power Analysis

At community level, we could detect effects of ~0.60 SDs with 0.80 power. We expected better power for our actual analysis because our power analysis does not use randomization inference to generate true p-values.  We simulated our community-level power analysis with the following code.

```{r, eval=F, echo=T}
# using insecurity as the default outcome, as it is our strongest survey outcome at the community level. outcome_list_qip[2] = "in_cw".
bigPow.fn <-function(nsims, var=outcome_list_qip[2], tau)
{
  newPow.fn <- function(var, tau)
{
    # 6 TR sites from Nas, 4 from Ben
    newtr_nas <- sample(unique(ag.df$psu[ag.df$state %in% "nas"]), size=6)
    newtr_ben <- sample(unique(ag.df$psu[ag.df$state %in% "ben"]), size=4)
    newtr <- c(as.character(newtr_nas), as.character(newtr_ben))
    df <- ag.df
    df[,"newtr"] <- ifelse(df$psu %in% newtr, 1, 0)
  
  # make endline outcome with TR effect tau
  df[, paste0(var,"_end")] <- (df[,paste0(var,"_end")]-mean(df[,paste0(var,"_end")]))/sd(df[,paste0(var,"_end")])
  #scale(df[,paste0(var,"_end")])
  df[df$newtr %in% 1, paste0(var,"_end")] <- df[df$newtr %in% 1, paste0(var,"_end")]+tau
  
  # for baseline control, also scale
  df[, paste0(var,"_base")] <- (df[,paste0(var,"_base")]-mean(df[,paste0(var,"_base")]))/sd(df[,paste0(var,"_base")])
  
  # lm
  lm1 <- lm_robust(df[,paste0(var,"_end")]~df[,'newtr']+df[,paste0(var,"_base")]+state, 
                   clusters = psu, data=df)
  
  want <- tidy(lm1)[2,5]
  return(want)
  }
  
  check <- do(nsims)*newPow.fn(var=var, tau=tau)
  pval <- mean(check<0.05)
  return(pval)
}

# run power analysis for tau 0-1
possibleTaus <- seq(0,1,0.1)
possibleTaus <- as.data.frame(possibleTaus)
system.time(
for(i in 1:nrow(possibleTaus))
{
  possibleTaus[i, "pow"] <- bigPow.fn(nsims=3000, tau=possibleTaus[i,1])
}
)
possibleTaus

```

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{../data_and_code/review/power_figure.pdf}
\caption{Community-level power analysis.}\label{fig:pow_comm}
\end{figure}

At individual level, we could detect effects of ~0.40 SDs with 0.80 power. We expected better power for our actual analysis because our power analysis does not use randomization inference to generate true p-values. We used the [EGAP power calculator](https://egap.shinyapps.io/power-app/) for the individual-level power analysis.  The parameters were: Alpha = 0.05, Tau = 0.40 SD, ICC=0.05, 15 clusters per arm, up to 300 respondents per cluster.

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{../data_and_code/review/power_figure_ind.png}
\caption{Individual-level power analysis.}\label{fig:pow_ind}
\end{figure}

**********
\newpage

# Appendix L: Difference-in-differences plots

Many effects are driven by worsening conditions in control communities. Given the small number of control communities, it's possible that the effects could be driven by a particularly bad period in a single control community. It's also possible that there could be ceiling or floor effects. These plots show that (1) the effects are not driven by a large drop in a single control community/site and (2) the overall effect is not demonstrating a floor below which no community-site falls.

## Survey outcomes

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{../data_and_code/survey_dat/figs/did_plots/attitudeComm_plot.pdf}
\caption{Difference-in-differences plot comparing change in treatment to change in control.}\label{fig:att_comm}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{../data_and_code/survey_dat/figs/did_plots/attitudeComm.plot_disag.pdf}
\caption{Each point represents a community. This graph shows (1) that overall changes are not driven by a large change in a single community and (2) that the overall change does not reflect a ceiling or floor effect.}\label{fig:att_comm_dis}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{../data_and_code/survey_dat/figs/did_plots/finished_didPlots/conComm_plot.pdf}
\caption{Difference-in-differences plot comparing change in treatment to change in control.}\label{fig:con_comm}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{../data_and_code/survey_dat/figs/did_plots/conComm_plot_disag.pdf}
\caption{Each point represents a community. This graph shows (1) that overall changes are not driven by a large change in a single community and (2) that the overall change does not reflect a ceiling or floor effect.}\label{fig:con_comm_dis}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{../data_and_code/survey_dat/figs/did_plots/finished_didPlots/inComm_plot.pdf}
\caption{Difference-in-differences plot comparing change in treatment to change in control.}\label{fig:in_comm}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{../data_and_code/survey_dat/figs/did_plots/inComm_plot_disag.pdf}
\caption{Each point represents a community. This graph shows (1) that overall changes are not driven by a large change in a single community and (2) that the overall change does not reflect a ceiling or floor effect.}\label{fig:in_comm_dis}
\end{figure}

<!--
#Removing survey experiments because disaggregating them at comm-level is weird.
\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{../data_and_code/survey_dat/figs/did_plots/finished_didPlots/endComm_plot.png}
\caption{Difference-in-differences plot comparing change in treatment to change in control.}\label{fig:end_comm}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{../data_and_code/survey_dat/figs/did_plots/finished_didPlots/randComm_plot.png}
\caption{Difference-in-differences plot comparing change in treatment to change in control.}\label{fig:perc_comm}
\end{figure}
-->

## Behavioral outcomes

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{../data_and_code/obs_dat/b_analysis/market_pasts_TrTime.plot.png}
\caption{Difference-in-differences plot comparing change in treatment to change in control.}\label{fig:market_past_TrTime}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{../data_and_code/obs_dat/b_analysis/market_pasts_siteTime.plot.png}
\caption{Each point represents a site. This graph shows (1) that overall changes are not driven by a large change in a single community and (2) that the overall change does not reflect a ceiling or floor effect.}\label{fig:market_past_siteTime}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{../data_and_code/obs_dat/b_analysis/market_farms_TrTime.plot.png}
\caption{Difference-in-differences plot comparing change in treatment to change in control.}\label{fig:market_farm_TrTime}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{../data_and_code/obs_dat/b_analysis/market_farms_siteTime.plot.png}
\caption{Each point represents a site. This graph shows (1) that overall changes are not driven by a large change in a single community and (2) that the overall change does not reflect a ceiling or floor effect.}\label{fig:market_farm_siteTime}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{../data_and_code/obs_dat/b_analysis/event_outgroup_TrTime.plot.png}
\caption{Difference-in-differences plot comparing change in treatment to change in control.}\label{fig:market_past_TrTime}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{../data_and_code/obs_dat/b_analysis/events_outgroup_siteTime.plot.png}
\caption{Each point represents a site. This graph shows (1) that overall changes are not driven by a large change in a single community and (2) that the overall change does not reflect a ceiling or floor effect.}\label{fig:events_outgroup_siteTime}
\end{figure}



**********
\newpage

# Appendix M: Intervention and site-selection

## Intervention Details

To address the rising conflict in the Middle Belt in Nigeria, Mercy Corps implemented a four-year, USAID-funded program titled Engaging Communities for Peace in Nigeria, targeted at over 9,000 people at 10 Middle Belt sites (where a “site” is a location that contains two conflicting communities). The main objective of the program was to foster positive contact between farmers and pastoralists, with the aim of improving their attitudes toward and relationships with each other. The program included three interventions. 

The first intervention involved creating joint project committees in which farmers and pastoralists worked together to design and implement development projects that would address intergroup tensions. The process for selecting projects was similar to that of many community-driven development programs. It started with a series of community meetings, beginning with separate farmer and pastoralist meetings that built up to joint decision-making meetings with the two groups together on the project committees. Project committees met weekly during the dry season and bi-weekly during farming and harvest season. Each joint project committee included an even number of farmers and pastoralists, as well as women and youth representatives, and totaled between 12 and 15 members. 

Each committee received two grants, one for quick-impact projects, of approximately $2,000, and one for joint economic projects, of approximately $25,000. To inform the selection of projects, the project committees conducted a participatory needs assessment to gather the opinions of various demographic groups within their communities. The project committees then used this information, along with a conflict and resource mapping exercise, to identify resource-based drivers of conflict and select projects to implement with the grant money. The quick-impact projects were conceived as a trust-building initiative, intended to demonstrate that cooperation was possible and in the interest of both groups. Quick-impact projects, managed by both farmers and pastoralists, included hand pumps, construction or rehabilitation of market stalls and schools, rehabilitation of health centers, and construction of fences along grazing routes to protect farmlands. The joint economic projects aimed to address an underlying issue related to the conflict: sharing of scarce resources that impact livelihoods. Pollution of water, affecting both farming and livestock, was the primary issue people raised. As a result, each project committee decided to build a new borehole well, with the committee managing the project and with farmer and pastoralist youth helping to construct the wells. For most communities, the borehole was erected near the end of the 18 month program. 

The second intervention was training community leaders in how to mediate disputes so that conflict did not escalate into violence. To help alleviate violence, two joint committees were formed: peace and early warning / early response. In some venues, a peace committee was already in place. In those instances, we worked with the preexisting peace committee to ensure that it was balanced in terms of farmers and pastoralists, as well as gender. Over the course of the two years, 120 people were trained in mediation, and they went on to resolve 528 disputes around local grazing routes, seasonal access to water points, crop damage, cutting down of trees, and water pollution by animals. That said, only 52 of over 1000 respondents in the treatment group had exposure to mediation at endline. 

The third intervention was conflict prevention forums for the larger community, in which farmers and pastoralists came together to discuss issues and policies that were affecting them. Government officials also attended these events. Due to time, this aspect of the program was only lightly implemented. 

## Site Selection Details

The scoping exercise initially identified more than thirty potential implementation sites with a history of violence. The ECPN implementation team visited these sites to establish community need and obtain community consent for potentially becoming part of the ECPN program. From these visits we narrowed down the list of implementation sites to 24. These 24 sites received a preliminary survey of 10 individuals per farmer and pastoralist community to further identify need. This survey revealed one site that was too close geographically to a larger site, one site that was too remote for feasible implementation, and four sites did not fulfill our “demonstrated need” criteria. Of the remaining 18, three were lost before random assignment or implementation of the program. From the fifteen remaining sites, we randomly assigned ten to intervention, where ECPN would be implemented, and five to control, where ECPN would not be implemented.
