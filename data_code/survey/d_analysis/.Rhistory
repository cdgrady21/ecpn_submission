#ate_nbwt2 <- difference_in_means(Y~Z,blocks = b,data=dat2) #
#ate_nbwt3 <- lm_lin(Y~Z,covariates=~bF,data=dat2)
#ate_nbwt5 <- EstimateIWE(y="Y",treatment="Z",group="bF",controls=NULL,data=as.data.frame(dat2))
nbwtates<-c(simple_block, block_wts$coefficients[["Z"]]
)
nbwtates
#chris: remove chunk if not being used.
## Comparing the Standard Errors
## ate_nbwt1se <- sqrt(sum(datB$nbwt^2 * datB$estvartaub))
##
##nbwtses <- c(simple_block=ate_nbwt1se,
##             wts=ate_nbwt6$std.error[["Z"]])
## nbwtses
ate_hbwt1 <- simple_precis <- with(datB, sum(taub*hbwt01))
ate_hbwt4 <- precis_wts <- lm_robust(Y~Z,data=dat2,weights=hbwt3)
ate_hbwt2 <- fixed_effect <- lm_robust(Y~Z+bF,data=dat2)
#ate_hbwt3 <- lm_robust(Y~Z,fixed_effects=~bF,data=dat2) # identical to above but does not print block coefs
# ate_hbwt5 <- lm_robust(I(Y-ave(Y,b))~I(Z-ave(Z,b)),data=dat2) #demeaning
hbwtates<-c(simple_precis=ate_hbwt1,
precis_wts=ate_hbwt4$coefficients[["Z"]],
fixed_effects=ate_hbwt2$coefficients[["Z"]])
hbwtates
# chris: remove if not using.
## ate_hbwt1se <- sqrt(sum(datB$hbwt01^2 * datB$estvartaub))
##
## hbwtses <- c(simple_precis=ate_hbwt1se,
## 	     lmfe1=ate_hbwt2$std.error[["Z"]],
## 	     lmfe2=ate_hbwt3$std.error[["Z"]],
## 	     wts=ate_hbwt4$std.error[["Z"]],
## 	     demean=ate_hbwt5$std.error[[2]])
## hbwtses
##
## nbwtses
# Define estimators that can be repeated in the simulation below
estnowtHC2 <- declare_estimator(Y~Z, estimand=theestimand, model=lm_robust, label="Naive: Ignores Blocks, Design SE")
estnbwt1   <- declare_estimator(Y~Z, estimand=theestimand, model=difference_in_means, blocks = b,label="Block1: Diff Means Block Size Weights, Design SE")
nbwt_est_fun <- function(data){
data$newnbwt <- with(data,( Z/pib ) + ( (1-Z)/(1-pib) ) )
obj <-lm_robust(Y~Z,data=data,weights = newnbwt)
res <- tidy(obj) %>% filter(term=="Z")
return(res)
}
hbwt_est_fun <- function(data){
data$newnbwt <- with(data,( Z/pib ) + ( (1-Z)/(1-pib) ) )
data$newhbwt <-  with(data, newnbwt * ( pib * (1 - pib) ) )
obj <-lm_robust(Y~Z,data=data,weights = newhbwt)
res <- tidy(obj) %>% filter(term=="Z")
return(res)
}
estnbwt4   <- declare_estimator(handler = tidy_estimator(nbwt_est_fun), estimand=theestimand, label="Block2: Least Squares with Block Size Weights, Design SE")
esthbwt1   <- declare_estimator(Y~Z+bF, estimand=theestimand, model=lm_robust,label="Precis1: Precision Weights via Fixed Effects, Design SE")
#esthbwt2   <- declare_estimator(Y~Z, estimand=theestimand, model=lm_robust,fixed_effects=~bF,label=": Precision Weights via Demeaning, Design SE")
esthbwt3   <- declare_estimator(handler = tidy_estimator(hbwt_est_fun), estimand=theestimand,label="Precis2: Least Squares with Precision Weights, Design SE")
theestimators <- ls(patt="^est.*?wt")
theestimators
checkest <- sapply(theestimators,function(x){ get(x)(as.data.frame(dat2))[c("estimate","std.error")]})
checkest
thedesignPlusEstimators <- thedesign2 +
estnowtHC2 + estnbwt1 + estnbwt4 +
esthbwt1 + esthbwt3
#chris: remove if not using.
## Verifying that this works with a fixed population
## datv1 <- draw_data(thedesign)
##datv2 <- draw_data(thedesign)
##table(datv1$Z,datv2$Z)
## Create block sizes and create block weights
#B <- 10 # Number of blocks # already created above.
set.seed(2201)
# simulate random assignment to block and treatment using same N from above
dat_pr <- data.frame(b=sample(1:10, nrow(dat2), replace=T))
dat_pr$bF <- factor(dat_pr$b)
dat_pr <- dat_pr[order(dat_pr$b),] # not necessary but maintains order from previous section
## x1 is a covariate that strongly predicts the outcome without treatment
dat_pr <- group_by(dat_pr,b) %>% mutate(nb=n(),
x1=rpois(n = nb,lambda=runif(1,min=1,max=2000)))
## The treatment effect varies by size of block (using sqrt(nb) because nb has such a large range.)
dat_pr <- group_by(dat_pr,b) %>% mutate(y0=sd(x1)*x1+rchisq(n=nb,df=1),
y0=y0*(y0>quantile(y0,.05)),
tauib = -(sd(y0))*sqrt(nb)  + rnorm(n(),mean=0,sd=sd(y0)),
y1=y0+tauib/50, # /50 to try and get less than 1.0 power.
y1=y1*(y1>0))
blockpredpower_pr <- summary(lm(y0~bF,data=dat_pr))$r.squared
## Setting up Declare Design:
thepop_pr <- declare_population(dat_pr)
#po_function <- function(data){  # already created
#	data$Y_Z_0 <- data$y0
#	data$Y_Z_1 <- data$y1
#	data
#}
theys_pr  <- declare_potential_outcomes(handler = po_function) # chris: identical to above
theestimand_pr <- declare_estimand(ATE = mean(Y_Z_1 - Y_Z_0)) # chris: identical to above
# declare_assignment doesn't do random assignment if declare_population comes from existing data.
## instead, it makes forces 50% of each block is in TR and in CO.
#theassign_pr <- declare_assignment(blocks=bF, prob=0.5)
test <- dat_pr %>% group_by(bF) %>%
mutate(n=n(),
t=sample(0:1,n,replace=T))
numtreated_pr <- table(test$t, test$bF)[2,]
theassign_pr <- declare_assignment(blocks=bF, block_m=numtreated_pr)
theobsident_pr <- declare_reveal(Y, Z) # chris: identical to above
thedesign_pr <- thepop_pr + theassign_pr + theys_pr + theestimand_pr + theobsident_pr
set.seed(2201)
dat2_pr <- draw_data(thedesign_pr)
table(dat2_pr$Z, dat2_pr$bF)
## Add probability of being treated to the data so weights can be calculated later.
dat2_pr <- dat2_pr %>% group_by(b) %>% mutate(nb = n(), ## Size of block
pib=mean(Z), ## prob of treatment assignment
nTb=sum(Z), ## Number treated
nCb=nb - nTb) ## Number control
# New pop and design that includes these new columns.
thepop2_pr <- declare_population(dat2_pr) #chris: ask Jake why we are declaring population twice.  Why couldn't we add weights to the original "thepop"? ## note I see now that it is because we want the Z variable to come from DeclareDesign.
thedesign2_pr <- thepop2_pr + theys_pr + theestimand_pr + theassign_pr + theobsident_pr
## And create the block level dataset, with block level weights.
datB_pr <- group_by(dat2_pr,b) %>% summarize(taub = mean(Y[Z==1]) - mean(Y[Z==0]),
truetaub = mean(y1) - mean(y0),
nb = n(),
nTb = sum(Z),
nCb = nb - nTb,
estvartaub =  (nb/(nb-1)) * ( var(Y[Z==1]) / nTb )  + ( var(Y[Z==0])/nCb ) ,
pb=mean(Z), # proportion treated
nbwt = unique(nb/nrow(dat2_pr)),
pbwt = pb * ( 1 - pb),
hbwt2 = nbwt * pbwt,
hbwt5 = pbwt * nb,
hbwt= ( 2*( nCb * nTb ) / (nTb + nCb)))
datB$greenlabrule <- 20*datB$hbwt5/sum(datB$hbwt5)
# Define estimators that can be repeated in the simulation below
estnowtHC2_pr <- declare_estimator(Y~Z, estimand=theestimand_pr, model=lm_robust, label="Naive: Ignores Blocks, Design SE")
estnbwt1_pr   <- declare_estimator(Y~Z, estimand=theestimand_pr, model=difference_in_means, blocks = b,label="Block1: Diff Means Block Size Weights, Design SE")
nbwt_est_fun <- function(data){ # chris: already created above, so could comment out/delete
data$newnbwt <- with(data,( Z/pib ) + ( (1-Z)/(1-pib) ) )
obj <-lm_robust(Y~Z,data=data,weights = newnbwt)
res <- tidy(obj) %>% filter(term=="Z")
return(res)
}
hbwt_est_fun <- function(data){ # chris: already created above, so could comment out/delete
data$newnbwt <- with(data,( Z/pib ) + ( (1-Z)/(1-pib) ) )
data$newhbwt <-  with(data, newnbwt * ( pib * (1 - pib) ) )
obj <-lm_robust(Y~Z,data=data,weights = newhbwt)
res <- tidy(obj) %>% filter(term=="Z")
return(res)
}
estnbwt4_pr   <- declare_estimator(handler = tidy_estimator(nbwt_est_fun), estimand=theestimand_pr, label="Block2: Least Squares with Block Size Weights, Design SE")
esthbwt1_pr  <- declare_estimator(Y~Z+bF, estimand=theestimand_pr, model=lm_robust,label="Precis1: Precision Weights via Fixed Effects, Design SE")
#esthbwt2_pr   <- declare_estimator(Y~Z, estimand=theestimand_pr, model=lm_robust,fixed_effects=~bF,label=": Precision Weights via Demeaning, Design SE")
esthbwt3_pr   <- declare_estimator(handler = tidy_estimator(hbwt_est_fun), estimand=theestimand_pr,label="Precis2: Least Squares with Precision Weights, Design SE")
theestimators_pr <- paste0(theestimators, "_pr") # chris: created in previous section.
checkest_pr <- sapply(theestimators_pr,function(x){ get(x)(as.data.frame(dat2_pr))[c("estimate","std.error")]})
checkest_pr #chris: data structure maybe too simple because all of these give same estimate.
thedesignPlusEstimators_pr <- thedesign2_pr +
estnowtHC2_pr + estnbwt1_pr + estnbwt4_pr +
esthbwt1_pr + esthbwt3_pr
plan(sequential)
sims <- 1000
set.seed(12345)
thediagnosis_pr <- diagnose_design(thedesignPlusEstimators_pr, sims = sims, bootstrap_sims = 0)
## See https://haozhu233.github.io/kableExtra/awesome_table_in_html.html
kable(reshape_diagnosis(thediagnosis_pr)[c(3,1,2,4,5),diagcols] ) # %>% kable_styling() %>% scroll_box(width = "100%", height = "600px")
diagcols <- c(3,5,6,7,8,9,10,11)
## See https://haozhu233.github.io/kableExtra/awesome_table_in_html.html
kable(reshape_diagnosis(thediagnosis_pr)[c(3,1,2,4,5),diagcols] ) # %>% kable_styling() %>% scroll_box(width = "100%", height = "600px")
## Create block sizes and create block weights
B <- 10 # Number of blocks
dat <- data.frame(b=rep(1:B,c(8,20,30,40,50,60,70,80,100,800)))
dat$bF <- factor(dat$b)
set.seed(2201)
## x1 is a covariate that strongly predicts the outcome without treatment
dat <- group_by(dat,b) %>% mutate(nb=n(),
x1=rpois(n = nb,lambda=runif(1,min=1,max=2000)))
## The treatment effect varies by size of block (using sqrt(nb) because nb has such a large range.)
dat <- group_by(dat,b) %>% mutate(y0=sd(x1)*x1+rchisq(n=nb,df=1),
y0=y0*(y0>quantile(y0,.05)),
tauib = -(sd(y0))*sqrt(nb)  + rnorm(n(),mean=0,sd=sd(y0)),
y1=y0+tauib/40,
y1=y1*(y1>0))
blockpredpower <- summary(lm(y0~bF,data=dat))$r.squared
# Chris: need to simplify these code chunks so that people know how to use them.
## definitely remove all the multiple ways to calc weights
### first figure out why the nbwt's at ind level are different.
## maybe make the dat and then aggregate to block-level stuff right away?
## Using Declare Design to ensure that the data here and the simulations below match
## Setting up Declare Design:
thepop <- declare_population(dat)
po_function <- function(data){
data$Y_Z_0 <- data$y0
data$Y_Z_1 <- data$y1
data
}
theys  <- declare_potential_outcomes(handler = po_function)
theestimand <- declare_estimand(ATE = mean(Y_Z_1 - Y_Z_0))
numtreated <- sort(unique(dat$nb))/rep(c(2,10),B/2)
theassign <- declare_assignment(blocks = bF, assignment_variable="Z",
block_m=numtreated) ##sort(unique(data$nb))/rep(c(2,10),B/2))
theobsident <- declare_reveal(Y, Z)
thedesign <- thepop + theys + theestimand + theassign + theobsident
set.seed(2201)
dat2 <- draw_data(thedesign)
## Adding rank transformed outcomes for use later.
dat2 <- dat2 %>% group_by(b) %>% mutate(y0md = y0 - mean(y0),
y1md = y1 - mean(y1),
alignedY = Y - mean(Y),
rankalignedY = rank(alignedY)
)
## Now add individual level weights to the data. Different textbooks and algebra yield different expressions. We show that they are all the same.
dat2 <- dat2 %>% group_by(b) %>% mutate(nb = n(), ## Size of block
pib=mean(Z), ## prob of treatment assignment
nTb=sum(Z), ## Number treated
nCb=nb - nTb, ## Number control
nbwt2 = nb/nrow(dat2), # the intuitive way to calc block-size weights
nbwt =  ( Z/pib ) + ( (1-Z)/(1-pib) ), # gerber and green block-size weight counterintuitively using prob of treatment
hbwt = 2 * (nCb * nTb )  / (nTb + nCb), ## Precision weight/Harmonic
hbwt2 = 2 * ( nbwt2 )*(pib*(1-pib)),
hbwt3 =  nbwt * ( pib * (1 - pib) ) )
#chris: note that hbwt and hbwt2 were commented out.  They are equivalent to each other, but not equivalent to hbwt3. hbwt is the way I understand precision weights but I am not sure how/why the others are different.
dat2$nbwt3 <- dat2$nbwt2/dat2$nb #chris: ask Jake about this because this looks like unweighting
thepop2 <- declare_population(dat2) #chris: ask Jake why we are declaring population twice.  Why couldn't we add weights to the original "thepop"? ## note I see now that it is because we want the Z variable to come from DeclareDesign.
thedesign2 <- thepop2 + theys + theestimand + theassign + theobsident
## And create the block level dataset, with block level weights.
datB <- group_by(dat2,b) %>% summarize(taub = mean(Y[Z==1]) - mean(Y[Z==0]),
truetaub = mean(y1) - mean(y0),
nb = n(),
nTb = sum(Z),
nCb = nb - nTb,
estvartaub =  (nb/(nb-1)) * ( var(Y[Z==1]) / nTb )  + ( var(Y[Z==0])/nCb ) ,
pb=mean(Z), # proportion treated
nbwt = unique(nb/nrow(dat2)),
pbwt = pb * ( 1 - pb),
hbwt2 = nbwt * pbwt,
hbwt5 = pbwt * nb,
hbwt= ( 2*( nCb * nTb ) / (nTb + nCb)))
datB$greenlabrule <- 20*datB$hbwt5/sum(datB$hbwt5)
## Notice that all of these different ways to express the harmonic mean weight are the same.
datB$hbwt01 <- datB$hbwt/sum(datB$hbwt)
datB$hbwt201 <- datB$hbwt2/sum(datB$hbwt2)
datB$hbwt501 <- datB$hbwt5/sum(datB$hbwt5)
stopifnot(all.equal(datB$hbwt01,datB$hbwt201))
stopifnot(all.equal(datB$hbwt01,datB$hbwt501))
## What is the "true" ATE?
trueATE1 <- with(dat2,mean(y1) - mean(y0))
trueATE2 <- with(datB, sum(truetaub*nbwt))
stopifnot(all.equal(trueATE1,trueATE2))
## We could define the following as an estimand, too. But it is a bit weird.
## trueATE3 <- with(datB, sum(truetaub*hbwt01))
## c(trueATE1,trueATE2,trueATE3)
## We can get the same answer using R's weighted.mean command
trueATE2b <- weighted.mean(datB$truetaub,w=datB$nbwt)
stopifnot(all.equal(trueATE2b,trueATE2))
with(dat2,table(treatment=Z,blocknumber=b))
### Block size weighting
ate_nbwt1 <- simple_block <- with(datB,sum(taub*nbwt))
ate_nbwt6a <- block_wts <- lm(Y~Z,data=dat2,weights=nbwt)
#lm(Y~Z,data=dat2,weights=nbwt2) #chris: hmm, diff way of calcing the ind-level weight gives diff answer...
ate_nbwt6 <- block_wts_robust <- lm_robust(Y~Z,data=dat2,weights=nbwt)
ate_nbwt6ase <- block_wts_hc2 <- coeftest(ate_nbwt6a,vcov=vcovHC(ate_nbwt6a,type="HC2"))
##### other methods from footnote
#ate_nbwt2 <- difference_in_means(Y~Z,blocks = b,data=dat2) #
#ate_nbwt3 <- lm_lin(Y~Z,covariates=~bF,data=dat2)
#ate_nbwt5 <- EstimateIWE(y="Y",treatment="Z",group="bF",controls=NULL,data=as.data.frame(dat2))
nbwtates<-c(simple_block, block_wts$coefficients[["Z"]]
)
nbwtates
#chris: remove chunk if not being used.
## Comparing the Standard Errors
## ate_nbwt1se <- sqrt(sum(datB$nbwt^2 * datB$estvartaub))
##
##nbwtses <- c(simple_block=ate_nbwt1se,
##             wts=ate_nbwt6$std.error[["Z"]])
## nbwtses
ate_hbwt1 <- simple_precis <- with(datB, sum(taub*hbwt01))
ate_hbwt4 <- precis_wts <- lm_robust(Y~Z,data=dat2,weights=hbwt3)
ate_hbwt2 <- fixed_effect <- lm_robust(Y~Z+bF,data=dat2)
#ate_hbwt3 <- lm_robust(Y~Z,fixed_effects=~bF,data=dat2) # identical to above but does not print block coefs
# ate_hbwt5 <- lm_robust(I(Y-ave(Y,b))~I(Z-ave(Z,b)),data=dat2) #demeaning
hbwtates<-c(simple_precis=ate_hbwt1,
precis_wts=ate_hbwt4$coefficients[["Z"]],
fixed_effects=ate_hbwt2$coefficients[["Z"]])
hbwtates
# chris: remove if not using.
## ate_hbwt1se <- sqrt(sum(datB$hbwt01^2 * datB$estvartaub))
##
## hbwtses <- c(simple_precis=ate_hbwt1se,
## 	     lmfe1=ate_hbwt2$std.error[["Z"]],
## 	     lmfe2=ate_hbwt3$std.error[["Z"]],
## 	     wts=ate_hbwt4$std.error[["Z"]],
## 	     demean=ate_hbwt5$std.error[[2]])
## hbwtses
##
## nbwtses
# Define estimators that can be repeated in the simulation below
estnowtHC2 <- declare_estimator(Y~Z, estimand=theestimand, model=lm_robust, label="Naive: Ignores Blocks, Design SE")
estnbwt1   <- declare_estimator(Y~Z, estimand=theestimand, model=difference_in_means, blocks = b,label="Block1: Diff Means Block Size Weights, Design SE")
nbwt_est_fun <- function(data){
data$newnbwt <- with(data,( Z/pib ) + ( (1-Z)/(1-pib) ) )
obj <-lm_robust(Y~Z,data=data,weights = newnbwt)
res <- tidy(obj) %>% filter(term=="Z")
return(res)
}
hbwt_est_fun <- function(data){
data$newnbwt <- with(data,( Z/pib ) + ( (1-Z)/(1-pib) ) )
data$newhbwt <-  with(data, newnbwt * ( pib * (1 - pib) ) )
obj <-lm_robust(Y~Z,data=data,weights = newhbwt)
res <- tidy(obj) %>% filter(term=="Z")
return(res)
}
estnbwt4   <- declare_estimator(handler = tidy_estimator(nbwt_est_fun), estimand=theestimand, label="Block2: Least Squares with Block Size Weights, Design SE")
esthbwt1   <- declare_estimator(Y~Z+bF, estimand=theestimand, model=lm_robust,label="Precis1: Precision Weights via Fixed Effects, Design SE")
#esthbwt2   <- declare_estimator(Y~Z, estimand=theestimand, model=lm_robust,fixed_effects=~bF,label=": Precision Weights via Demeaning, Design SE")
esthbwt3   <- declare_estimator(handler = tidy_estimator(hbwt_est_fun), estimand=theestimand,label="Precis2: Least Squares with Precision Weights, Design SE")
theestimators <- ls(patt="^est.*?wt")
theestimators
checkest <- sapply(theestimators,function(x){ get(x)(as.data.frame(dat2))[c("estimate","std.error")]})
checkest
thedesignPlusEstimators <- thedesign2 +
estnowtHC2 + estnbwt1 + estnbwt4 +
esthbwt1 + esthbwt3
#chris: remove if not using.
## Verifying that this works with a fixed population
## datv1 <- draw_data(thedesign)
##datv2 <- draw_data(thedesign)
##table(datv1$Z,datv2$Z)
plan(sequential)
sims <- 1000
set.seed(12345)
thediagnosis <- diagnose_design(thedesignPlusEstimators, sims = sims, bootstrap_sims = 0)
## See https://haozhu233.github.io/kableExtra/awesome_table_in_html.html
kable(reshape_diagnosis(thediagnosis)[c(3,1,2,4,5),diagcols] ) # %>% kable_styling() %>% scroll_box(width = "100%", height = "600px")
25*10
250*12
21*81
217/14371
.01^30
10000*30
(2^30)/100
(1+2^29)/100
((1+2^29)/100) - (10000*30)
(((1+2^29)/100)*2) - (10000*30)
50*.25
.03*1806
2000000000*.01
10/1600
10/850
install.packages("rmarkdown")
install.packages("qdap")
text <- "Text mining usually involves the process of structuring the input text. The overarching goal is, essentially, to turn text into data for analysis, via application of natural language processing (NLP) and analytical methods."
frequent_terms <- freq_terms(text, 3)
library(qdap)
frequent_terms <- freq_terms(text, 3)
frequent_terms <- qdap::freq_terms(text, 3)
1+9+3+8
21/4
200*80
20*360
28*360
30000/160
500*160
300*160
200*30
300*30
300*20
6000*12
30*18*28
30*18*28*3
160/3
300*55
300*160
330*6
1980/20
330/20
# 20 enumerators,
test <- 1:6
?sample
# 20 enumerators,
test <- sample(1:6, size=20, replace=T)
test
?rep
x <- rep(sample(1:6, size=20, replace=T),20)
x
once <- mosaic::do(20)*(sample(1:6, size=20, replace=T))
once
# 20 enumerators,
test.fun <- function()
{
once <- mosaic::do(20)*(sample(1:6, size=20, replace=T))
}
dists <- mosaic::do(1000)*test.fun()
summary(dists$V1)
dists[1:5,1:5]
dim(dists)
dists <- mosaic::do(1000)*(sample(1:6, size=20, replace=T))
dim(dists)
sample(1:6, size=100, replace=T)
# 20 enumerators = 100 svys each, sorted into 6 groups
dists <- mosaic::do(1000)*(sample(1:6, size=100, replace=T))
dim(dists)
summary(dists[,1;10])
summary(dists[,1:10])
summary(dists[1:20,1:10])
335*6
2000/20
100/6
mode(dists[1:20,1:10])
Modes <- function(x) {
ux <- unique(x)
tab <- tabulate(match(x, ux))
ux[tab == max(tab)]
}
Modes(dists[1:20,1:10])
Modes(dists[1,1:10])
Modes(dists[1:20,1])
Modes(dists[1:20,2])
Modes(dists[1:20,3])
8^6
(8^6)*4
2^9
1316/4
(1316/4)/7
20*700
2020-63
1989+16
13927-6300
10000*200
90/7
1200*300000000
n=3+4+3+3+5+14+31+44+43+39+30+27+24+18+15+11+9+8+5+4+1
n
341/21
80-(11.96*3)
11.96*3
36+59
63*.77
400000*1.03
400000*1.33
10000*750
10000/(137000+120000)
20000*1.1
20000*.1
2000*.65
100000/725
100000/750
15/1000
100*(2.89)^25
100*(2.89^25)
100*2.89
100*1.0289
100*(1.0289^25)
100*(1.0289^24)
.09*.09
1-(.09*.09)
133/176
152/215
1000/360
setwd("C:/Users/cdgra/Google Drive/Africa/Nigeria - Farmer-Pastoralist/ecpn_work/analysis/academicPaper/survey/b_creating_outcomes")
library(estimatr)
library(dplyr)
rm(list=ls())
load("../a_cleaning/c_dataCombine.Rdata")
summary(df$income_month)
summary(df$income_year)
median(df$income_year)
1000/median(df$income_year)
1000/(median(df$income_year)/365)
1000/(median(base$income_year)/365)
1000/(median(end$income_year)/365)
summary(df$income_year)
summary(base$income_year)
summary(end)
summary(df$income_year)
summary(base$income_year)
summary(end$income_year)
setwd("C:/Users/cdgra/Google Drive/Africa/Nigeria - Farmer-Pastoralist/ecpn_work/analysis/academicPaper/survey/d_analysis")
rm(list=ls())
load("../c_creating_dataframes/f-aggregateComms_ap.Rdata")
load("../c_creating_dataframes/rand_df.Rdata")
summary(ag.df$income_month)
summary(ag.df$income_month_base)
summary(ag.df$income_month_end)
27024-25515
lm(income_month_base~tr)
lm(income_month_base~tr, data=df)
lm(income_month_base~treatment, data=df)
lm(income_month_base~treatment, data=ag.df)
lm_robust(income_month_base~treatment, data=ag.df)
summary(lm(income_month_base~treatment, data=ag.df))
lm(income_month_end~treatment*income_month_base, data=ag.df)
summary(lm(income_month_end~treatment*income_month_base, data=ag.df))
summary(lm(income_month~treatment, data=ag.df))
library(mosaic)
mosaic::mean(ag.df$income_month_base~ag.df$treatment)
mosaic::mean(ag.df$income_month_end~ag.df$treatment)
8*8*365
8*8*(365*(5/7))
setwd("C:/Users/cdgra/Google Drive/Africa/Nigeria - Farmer-Pastoralist/ecpn_work/analysis/academicPaper/survey/d_analysis")
rm(list=ls())
load("../c_creating_dataframes/f-aggregateComms_ap.Rdata")
load("../c_creating_dataframes/rand_df.Rdata")
table(ag.df$state, ag.df$treatment)
4/6
8/12
4/6
6/3
3/6
4/6
6/9
3000/7500
8*6
1680+48
240000/1730
240000/1850
540*130
load("C:/Users/cdgra/Dropbox/CG-NC projects/academic_projects_joint/MuslimBan/data/A-arewa_data_recode.Rda")
load("C:/Users/cdgra/Dropbox/CG-NC projects/academic_projects_joint/MuslimBan/data/A-arewa_data_recode.Rda")
names(base)
