---
title: "f-aggregateComms"
author: "cdgrady21"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
load("e-makeIndices.Rdata")
library(plyr)
library(dplyr)
library(estimatr)
```

chris: note: the "violence_effect_num" variable that is the mean of the "vio[1-9]_" variables should probably be combined into an index with ICW, not just the mean.  Same for Insecurty/Conflict.


# Functions

From Cyrus Samii for IC weighting and factor analysis.

```{r}
## from cyrus samii IC weighting

# Function to standardize columns of a matrix
# where you designate a standardization group
# (e.g., the control group in an experiment)
# with "sgroup", a logical vector.

matStand <- function(x, sgroup = rep(TRUE, nrow(x))){
  for(j in 1:ncol(x)){
    x[,j] <- (x[,j] - mean(x[sgroup,j]))/sd(x[sgroup,j]) # chris: demeans outcome, but by control group mean, not x group mean?  Then divides by control group sd, which I get.  But why demean by control group mean even for tr group members?
  }
  return(x)
}

# Function that takes in data in matrix format and returns
# (i) IC weights and (ii) ICW index.
# Weights can be incorporated using the "wgts" argument.
# The "revcols" argument takes a vector indicating which columns,
# if any, should have values reversed (that is, standardized 
# values are multiplied by -1) prior to construction of the index. 

icwIndex <- function(	xmat,
                      wgts=rep(1, nrow(xmat)),
                      revcols = NULL,
                      sgroup = rep(TRUE, nrow(xmat))){
  X <- matStand(xmat, sgroup)
  if(length(revcols)>0){
    X[,revcols] <-  -1*X[,revcols]
  }
  i.vec <- as.matrix(rep(1,ncol(xmat)))
  Sx <- cov.wt(X, wt=wgts)[[1]]
  weights <- solve(t(i.vec)%*%solve(Sx)%*%i.vec)%*%t(i.vec)%*%solve(Sx)
  index <- t(solve(t(i.vec)%*%solve(Sx)%*%i.vec)%*%t(i.vec)%*%solve(Sx)%*%t(X))
  return(list(weights = weights, index = index))
}

# Factor analysis function (R base does not have one. factanal() is MLE, which we don't want.) 
#source("http://www.stat.sc.edu/~habing/courses/530/fact.txt")
```

# Clear out the panel people

First remove preselected ppl.

```{r}
# removing panel people/preselected
rand.df <- df[!df$pre_selected %in% 'pre',]

# drop community 21f & comm 30, who we did not survey at endline
rand.df <- droplevels(rand.df[!rand.df$community %in% c("20f1", "30.farmers", "30.pastoralists"),])

# make var to indicate control group for ICW
rand.df$control <- ifelse(rand.df$treatment == 1, 0, 1)
```

# Inverse Covariance Weighted Indices, Factors

Testing.

```{r, eval=F}
# cannot have any NAs.
#x <- na.omit(rand.df[,xVars])
#cor(x)
# should replace NA with mean for the column??
x <- rand.df[,xVars]
x <- zoo::na.aggregate(x)
out_cw <- icwIndex(x)
cor(x)
out_cw$weights
rand.df$x_cw <- as.vector(out_cw$index)

cor(na.omit(rand.df[,c("x_cw", "x_index")])) # super highly correlated.


# Now, only using control group for ICW
x <- rand.df[,xVars]
x <- zoo::na.aggregate(x)
out_cw <- icwIndex(xmat=x, sgroup=as.logical(rand.df[,'control']))
cor(x)
out_cw$weights
rand.df$x_cw <- as.vector(out_cw$index)

cor(na.omit(rand.df[,c("x_cw", "x_index")])) # super highly correlated.
```

Functions

```{r}
# both tr and co
ic.fun1 <- function(vars, thedf)
{
  x <- thedf[,vars]
  x <- zoo::na.aggregate(x)
  out_cw <- icwIndex(x)
  print(cor(x))
  print(out_cw$weights)
  return(as.vector(out_cw$index))
}


# just co
ic.fun <- function(vars, thedf)
{
  x <- thedf[,vars]
  x <- zoo::na.aggregate(x)
  out_cw <- icwIndex(xmat=x, sgroup=as.logical(thedf[,'control']))
  print(cor(x))
  print(out_cw$weights)
  return(as.vector(out_cw$index))
}
```

Doing.

```{r}
# want separate baseline & endline indices
rand.df1 <- rand.df[rand.df$survey %in% 0,]
rand.df2 <- rand.df[rand.df$survey %in% 1,]

# should loop but feeling braindead
# Baseline
rand.df1$x_cw <- ic.fun(xVars, rand.df1)
rand.df1$out_cw <- ic.fun(outVars, rand.df1)
rand.df1$clash_cw <- ic.fun(clashVars[c(1,2,4)], rand.df1)
rand.df1$contact_cw <- ic.fun(contactVars, rand.df1)
rand.df1$contactOnly_cw <- ic.fun(contactVars[c(1:4,7)], rand.df1)
rand.df1$bene_cw <- ic.fun(beneVarsPerc, rand.df1)
rand.df1$threatIn_cw <- ic.fun(threatInVars, rand.df1)
rand.df1$threat_cw <- ic.fun(threatVars, rand.df1)
rand.df1$in_cw <- ic.fun(inVars, rand.df1)
rand.df1$cohes_cw <- ic.fun(cohesVars, rand.df1)
rand.df1$cohes1_cw <- ic.fun(cohesVars1, rand.df1)
rand.df1$cohes2_cw <- ic.fun(cohesVars2, rand.df1)
rand.df1$dis_cw <- ic.fun(disVars, rand.df1)
rand.df1$share_cw <- ic.fun(shareVars, rand.df1)
rand.df1$numDis_cw <- ic.fun(numDisVars, rand.df1)
rand.df1$resolve_cw <- ic.fun(resolveVars, rand.df1)
rand.df1$disActor_cw <- ic.fun(disActorVars, rand.df1)
rand.df1$vio_cw <- ic.fun(vioVars, rand.df1)
rand.df1$vioExp_cw <- ic.fun(vioExpVars, rand.df1)

# Endline
rand.df2$x_cw <- ic.fun(xVars, rand.df2)
rand.df2$out_cw <- ic.fun(outVars, rand.df2)
rand.df2$clash_cw <- ic.fun(clashVars[c(1,2,4)], rand.df2)
rand.df2$contact_cw <- ic.fun(contactVars, rand.df2)
rand.df2$contactOnly_cw <- ic.fun(contactVars[c(1:4,7)], rand.df2)
rand.df2$bene_cw <- ic.fun(beneVarsPerc, rand.df2)
rand.df2$threatIn_cw <- ic.fun(threatInVars, rand.df2)
rand.df2$threat_cw <- ic.fun(threatVars, rand.df2)
rand.df2$in_cw <- ic.fun(inVars, rand.df2)
rand.df2$cohes_cw <- ic.fun(cohesVars, rand.df2)
rand.df2$cohes1_cw <- ic.fun(cohesVars1, rand.df2)
rand.df2$cohes2_cw <- ic.fun(cohesVars2, rand.df2)
rand.df2$dis_cw <- ic.fun(disVars, rand.df2)
rand.df2$share_cw <- ic.fun(shareVars, rand.df2)
rand.df2$numDis_cw <- ic.fun(numDisVars, rand.df2)
rand.df2$resolve_cw <- ic.fun(resolveVars, rand.df2)
rand.df2$disActor_cw <- ic.fun(disActorVars, rand.df2)
rand.df2$vio_cw <- ic.fun(vioVars, rand.df2)
rand.df2$vioExp_cw <- ic.fun(vioExpVars, rand.df2)

# Now scale as 0-1 so that we can easily discuss them as % increase/decrease for MC report. # not necessary until aggregated.
#icVars <- names(rand.df1)[grepl("_cw", names(rand.df1))]
#rand.df1[,icVars] <- reshape::rescaler(rand.df1[,icVars],type="range")
#rand.df2[,icVars] <- reshape::rescaler(rand.df2[,icVars],type="range")

# rebind
rand.df <- rbind(rand.df1, rand.df2)
```



```{r, eval=F}
# if want IC weights calculated with baseline and endline data together, do this without splitting df.
ic.fun <- function(vars)
{
  x <- rand.df[,vars]
  x <- zoo::na.aggregate(x)
  out_cw <- icwIndex(x)
  print(cor(x))
  print(out_cw$weights)
  return(as.vector(out_cw$index))
}


# should loop but feeling braindead
rand.df$x_cw <- ic.fun(xVars)
rand.df$out_cw <- ic.fun(outVars)
rand.df$clash_cw <- ic.fun(clashVars[c(1,2,4)])
rand.df$contact_cw <- ic.fun(contactVars)
rand.df$contactOnly_cw <- ic.fun(contactVars[c(1:4,7)])
rand.df$bene_cw <- ic.fun(beneVarsPerc)
rand.df$threatIn_cw <- ic.fun(threatInVars)
rand.df$threat_cw <- ic.fun(threatVars)
rand.df$in_cw <- ic.fun(inVars)
rand.df$cohes_cw <- ic.fun(cohesVars)
rand.df$cohes1_cw <- ic.fun(cohesVars1)
rand.df$cohes2_cw <- ic.fun(cohesVars2)
rand.df$dis_cw <- ic.fun(disVars)
rand.df$share_cw <- ic.fun(shareVars)
rand.df$numDis_cw <- ic.fun(numDisVars)
rand.df$resolve_cw <- ic.fun(resolveVars)
rand.df$disActor_cw <- ic.fun(disActorVars)
rand.df$vio_cw <- ic.fun(vioVars)
rand.df$vioExp_cw <- ic.fun(vioExpVars)

# cor(na.omit(rand.df[,c("resolve_cw", "resolve_index")])) # 0.84 correlated.
```

### Factors

chris: not yet done.

```{r, eval=F}
lambda <- fact(x,method="iter",maxfactors=1, niter=130)$loadings
sigma <- cor(x)
# This Thompson's method.
z.fac <- matStand(x)%*%solve(sigma)%*%lambda
```


# Rand Experiment

Needs to be done before aggregating.  Done in e-makeIndices_ap.Rmd file.












# Covariance Adjustment - Individuals

Note: this whole section is eval=F since I am not sure this makes any sense.  Especially using the residual of treatment as a predictor, once it is aggregated.  More likely to use this at the community-level.  **Skip to "# Aggregate"**

<!--*Chris question: should this be pooled so these covariates have the same prediction at baseline/endline, or should this be separate?  Separate = gender's effect on outgroup attitudes could be different at baseline and endline.  Separate kind of seems more logical, but I think I need to pool so that I still just have two treatment indicators?  

"Treatment" will no longer be a 0-1 at the community level.  And it will be different at baseline and endline?  How will I make diff-in-diff outcomes?  I....don't know.

Predict an individual's score at baseline/endline based on other variables.  If had same people in a panel, would be idea to predict the _change_ from baseline to endline, but don't have same people.-->

Make new vars that are "[var]_adj" for all outcome variables and for the treatment variable.

```{r, eval=F}
covars <- c('age', 'ethnic2', 'radio',
            'gender', 'income_month',
            'username', 'duration',
            "state"
            )
rand.df$age <- as.numeric(as.character(rand.df$age))

############################
# BASELINE
###########################
base.df <- rand.df[rand.df$survey %in% 0,]

#tr resid
tr_fmla<-reformulate(covars, response='treatment')
tr.lm <- lm(tr_fmla,base.df) # with other controls

lm.tr_resid<-resid(tr.lm)
base.df[names(lm.tr_resid),"tr_resid"]<-lm.tr_resid
stopifnot(base.df[8,"tr_resid"]==lm.tr_resid[8])

##########################
# ENDLINE
#########################
end.df <- rand.df[rand.df$survey %in% 1,]

#tr resid
tr.lm <- lm(tr_fmla,end.df) # with other controls

lm.tr_resid<-resid(tr.lm)
end.df[names(lm.tr_resid),"tr_resid"]<-lm.tr_resid
stopifnot(end.df[8,"tr_resid"]==lm.tr_resid[8])

#function to resid the other vars.
#####################################################
adj.fun <- function(var, df)
{
  the_fmla <- reformulate (covars, response=var)
  the_lm <- lm(the_fmla, df)
  the_resids <- resid(the_lm)
  df[names(the_resids), paste0(var,"_resid")] <- the_resids
  test <- df[!is.na(df[paste0(var,"_resid")]),]
  stopifnot(test[1,paste0(var,"_resid")]==the_resids[1])
  
  return(df[,paste0(var,"_resid")])
}

```

Test function.

```{r, eval=F}
# baseline
base.df$out_index_resid <- adj.fun("out_index", base.df)

#
new_fmla<-reformulate(c("treatment", covars), response='out_index')
(lm.test1 <- lm_robust(new_fmla, data=base.df, clusters=community))
test1 <- lm.test1$coefficients['treatment']

(lm.test2 <- lm_robust(out_index_resid~tr_resid, data=base.df, clusters=community))
test2 <- lm.test2$coefficients['tr_resid']
stopifnot(round(test1,8)==round(test2,8)) # diff because of dropping people?


# endline
end.df$x_index_resid <- adj.fun("x_index", end.df)

#
new_fmla<-reformulate(c("treatment", covars), response='x_index')
(lm.test1 <- lm_robust(new_fmla, data=end.df, clusters=community))
test1 <- lm.test1$coefficients['treatment']

(lm.test2 <- lm_robust(x_index_resid~tr_resid, data=end.df, clusters=community))
test2 <- lm.test2$coefficients['tr_resid']
stopifnot(round(test1,8)==round(test2,8))

```

Use function to make _resid versions of all vars.

Baseline.

```{r, eval=F}
outcomes <- c(names(base.df)[grepl("index$", names(base.df))], "bene_index_perc"#,
              #'pgp_amount', 'pgp_donate', 'pgp_meanDist'
              )
# outcome resids...sapply not working
#panel.df[,paste0(outcomes, "_resid")] <- sapply(panel.df[,outcomes], adj.fun)

base.df[,paste0(outcomes, "_resid")] <- NA
for(i in 1:ncol(base.df[,paste0(outcomes, "_resid")]))
{
  base.df[,paste0(outcomes, "_resid")[i]] <- adj.fun(paste0(outcomes)[i], base.df)
}

# test
# as controls
new_fmla <- reformulate(c('treatment', covars), response="out_index")
lm.con <- lm_robust(new_fmla, data=base.df, clusters=community)
test1 <- lm.con$coefficients['treatment']

#covar adjusted
(lm.adj <- lm_robust(out_index_resid~tr_resid, data=base.df, clusters=community))
test2 <- lm.adj$coefficients['tr_resid']
stopifnot(round(test1,8)==round(test2,8)) # R's weird rounding


```

Endline

```{r, eval=F}
outcomes <- c(names(end.df)[grepl("index$", names(end.df))], "bene_index_perc",
              'pgp_amount', 'pgp_donate', 'pgp_meanDist'
              )
# outcome resids...sapply not working
#panel.df[,paste0(outcomes, "_resid")] <- sapply(panel.df[,outcomes], adj.fun)

end.df[,paste0(outcomes, "_resid")] <- NA
for(i in 1:ncol(end.df[,paste0(outcomes, "_resid")]))
{
  end.df[,paste0(outcomes, "_resid")[i]] <- adj.fun(paste0(outcomes)[i], end.df)
}

# test
# as controls
new_fmla <- reformulate(c('treatment', covars), response="out_index")
lm.con <- lm_robust(new_fmla, data=end.df, clusters=community)
test1 <- lm.con$coefficients['treatment']

#covar adjusted
(lm.adj <- lm_robust(out_index_resid~tr_resid, data=end.df, clusters=community))
test2 <- lm.adj$coefficients['tr_resid']
stopifnot(round(test1,8)==round(test2,8)) # R's weird rounding


```

Recombine base.df and end.df

```{r, eval=F}
base.df[,setdiff(names(end.df), names(base.df))] <- NA

rand.df <- rbind(base.df, end.df)
```




















# Aggregate

Now aggregate to community-year level

```{r}
# stuff from above that needs to be run becaeuse above is now eval=F
covars <- c('age', 'ethnic2', 'radio',
            'gender', 'income_month',
            'username', 'duration',
            "state"
            )
rand.df$age <- as.numeric(as.character(rand.df$age))


# fix/make numeric variables
rand.df$ethnic2 <- as.factor(rand.df$ethnic2)
rand.df <- cbind(rand.df,model.matrix(~ . + 0, data=rand.df['ethnic2'], contrasts.arg = lapply(rand.df['ethnic2'], contrasts, contrasts=FALSE))) #
rand.df$psu <- as.numeric(as.character(rand.df$psu)) #for aggregation we want psu as a number
rand.df$female <- ifelse(rand.df$gender %in% "female", 1, 0)
covars <- c(covars[!covars %in% c("ethnic2", "username", "gender", "state")], "female")

# aggregate vars
listVars <- ls(pattern="Vars") # there is a way to do this just from this list of values, but idk how offhand.
expVars <- names(rand.df)[grepl("^(...|....)_(exp[0-9])|^rand_", names(rand.df))]
pgpVars <- names(rand.df)[grepl("pgp", names(rand.df))]
ag.vars <- c(names(rand.df)[grepl("index", names(rand.df))], 
             names(rand.df)[grepl("cw", names(rand.df))], 
             beneVars, clashVars, 
             cohesVars, contactVars, disVars, outVars, threatInVars, vioVars,
             expVars, pgpVars,
             'treatment', 'community', 'survey', "psu", #"tr_resid",
             covars, 
             names(rand.df)[grepl("ethnic2[a-z]", names(rand.df))])

ag1 <- aggregate(rand.df[rand.df$survey %in% 0,ag.vars], by=list(comm=rand.df[rand.df$survey %in% 0,ag.vars]$community), mean,na.rm=T)
ag2 <- aggregate(rand.df[rand.df$survey %in% 1,ag.vars], by=list(comm=rand.df[rand.df$survey %in% 1,ag.vars]$community), mean,na.rm=T)
# warnings because "community" is factor and cannot be aggregated by itself...

stopifnot(names(ag1)==names(ag2))
names(ag1) <- paste0(names(ag1),"_base")
names(ag2) <- paste0(names(ag2),"_end")
```

Merge to one big dataset.  Now have two versions of every variable: the baseline version, and the "_end" version for endline

```{r}
ag2[, c('treatment_end','psu_end', "comm_end")] <- NULL # remove things from ag2 that are also in ag1 so no useless duplicates
ag.df<-as.data.frame(cbind(ag1,ag2))
ag.df$state <- rand.df$state[match(ag.df$comm_base,rand.df$community)]
ag.df$clash_index_end[is.na(ag.df$clash_in)] # if there is an NA in clash_index (no one even knew about conflict), make it 0
stopifnot(mean(ag.df$clash_index_base)==mean(ag1$clash_index_base, na.rm=T))
stopifnot(mean(ag.df$clash_index_end)==mean(ag2$clash_index_end, na.rm=T))
names(ag.df)[names(ag.df) %in% c("comm_base", "treatment_base", "psu_base")] <- c("comm", "treatment","psu" )
ag.df[,grepl("(survey|community)", names(ag.df))] <- NULL
rm(ag1); rm(ag2)
```


# Now scale as 0-1 so that we can easily discuss them as % increase/decrease for MC report.

Did this for individuals before aggregate, also doing it now for communities.  Before the DiD outcomes created, because we want the DiD outcome to be the change on a 0-1 scale. I f we did it after DiD outcomes created, the _change_ itself would be on the 0-1 scale.  And the scales would not be comparable.



```{r}
## re-scale before DiD outcome.  It puts both baseline and endline on 0-1, then asks about movement on that 0-1.  Otherwise, max score at baseline/endline would look like a big change when they are supposed to be the same thing.
icVars <- names(ag.df)[grepl("_cw", names(ag.df))]

ag.df[,icVars] <- reshape::rescaler(ag.df[,icVars],type="range")
ag.df[,icVars] <- reshape::rescaler(ag.df[,icVars],type="range")
```



# Make the DiD outcomes.

First need to make list & end exp vars that are tr-co for baseline and tr-co for endline.  

Rand exp is not a "tr vs co".  Have to use lm(randOutcome ~ randCondition) at baseline and endline for each community. High values good. Done earlier.  Now can be treated like a typical aggregate variable.

```{r}
# list exp
ag.df$list_exp_base <- ag.df$list_exp1b_base - ag.df$list_exp1a_base
ag.df$list_exp_end <- ag.df$list_exp1b_end - ag.df$list_exp1a_end
ag.df[,names(ag.df)[grepl("list_exp1(a|b)", names(ag.df))]] <- NULL

# end_exp: 1a goes to pastoralists, 1b goes to farmer's, 1c is generic.
ag.df$end_expTR_end <- ifelse(is.na(ag.df$end_exp1a_end), ag.df$end_exp1b_end, ag.df$end_exp1a_end)
ag.df$end_expTR_base <- ifelse(is.na(ag.df$end_exp1a_base), ag.df$end_exp1b_base, ag.df$end_exp1a_base)

ag.df$end_exp_end <- ag.df$end_expTR_end - ag.df$end_exp1c_end
ag.df$end_exp_base <- ag.df$end_expTR_base - ag.df$end_exp1c_base

#ag.df[,c("comm",names(ag.df)[grepl("end_exp", names(ag.df))])]
ag.df[,names(ag.df)[grepl("end_exp1(a|b)", names(ag.df))]] <- NULL 

```

Make DiD outcomes that are "[var]_end" - "[var]_base".

```{r}
ag.df[,sub("_end$", "", names(ag.df)[grepl("_end$",names(ag.df))])] <- ag.df[,grepl("_end", names(ag.df))] - ag.df[,grepl("_base", names(ag.df))]

# test that worked right
ag.df$test <- ag.df$cohes_index_end - ag.df$cohes_index_base
stopifnot(ag.df$test==ag.df$cohes_index)
ag.df$test <- ag.df$list_exp_end - ag.df$list_exp_base
stopifnot(ag.df$test==ag.df$list_exp)
ag.df$test <- NULL

# pgp is only at endline, so remove pgp base vars
ag.df[,names(ag.df)[grepl("(pgp_.*_base|pgp_[[:alpha:]]*$)", names(ag.df))]] <- NULL 

```


# Covariance Adjustment - Community Level

Set the variables. Chris: Need to do a lasso.  Currently this just uses all of the variables that could be covars.

Also: add the survey experiments!

```{r}
outcomes <- c(names(ag.df)[grepl("index$", names(ag.df))], names(ag.df)[grepl("cw$", names(ag.df))],
              "bene_index_perc", 'cohes_index1', 'cohes_index2',
              'pgp_amount_end', 'pgp_donate_end', 'pgp_meanDist_end'
              )

# add state and ethnic2 back into covars
covars <- c(covars, names(ag.df)[grepl("ethnic2.*end$", names(ag.df))], "state")

```

Do lasso to determine covars that should be used.

```{r, eval=F}
# chris: not done

# lasso

# assign covars
covars
```

Now Rosenbaum residual so I can use the "controlled for" outcome in NPC.

```{r}
#tr resid
tr_fmla<-reformulate(covars, response='treatment')
tr.lm <- lm(tr_fmla,ag.df) # with other controls

lm.tr_resid<-resid(tr.lm)
ag.df[names(lm.tr_resid),"tr_resid"]<-lm.tr_resid
stopifnot(ag.df[8,"tr_resid"]==lm.tr_resid["8"])

#function to resid the other vars.
#####################################################
adj.fun <- function(var)
{
  the_fmla <- reformulate (covars, response=var)
  the_lm <- lm(the_fmla, ag.df)
  the_resids <- resid(the_lm)
  ag.df[names(the_resids), paste0(var,"_resid")] <- the_resids
  test <- ag.df[!is.na(ag.df[paste0(var,"_resid")]),]
  stopifnot(test[8,paste0(var,"_resid")]==the_resids[8])
  
  return(ag.df[,paste0(var,"_resid")])
}


```

Test function.

```{r, eval=F}
ag.df$test <- adj.fun("x_index")

#
new_fmla<-reformulate(c("treatment", covars), response='x_index')
(lm.test1 <- lm_robust(new_fmla, data=ag.df, clusters=psu))
test1 <- lm.test1$coefficients['treatment']

(lm.test2 <- lm_robust(test~tr_resid, data=ag.df, clusters=psu))
test2 <- lm.test2$coefficients['tr_resid']
stopifnot(round(test1,8)==round(test2,8))

```

Use function to make _resid versions of all vars.

```{r}
# outcome resids...sapply not working
#ag.df[,paste0(outcomes, "_resid")] <- sapply(ag.df[,outcomes], adj.fun)

ag.df[,paste0(outcomes, "_resid")] <- NA
for(i in 1:ncol(ag.df[,paste0(outcomes, "_resid")]))
{
  ag.df[,paste0(outcomes, "_resid")[i]] <- adj.fun(paste0(outcomes)[i])
}

# test
# as controls
new_fmla <- reformulate(c('treatment', covars), response="out_index")
lm.con <- lm_robust(new_fmla, data=ag.df, clusters=psu)
test1 <- lm.con$coefficients['treatment']

#covar adjusted
lm.adj <- lm_robust(out_index_resid~tr_resid, data=ag.df, clusters=psu)
test2 <- lm.adj$coefficients['tr_resid']
stopifnot(round(test1,8)==round(test2,8)) # R's weird rounding

```

### Make Rosenbaum Residual of "Controlling-For" analysis method (no covariates except baseline outcome)

Chris: this will not work with NPC because each residualized outcome needs it's own treatment indicator (tr_resid).  In analysis file, will need to make RosenbaumResiduals for each outcome and then write my own test for how often my observed distribution of p-values are lower than randomization distribution of p-values.  

How to link the p-values I get from the many hypothesis tests: additive/mean seems bad, punishes evidence against one bad outcome.  Caughey et al recommend "product function
(also known as Fisher’s chi-square combination)."

```{r, eval=F}


```

Test function.

```{r, eval=F}

```

Use function to make _resid versions of all vars.

```{r, eval=F}

```


*****




# Added Later - the Randomization Experiment pt2

Instead of asking "did the relationship between % outgroup and saying yes change from baseline to endline?" Let's ask "Did more people say yes in the treatment group than the control group?"  The reason for this: in Treatment, "yes" was higher for every % outgroup, which means the Relationship between X & Y did not change, but looks like a treatment effect.  Just doesn't work because the 5% outgroup condition is supposed to be a calibrate/everyone says yes condition, but it didn't work.

The code below: first I aggregated to community-condition level with outcomes that tell us (1) % who say yes in each condition at BASELINE and (2) the % who says yes in each condition at ENDLINE.  But then I realized I needed this at the community-level, so aggregated it to the community-level so it could merge with ag.df.  The two are mathematically equivalent.

```{r, include=F}
# aggregate to treatment/condition level, outcomes are (1) % who say yes in each condition at BASELINE and (2) the % who says yes in each condition at ENDLINE.
table(rand.df$rand_condition, exclude=c())
rand.df <- rand.df[!is.na(rand.df$rand_condition),]

new.df <- rand.df %>%
  select(treatment,survey, community, rand_outcome, rand_condition, state, psu) %>%
  dplyr::group_by(community, treatment, rand_condition, state, psu) %>%
  dplyr::summarise(randOut_end=mean(rand_outcome[survey %in% 1], na.rm=T), 
                   randOut_base=mean(rand_outcome[survey %in% 0]),
                   randOut=randOut_end-randOut_base) %>%
  as.data.frame()

#summary(lm(randOut~treatment+factor(rand_condition)+state, new.df))
# looks right, now to make it a randomization test

#####
# But how to do this in a way that lets me easily test it with NPC?  Not possible now, diff datasets.  Maybe if we collapse this into a comm-level with columns for: (1) increase at 5%, (2) increase at 25%, (3) increase at 50%, (4) increase at 75%, and (5) average increase.  Can then merge/cbind with ag.df.  Will be functionally identical to above, but at ag.df level!
####
merge.df <- new.df %>% dplyr::group_by(community) %>%
  summarise(r5=randOut[rand_condition %in% 5],
            r25=randOut[rand_condition %in% 25],
            r50=randOut[rand_condition %in% 50],
            r75=randOut[rand_condition %in% 75],
            r5_base=randOut_base[rand_condition %in% 5],
            r25_base=randOut_base[rand_condition %in% 25],
            r50_base=randOut_base[rand_condition %in% 50],
            r75_base=randOut_base[rand_condition %in% 75],
            r5_end=randOut_end[rand_condition %in% 5],
            r25_end=randOut_end[rand_condition %in% 25],
            r50_end=randOut_end[rand_condition %in% 50],
            r75_end=randOut_end[rand_condition %in% 75]
            ) %>%
  as.data.frame()
merge.df$rMean <- rowMeans(merge.df[c('r5','r25','r50','r75')])
merge.df$rMean_base <- rowMeans(merge.df[c('r5_base','r25_base','r50_base','r75_base')])
merge.df$rMean_end <- rowMeans(merge.df[c('r5_end','r25_end','r50_end','r75_end')])

ag.df <- merge(ag.df, merge.df, all=T, by.x="comm", by.y="community")
rm(new.df)
rm(merge.df)
```


# Moved here later - reversing Indices where LOW is good

Was previously doing this in the analysis file and in the plot files, but is just better to do it here.  High is now GOOD for all variables.

```{r}
ag.df$psu <- as.factor(as.character(ag.df$psu))

# need to reverse some cols so that HIGH is GOOD for all variables.  For these variables right now, HIGH is BAD.  This makes HIGH GOOD.
revCols <- c("clash_index", "threatIn_index", "threat_index",
             "clash_index_resid", "threatIn_index_resid", "threat_index_resid",
             "clash_cw", "clash_cw_base", "clash_cw_end",
             "threatIn_cw", "threat_cw", 
             "clash_cw_resid", "threatIn_cw_resid", "threat_cw_resid", 
             "list_exp", "list_exp_base", "list_exp_end")
ag.df[,revCols] <- ag.df[,revCols]*-1

```


# ADDED LATER - all_index with Inverse Covariance Weighting

What if we combined all the outcomes in ag.df using inverse covariance weighting?  Does that make sense?

Slightly difference than NPC.  NPC does not weight them, though it will account for their interdependence because really correlated things will be correlated in the null distribution, making extreme values on both less rare than if they were independent.

Not sure how NPC and icw results should be interpreted differently...they should really tell the same story.

Chris: Not sure this is right.

```{r}
allIndices <- c("x_cw", "cohes_cw", "pgp_amount_end",
                "pgp_donate_end", "contactOnly_cw", "in_cw",
                "resolve_cw", "list_exp", "rMean", "end_exp")
# chris: if we are comfortable, could replace rand_lm with rMean, the diff outcome of the rando_exp.  Or add it.

ag.df$control <- ifelse(ag.df$treatment == 1, 0, 1)
ic2.fun <- function(vars)
{
  x <- ag.df[,vars]
  x <- zoo::na.aggregate(x)
  out_cw <- icwIndex(xmat=x, sgroup=as.logical(ag.df$control))
  print(cor(x))
  print(out_cw$weights)
  return(as.vector(out_cw$index))
}

baseIndices <- c(paste0(allIndices[grepl("cw", allIndices)], "_base"), allIndices[!grepl("cw", allIndices)])
endIndices <- sub("_base", "_end", baseIndices)
ag.df$all_cw_base <- reshape::rescaler(ic2.fun(baseIndices), type="sd")
ag.df$all_cw_end <- reshape::rescaler(ic2.fun(endIndices), type="sd")
ag.df$all_cw <- ag.df$all_cw_end-ag.df$all_cw_base


# no pgg
ag.df$all2_cw <- ic2.fun(allIndices[-c(3,4)])
```


# ADDED LATER - rank-based outcomes

Idea from Ekrem.  Remember to thank him in paper.

```{r}
rankCols <- c(names(ag.df)[grepl("_cw", names(ag.df))], 
              "pgp_amount_end", "pgp_donate_end", 
              'list_exp', 'rMean', 'end_exp') # still more outcomes than I care about, but that's okay

ag.df[,paste0(rankCols, "_rank")] <- sapply(ag.df[,rankCols], rank)

```


# Save

```{r}
save(rand.df, file="rand_df.Rdata")
rm(list=ls(pattern="(rand|base|end|^df|^i$|^lm|lm$|new_fmla|test)"))
save.image(file="f-aggregateData.Rdata")

```




# not included other ideas

chris: not good ideas here that I either didn't implement or started to implement before realizing they make no sense.

What happens if we make community level icw indices?
What happens if we do covariate adjustment at the individual level before aggregating?
Can I somehow make an individual-level index with the xVars and the survey experiments?