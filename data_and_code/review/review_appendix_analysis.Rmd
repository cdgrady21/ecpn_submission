---
title: "Review_appendix"
date: "2023-07-12"
output:
  pdf_document:
    toc: yes
    toc_depth: '2'
  html_document:
    toc: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
rm(list=ls())
# Load data I anticipate needing
load("../survey_dat/c_creating_dataframes/f-aggregateComms_ap.Rdata")
load("../survey_dat/c_creating_dataframes/rand_df.Rdata")
load("../survey_dat/b_creating_outcomes/f2-panelData.Rdata")
load("../obs_dat/b_analysis/eventsMedian.Rdata")
load("../obs_dat/b_analysis/marketMedian.Rdata")

# clean environment
rm(list=ls(pattern="Var|var|.fun|Fun|Col|Index|Indice|Stand|fmla|outcomes"))

# Functions
## True p-value function. 
load("../survey_dat/d_analysis/true_fun.rda")

# make variables
ag.df$farm_past <- ifelse(grepl(".farmers", ag.df$comm), "farm", "past")

# Packages
library(estimatr)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(DescTools)

```

# Review 1

## Comment 1

**Comment**
Third, how can the authors differentiate the impact of intergroup contact from the impact of the development project around which the contact was organized? Treatment communities received large monetary contributions to be used for development projects that could potentially reduce the resource scarcity that is driving conflict (water access points and fencing to protect crops from grazing livestock). Maybe the reported findings have nothing to do with intergroup contact and are instead driven by a reduction in the triggers for conflict. The authors acknowledge this possibility on page 6, but only within the context of trying to understand diffusion mechanisms. While the experiment cannot be rerun, there may be analyses that could help address this (e.g., if the effects are larger in places with greater scarcity, this would suggest that the resource infusion is doing much of the work).

**Response**
Great question. We might be able to answer this that the boreholes were largely constructed at the end of the project, and likely had little impact on water scarcity at the time of the survey. Participants might have had expectations the scarcity would be lifted, and that’s hard to disentangle. Not sure what analysis we could do to disentangle. Maybe the fact that at endline, in Benue, pastoralists would not have benefited from the borehole as they were displaced?

- Few were aware of mediation
- Less likely to have direct short-term effects on attitudes
- Look at people who used the boreholes
- Maybe look at Benue pastoralists: is TR effect smaller there? (issue: low power)


**Code**

Few people participated in negotiations, relatively few were even aware of the ECPN development project or of Mercy Corps.

```{r}
## mediation awareness/participation
table(rand.df$ecpn_group.negotiation, exclude=c())
table(rand.df$heard_MC_group.heard_MC, exclude=c())
table(rand.df$heard_MC_group.part_MC, exclude=c())
```

Bigger effects among people aware/used QIP, people aware/used borehole?  Among TR group, does qip/borehole awareness and use predict improved outcomes?

```{r, echo=F}
# people who aware/used boreholes
table(rand.df$qip_group.borehole_aware, exclude=c())
table(rand.df$qip_group.borehole_use, exclude=c())

############
# must do effect of borehole aware/use among subset of treated comms/ppl bcuz TR and borehole use/aware almost perfectly correlated
#tidy(lm_robust(attitude_cw~qip_group.borehole_use_end,
#                            clusters = psu, data=ag.df[ag.df$treatment %in% 1,]))[, c(1,2,5)]

# graph reveals semi-outliers for some outcomes
# same relationship b/ween borehole use and attitude_change with semi-outliers removed
#ag.df$attitude_cw_test <- DescTools::Winsorize(ag.df$attitude_cw, probs = c(0.05, 0.95))
#lm1 <- lm_robust(attitude_cw_test~qip_group.borehole_use_end,
#                            clusters = psu, data=ag.df[ag.df$treatment %in% 1,])
#tidy(lm1)[, c(1,2,5)]


################################
# make one loop
##############################
#graph fun
qip_graph_fun <- function(ben_var, out_var, title, xlab, ylab, estimate1, intercept1)
{
  ggplot(ag.df[ag.df$treatment %in% 1,], aes(x = ag.df[ag.df$treatment %in% 1,ben_var], 
                                             y = ag.df[ag.df$treatment %in% 1,out_var], 
                                             color = psu)) +
    geom_point() +
    geom_text(aes(label = comm), vjust = -0.5) +
    geom_abline(slope=estimate1,
                intercept=intercept1,
                color="black",
                size=1) +
    theme_bw() +
    ggtitle(title) +
    xlab(xlab) +
    ylab(ylab)
}

# loop over outcome list (from g-aggAnalysis-mainOutcomes.Rmd) and save
outcome_list <- c("attitude", "in", 'contactOnly',
                  'rMean', "end_exp",
                  "pgp_donate_end", "pgp_amount_end")
outcome_list_qip <- c(paste0(outcome_list[1:3], "_cw"), outcome_list[4:length(outcome_list)])

ben_vars <- c("qip_group.borehole_use_end", "qip_group.borehole_aware_end",
              "qip_ben_end", "qip_aware_end")
ben_out_df <- expand.grid(ben_vars = ben_vars,
                    out_vars = outcome_list_qip)

# loop lm and graph fun
qipList <- vector(mode="list", length=nrow(ben_out_df))
names(qipList) <- paste(ben_out_df[,1], "and", ben_out_df[,2])
plot_list <- vector(mode="list", length=nrow(ben_out_df))
names(plot_list) <- paste(ben_out_df[,1], "and", ben_out_df[,2])
for(i in 1:nrow(ben_out_df))
{
  # thelm
  thelm <- lm_robust(ag.df[ag.df$treatment %in% 1,paste(ben_out_df[i,2])]~
                       ag.df[ag.df$treatment %in% 1,paste(ben_out_df[i,1])],
                            clusters = psu, data=ag.df[ag.df$treatment %in% 1,])
  
  # tidy it, grab term, coef, pval
  lm_res <- tidy(thelm)[, c(1,2,5,4)]
  
  # save to list
  qipList[[i]] <- lm_res
  
  # make plot
  theplot <- qip_graph_fun(ben_var = paste(ben_out_df[i,1]),
                           out_var = paste(ben_out_df[i,2]),
                           title=paste(ben_out_df[i,1], "and", ben_out_df[i,2]),
                           xlab=ben_out_df[i,1],
                           ylab=ben_out_df[i,2],
                           estimate1=qipList[[i]][[2,2]],
                           intercept1=qipList[[i]][[1,2]])
  
  # save to list
  plot_list[[i]] <- theplot
}

save(qipList, file="qip_list.Rda")
save(plot_list, file="plot_list.Rda")
# save plot images
for (i in 1:length(plot_list)) {
    file_name = paste0(names(plot_list)[i],".tiff")
    tiff(file_name)
    print(plot_list[[i]])
    dev.off()
}

#############################
# summarize coefs & pvals for each outcome/benefit variable
#############################
all_coefficients <- sapply(qipList, function(x) x$estimate)
all_pvalues <- sapply(qipList, function(x) x$p.value)
all_tstat <- sapply(qipList, function(x) x$statistic)
rownames(all_coefficients) <- c("intercept_coef", "var_coef")
rownames(all_pvalues) <- c("intercept_p", "var_p")
rownames(all_tstat) <- c("intercept_t", "var_t")

# all coefs, pvals, and ts for each outcome across benefit variables
benefit_df <- data.frame(coefs = numeric(0), pvals = numeric(0), tstat = numeric(0))
for(i in 1:length(outcome_list))
{
  benefit_df[i,1] <- mean(all_coefficients["var_coef",colnames(all_coefficients)[grepl(paste(outcome_list[i]), colnames(all_coefficients))]])
  benefit_df[i,2] <- mean(all_pvalues["var_p",colnames(all_pvalues)[grepl(paste(outcome_list[i]), colnames(all_pvalues))]])
  benefit_df[i,3] <- mean(all_tstat["var_t",colnames(all_tstat)[grepl(paste(outcome_list[i]), colnames(all_tstat))]])
}
rownames(benefit_df) <- outcome_list
benefit_df["all",] <- c(NA, mean(all_pvalues["var_p",]), mean(all_tstat["var_t",]))
save(benefit_df, file="benefit_df.Rda")


# all coefs, pvals, and ts for each benefit variable across outcomes
benefitVar_df <- data.frame(coefs = numeric(0), pvals = numeric(0), tstat = numeric(0))
for(i in 1:length(ben_vars))
{
  # coefs don't even really make sense because they're not on same scales
  benefitVar_df[i,1] <- mean(all_coefficients["var_coef",colnames(all_coefficients)[grepl(paste(ben_vars[i]), colnames(all_coefficients))]])
  benefitVar_df[i,2] <- mean(all_pvalues["var_p",colnames(all_pvalues)[grepl(paste(ben_vars[i]), colnames(all_pvalues))]])
   benefitVar_df[i,3] <- mean(all_tstat["var_t",colnames(all_tstat)[grepl(paste(ben_vars[i]), colnames(all_tstat))]])
}
rownames(benefitVar_df) <- ben_vars
benefitVar_df["all",] <- c(NA, mean(all_pvalues["var_p",]), mean(all_tstat["var_t",]))
save(benefitVar_df, file="benefitVar_df.Rda")


# all coefs, pvals, and ts for each benefit variable across outcomes, removing PGG
all_coefficients_svy <- all_coefficients[,!grepl("pgp", colnames(all_coefficients))]
all_pvalues_svy <- all_pvalues[,!grepl("pgp", colnames(all_pvalues))]
all_tstat_svy <- all_tstat[,!grepl("pgp", colnames(all_tstat))]

benefitVar_df_svy <- data.frame(coefs = numeric(0), pvals = numeric(0), tstat = numeric(0))
for(i in 1:length(ben_vars))
{
  # coef, pval, tstat
  benefitVar_df_svy[i,1] <- mean(all_coefficients_svy["var_coef",colnames(all_coefficients_svy)[grepl(paste(ben_vars[i]), colnames(all_coefficients_svy))]])
  benefitVar_df_svy[i,2] <- mean(all_pvalues_svy["var_p",colnames(all_pvalues_svy)[grepl(paste(ben_vars[i]), colnames(all_pvalues_svy))]])
   benefitVar_df_svy[i,3] <- mean(all_tstat_svy["var_t",colnames(all_tstat_svy)[grepl(paste(ben_vars[i]), colnames(all_tstat_svy))]])
}
rownames(benefitVar_df_svy) <- ben_vars
benefitVar_df_svy["all",] <- c(NA, mean(all_pvalues_svy["var_p",]), mean(all_tstat_svy["var_t",]))
save(benefitVar_df_svy, file="benefitVar_df_svy.Rda")
```

Show the analysis

```{r}
# all (hard to determine a trend across so many tests)
print(qipList)

# coefficients for each outcome across "benefit" variables
## no meaningful trend, but most coefficients positive and pvals below 0.50, so somewhat suggestive that benefiting from the project added to improved attitudes though certainly doesn't explain them entirely.
benefit_df

# coefficients for each "benefit variables" across outcomes
## no meaningful trend, but coef/tstat/pval could be affected by PGG being weird negative outcome
benefitVar_df

# coefficients for each "benefit variables" across outcomes, removing PGG
## no clear trend, seems slightly suggestive that benefiting weakly improved outcomes.
benefitVar_df_svy
```

Unecessary Robustness check

```{r}
# obvious: control group is all NA or 0 for borehole use/aware.
table(ag.df$qip_group.borehole_use_end>0, ag.df$treatment, exclude=c())

# robustness checks
## make a version thats all thats all 0 if NA (NA really means they didnt benefit)
ag.df$qip_group.borehole_use_end <- ifelse(is.na(ag.df$qip_group.borehole_use_end), 0, ag.df$qip_group.borehole_use_end)
ag.df$qip_group.borehole_aware_end <- ifelse(is.na(ag.df$qip_group.borehole_aware_end), 0, ag.df$qip_group.borehole_aware_end)
ag.df$qip_ben_end <- ifelse(is.na(ag.df$qip_ben_end), 0, ag.df$qip_ben_end)
ag.df$qip_aware_end <- ifelse(is.na(ag.df$qip_aware_end), 0, ag.df$qip_aware_end)

# run above code with robustness check var, save lists with "_0" at end.
load(file="qip_list_0.Rda")
load(file="plot_list_0.Rda")
load(file="benefit_df.Rda")
load(file="benefitVar_df.Rda")

```

**Benue pastoralists less likely to perceive benefit because (were displaced, not using boreholes). Are effects among Benue pastoralists different than other respondents?**

No patterns.

chris: more here. (did more but could do even more)

```{r}
# make ben past variable
ag.df$ben_past <- ifelse(ag.df$state %in% "ben" & ag.df$farm_past %in% "past", 1, 0)

# Benue pastoralists: are they less aware and do they use/benefit from projects less?
## yes, they are less aware and use the borehole less (mixed on other project, which was done earlier)
lm_robust(qip_group.borehole_use_end~ben_past,
                            clusters = psu, data=ag.df[ag.df$treatment %in% 1,])
lm_robust(qip_group.borehole_aware_end~ben_past,
                            clusters = psu, data=ag.df[ag.df$treatment %in% 1,])
lm_robust(qip_aware_end~ben_past,
                            clusters = psu, data=ag.df[ag.df$treatment %in% 1,])
lm_robust(qip_ben_end~ben_past,
                            clusters = psu, data=ag.df[ag.df$treatment %in% 1,])


# benue pastoralist differences?
## is the TR effect weaker among Benue pastoralists?
## chris: is this reg correct?  Or should it just be all benue pastoralists?  Or should it only be TR Ben pastoralists (rather than TR interaction, seeing if TR effect is weaker among Ben Pastoralists)?
benPastList <- vector(mode="list", length=length(outcome_list_qip))
names(benPastList) <- paste(outcome_list_qip)
for(i in 1:length(outcome_list_qip))
{
  # thelm
  thelm <- lm_robust(ag.df[,outcome_list_qip[i]]~ben_past*treatment,
                     clusters = psu, data=ag.df)
  
  # tidy it, grab term, coef, pval
  lm_res <- tidy(thelm)[, c(1,2,5,4)]
  
  # save to list
  benPastList[[i]] <- lm_res
}

save(benPastList, file="benPast_list.Rda")
```
```{r}
print(benPastList)

benPast_pvalues <- sapply(benPastList, function(x) x$p.value)
benPast_tstat <- sapply(benPastList, function(x) x$statistic)
rownames(benPast_pvalues) <- c("intercept_p", "ben_past_p", "tr_p", "benpast:tr_p")
rownames(benPast_tstat) <- c("intercept_t", "ben_past_t", "tr_t", "benpast:tr_t")

mean(benPast_pvalues['benpast:tr_p',])
mean(benPast_tstat['benpast:tr_t',])
```


## Comment 2

Fourth, I am concerned about the robustness of the findings given the relatively small sample size. In general, the findings were more mixed and more marginal than the paper's abstract and introduction would suggest. The marginality and mixed nature of the results is not surprising given the small sample size (20 communities), which is to be expected for such an intense/expensive intervention implemented in a real conflict setting. I think we can still learn something from the study, but would encourage the authors to address the following:

Were adjustments made for multiple comparisons? The PAP suggests that this would be done, but I do not believe that the manuscript mentions this.

**Response**
Within family FDR (appendix). Footnote with appendix.

```{r}
# from g-aggAnalysis-mainOutcomes.rmd
# comm
load("../survey_dat/d_analysis/list_of_coefs_and_ps.rda")
load("../obs_dat/b_analysis/obsDat_truePs.rda")

## add "base" var to PGG outcomes
newList[[6]]$base <- c(1,rep(0,3))
newList[[7]]$base <- c(1,rep(0,3))

## make list of ps
commListPs <- sapply(newList, function(x) x$truep[x$base %in% 1])
commListPs <- c(commListPs, obsDat_truePs$truep)
names(commListPs) <- c(outcome_list, rownames(obsDat_truePs))

# rebecca
## separate into our hypothesis families
### contact
p.adjust(commListPs[c(3,4,8:10)], method="none")
p.adjust(commListPs[c(3,4,8:10)], method="fdr")
p.adjust(commListPs[c(3,4,8:10)], method="holm")

### insecurity (its own family, could consider it an attitude)
p.adjust(commListPs[c(1,2,5)], method="none")
p.adjust(commListPs[c(1,2,5)], method="fdr")
p.adjust(commListPs[c(1,2,5)], method="holm")

### attitudes
p.adjust(commListPs[c(1,5)], method="none")
p.adjust(commListPs[c(1,5)], method="fdr")
p.adjust(commListPs[c(1,5)], method="holm")

### cooperation
p.adjust(commListPs[c(6,7)], method="none")
p.adjust(commListPs[c(6,7)], method="fdr")
p.adjust(commListPs[c(6,7)], method="holm")

### all
p.adjust(p=commListPs, method = "none")
p.adjust(p=commListPs, method = "fdr")
p.adjust(p=commListPs, method = "holm")
```

Individual-level (only interested in participant-control differences)

```{r}
## ind
load("../survey_dat/d_analysis/list_of_coefs_and_ps_ind.rda")

## add "base" var to PGG outcomes
newList_ind[[4]]$base <- c(rep(1,2),rep(0,6))
newList_ind[[5]]$base <- c(rep(1,2),rep(0,6))

# only interested in participant-control differences
indListPs <- sapply(newList_ind, function(x) x$truep[x$base %in% 1 & grepl("-part", rownames(x))])
names(indListPs) <- c(outcome_list[c(1:3,6:7)])

# not enough outcomes to really have families, but pgg vs not
# atts, insecurity, contact
p.adjust(p=indListPs[1:3], method = "none")
p.adjust(p=indListPs[1:3], method = "fdr")
p.adjust(p=indListPs[1:3], method = "holm")

# pgg
p.adjust(p=indListPs[4:5], method = "none")
p.adjust(p=indListPs[4:5], method = "fdr")
p.adjust(p=indListPs[4:5], method = "holm")

### all
p.adjust(p=indListPs, method = "none")
p.adjust(p=indListPs, method = "fdr")
p.adjust(p=indListPs, method = "holm")

```


## Comment 3

What are the substantive effect sizes and how do they compare to the minimum detectable effect sizes identified in the PAP's power analyses (0.3-0.4 SDs)?

Significant results are as strong or stronger than what is in the PAP
Add power analysis to appendix
Add .5 x-axis marker to community-level graph

**Response**
*Power analysis showed we had ~0.80 power for*:
(1) combined p-value of 0.3 SD for community and 0.20 SD for individual.
(2) separate p-values of ~0.60 SD for community-level analysis
(3) separate p-values of ~0.30-0.40 SD for individual-level analysis (this one done through egap power calc)

We would expect better power for our real analysis because the power analysis doesn't use randomization inference, but similar.

*The effects we find are*:
_Comm-level_
- close to 0.50 SD for survey outcomes attitudes, insecurity, contact
- ~0.20 SD for survey experiments (endorsement, percent exp)
- 1.0 SD for market pastoralists index
- ~0.20 SDs for events outgroup index
_Ind-level_
- Between 0.15 and 0.35 SD for survey outcomes atts, insec, contact. Atts weakest, contact strongest.

```{r}
# my original power analysis was bad. so inefficient and slow, so overcomplicated

# use our strongest outcome, insecurity.
#var=outcome_list_qip[2]; tau=0.2
bigPow.fn <-function(nsims, var=outcome_list_qip[2], tau)
{
  newPow.fn <- function(var, tau)
{
    # 6 TR sites from Nas, 4 from Ben
    newtr_nas <- sample(unique(ag.df$psu[ag.df$state %in% "nas"]), size=6)
    newtr_ben <- sample(unique(ag.df$psu[ag.df$state %in% "ben"]), size=4)
    newtr <- c(as.character(newtr_nas), as.character(newtr_ben))
    df <- ag.df
    df[,"newtr"] <- ifelse(df$psu %in% newtr, 1, 0)
  
  # make endline outcome with TR effect tau
  df[, paste0(var,"_end")] <- (df[,paste0(var,"_end")]-mean(df[,paste0(var,"_end")]))/sd(df[,paste0(var,"_end")])
  #scale(df[,paste0(var,"_end")])
  df[df$newtr %in% 1, paste0(var,"_end")] <- df[df$newtr %in% 1, paste0(var,"_end")]+tau
  
  # for baseline control, also scale
  df[, paste0(var,"_base")] <- (df[,paste0(var,"_base")]-mean(df[,paste0(var,"_base")]))/sd(df[,paste0(var,"_base")])
  
  # lm
  lm1 <- lm_robust(df[,paste0(var,"_end")]~df[,'newtr']+df[,paste0(var,"_base")]+state, 
                   clusters = psu, data=df)
  
  want <- tidy(lm1)[2,5]
  return(want)
  }
  
  check <- do(nsims)*newPow.fn(var=var, tau=tau)
  pval <- mean(check<0.05)
  return(pval)
}
#bigPow.fn(nsims=100, tau=0.7)

```

Run it over taus from 0-1 for one survey outcome.

```{r, eval=F}
possibleTaus <- seq(0,1,0.1)
possibleTaus <- as.data.frame(possibleTaus)
system.time(
for(i in 1:nrow(possibleTaus))
{
  possibleTaus[i, "pow"] <- bigPow.fn(nsims=3000, tau=possibleTaus[i,1])
}
)
possibleTaus

#save
save(possibleTaus, file="new_power.Rdata")
```
```{r}
load("new_power.Rdata")
```


## Comment 4

Figure 2 suggests that the effects in Figure 1 are driven by worsening conditions in control communities rather than improved relations in treatment communities. Given the small number of control communities (5), I worry that the effects could be driven by a particularly bad period in a single control community. Do similar patterns hold for other outcomes?

**Response**
Great point. In general, we do see control communities getting worse across outcomes. But it wasn't driven by a particularly bad period in a single control community.
Add to appendix: graphs with communities disaggregated

**Survey outcomes*

```{r}
# not the case that there is one big drop in control communities
## attitudes
summary(ag.df$attitude_cw[ag.df$treatment %in% 1])
summary(ag.df$attitude_cw[ag.df$treatment %in% 0])
```

\begin{figure}%[\sidecaptionrelwidth][t]
\centering
\includegraphics[width=\linewidth]{../survey_dat/figs/did_plots/attitudeComm.plot_disag.png}
\caption{Each point represents a community. This graph shows (1) that overall changes are not driven by a large change in a single community and (2) that the overall change does not reflect a ceiling or floor effect.}\label{fig:att_comm_dis}
\end{figure}

```{r}
## contact
summary(ag.df$contactOnly_cw[ag.df$treatment %in% 1])
summary(ag.df$contactOnly_cw[ag.df$treatment %in% 0])
```

\begin{figure}%[\sidecaptionrelwidth][t]
\centering
\includegraphics[width=\linewidth]{../survey_dat/figs/did_plots/conComm_plot_disag.png}
\caption{Each point represents a community. This graph shows (1) that overall changes are not driven by a large change in a single community and (2) that the overall change does not reflect a ceiling or floor effect.}\label{fig:con_comm_dis}
\end{figure}

```{r}
## insecurity
summary(ag.df$in_cw[ag.df$treatment %in% 1])
summary(ag.df$in_cw[ag.df$treatment %in% 0])
```

\begin{figure}%[\sidecaptionrelwidth][t]
\centering
\includegraphics[width=\linewidth]{../survey_dat/figs/did_plots/inComm_plot_disag.png}
\caption{Each point represents a community. This graph shows (1) that overall changes are not driven by a large change in a single community and (2) that the overall change does not reflect a ceiling or floor effect.}\label{fig:in_comm_dis}
\end{figure}

### Behavioral outcomes

Skipped summary stats for most of these.

#### Markets: pastoralist index

```{r}
# Events: pastoralists index
summary(events$pastoralists_index_rank[events$treatment %in% 1 &
                                       events$time %in% 0])
summary(events$pastoralists_index_rank[events$treatment %in% 1 &
                                       events$time %in% 1])

summary(events$pastoralists_index_rank[events$treatment %in% 0 &
                                       events$time %in% 0])
summary(events$pastoralists_index_rank[events$treatment %in% 0 &
                                       events$time %in% 1])
```

\begin{figure}%[\sidecaptionrelwidth][t]
\centering
\includegraphics[width=\linewidth]{../obs_dat/b_analysis/market_pasts_siteTime.plot.png}
\caption{Each point represents a site. This graph shows (1) that overall changes are not driven by a large change in a single community and (2) that the overall change does not reflect a ceiling or floor effect.}\label{fig:market_past_siteTime}
\end{figure}

#### Markets: farmers index

\begin{figure}%[\sidecaptionrelwidth][t]
\centering
\includegraphics[width=\linewidth]{../obs_dat/b_analysis/market_farms_siteTime.plot.png}
\caption{Each point represents a site. This graph shows (1) that overall changes are not driven by a large change in a single community and (2) that the overall change does not reflect a ceiling or floor effect.}\label{fig:market_farm_siteTime}
\end{figure}

#### Events: Outgroup index

\begin{figure}%[\sidecaptionrelwidth][t]
\centering
\includegraphics[width=\linewidth]{../obs_dat/b_analysis/events_outgroup_siteTime.plot.png}
\caption{Each point represents a site. This graph shows (1) that overall changes are not driven by a large change in a single community and (2) that the overall change does not reflect a ceiling or floor effect.}\label{fig:events_outgroup_siteTime}
\end{figure}


## Comment 5

Lots of the findings are not statistically significant (e.g., Figure 3 seems to show that none of the effects on non-participants were statistically distinguishable from zero). Sometimes such estimates are treated as null effects and other times as impacts that are not statistically significant. It would be helpful to understand how the authors make such distinctions.

**Response**
Thank you, that is correct that the non-participants were not statistically different from the control group. We need to be consistent with wording.

.1 marginal
.2 a potential trend
/>.2 null

```{r}
# For exact p-values: Appendix B for community-level analysis, Appendix C for individual-level.

```

## Comment 6 (smaller questions)

Finally, a few smaller questions:
• Why are conflict and violence not included as dependent variables? There is an assumption that violence is caused by poor intergroup attitudes, but it is possible that attitudes could be improved without reducing violence. This seems important both theoretically and practically.

**Response**
Good question. We have the footnote about it. It's a good idea but we weren't able to measure that.
We have: violence_effect “In any clash that occurred in the last year, were you or anyone in your family negatively affected by an attack caused by [X group]”


```{r}
#violence_effect
with(rand.df[rand.df$survey %in% 0,], prop.table(table(violence_effect_num, treatment),2))

with(rand.df[rand.df$survey %in% 1,], prop.table(table(violence_effect_num, treatment),2))

# violence work effect
with(rand.df[rand.df$survey %in% 0,], prop.table(table(violence_work_effect, treatment),2))

with(rand.df[rand.df$survey %in% 1,], prop.table(table(violence_work_effect, treatment),2))
```


• Were the enumerators who carried out the market observations aware of a community's treatment status? If such observations were not treatment-blind, should we be concerned about biased reporting of intergroup contact?

**Response**
Lisa’s email .

Method appendix
Unaware of hypotheses
Enumerator differences: take out Israel and Hadiza?

```{r}
### robustness checks without hadiza/israel
load("../obs_dat/b_analysis/obsDat_truePs_rb.rda")
### robustness checks with only hadiza/israel
load("../obs_dat/b_analysis/obsDat_truePs_had.rda")

# without
behObs_enumsCheck <- rbind(mark_pasts, mark_pasts_rb,
                           mark_farms, mark_farms_rb,
                           out_ind, out_ind_rb)
colnames(behObs_enumsCheck) <- c("coefficient", "p-value")
rownames(behObs_enumsCheck) <- c("market-pastoralists_all",
                                 "market-pastoralists_without",
                                 "market-farmers_all",
                                 "market-farmers_without",
                                 "events-outgroup_all",
                                 "events-outgroup_without")
behObs_enumsCheck <- round(behObs_enumsCheck,3)
behObs_enumsCheck_tab <- knitr::kable(behObs_enumsCheck, format="latex")

# only them
behObs_enumsOnly <- rbind(mark_pasts_had, mark_farms_had, out_ind_had)
colnames(behObs_enumsOnly) <- c("coefficient", "p-value")
rownames(behObs_enumsOnly) <- c("market-pastoralists_enum",
                                 "market-farmers_enum",
                                 "events-outgroup_enum")
```

**Chris written description for appendix**: Enumerators (for surveys and for behavioral observation) were not informed of a community's treatment status, but two of the enumerators for behavioral observations were involved in administering the intervention. They also only made observations at treatment sites. If their knowledge of program aims affected their observations (or if their observations became more positive over time for other reasons), our estimates of the treatment effect could be inflated.

We removed observations from these two enumerators as a robustness check.  We also checked their change over time. Coefficients with their data removed are very similar to coefficients with their data included, and $p$-values are higher mainly as a result of fewer observations (and therefore degrees of freedom). Descriptively, the two enumerators involved in administering the intervention observed _less_ interaction in treatment sites over time relative to other enumerators. 

\begin{table}[H]
\begin{center}
\label{tab:behObs_enumsCheck_tab}
\caption{\textbf{Robustness check for behavioral observations} This table shows robustness checks for behavioral observations outcomes. The first column shows coefficients from OLS regression, the second column shows $p$-values. The row names show  outcomes (pastoralists in the market, farmers in the market, and outgroup attending events) and subsets of the data (all data, data without two enumerators, and data from only those two enumerators).}
\smallskip
`r behObs_enumsCheck_tab`
\end{center}
\end{table}


# Review 2

## Comment 1

The baseline for our understanding of pastoralist-farmer relations here refers to conflict. As the authors note circa line 147, relations had involved positive interactions that arose endogenously (see 167-68). The intervention here, as well as some of the drivers of contemporary conflict (ie, climate change) are largely exogenous. This could interfere with certain aspects of the research design, discussed below. But I believe it could be sufficiently, appropriately addressed within the framing of the paper around intergroup theory. For example, Allport was exploring prejudice and misinformed views about outgroups. Farmers and pastoralists have different interests, meaning that the attitudes shaping their interactions are not simply about a lack of information (or experience with) the other. The authors explore this around line 163. The PGG generates a shared interest, and in his regard the failure, or limited evidence of cooperation there, is an important limitation of this study, as the authors concede. I would appreciate a stronger justification, perhaps within the background about Nigeria itself, for how the inorganic and engineered contact does not interfere with the theorized drivers of outcomes. This seems especially important since participants were provided with mediation training; this made me wonder if I am observing effects and positive spillover of mediation training or random social contact that generates "authentic" attitudes and behaviors. Is the contact or the efficacy of the mediation driving change here?

**Response**
Many good points being made here.  We will address each of them. 

Emphasize conditions need to be met. Why intervention was explicitly designed to meet those conditions. Just encountering can have negative effects (Enos)
We can’t disqualify that some of the spillover contact–for example in the markets–did not also contribute to outcomes. But that is part of the hope of contact interventions is that it leads to positive contact outside of the intervention. This is a rare study that we look at both in the intervention and outside (Mousa an exception). 

Mediation being driving, see response above
Lack of information–contact may apply  in both when people have negative attitudes–extensions of contact theory to situations where knowledge may not be an issues but still negative beliefs

So in my rereading of the comment, it seems more about that in addition to lack of knowledge there are differing interests in this situation. So it’s not just about knowledge–there is real resource scarcity. While the resource scarcity is real, a) it’s a common interest to manage it well and b) there is a history of cooperation. 
Maybe Kertzer on contact not improving attitudes if other side wants bad things for you
Maybe other stuff

Maybe concerned with:
- artificiality of intervention?
- real effect caused by random social contact that our intervention generated.  Voluntary contact outside of the program is an intended outcome of the intervention.
- these groups have differing interests, intervention trying to build on common interests. vs most contact interventions: cause of prejudice/conflict lack of knowledge.  Here groups are competing with one another.  Response Empirical question we are answering. beyond minimal groups, unrealistic that groups have no information. contact can do more than knowledge -- can change perceptions about degree to which interests are aligned/misaligned. pettigrew & tropp meta-analysis about more than information.

Possible response solution: note that the reviewer makes good points and this is a complex issue.  Then go over the several things we think reviewer is pointing out, responding to each point.


## Comment 2

With regard to research design, I would appreciate a stronger justification of the site selection. As the authors note, Benue has embraced especially strong policies biased against pastoralists (it was one of the first states to ban "open grazing"). The intervention is therefore correcting for a manufactured imbalance between the groups, in a way: pastoralists likely feel insecure when the state sided with farmers and organized militias on their behalf. This is also a condition that is arguably different from Nasarawa. Perhaps this is adequately captured in the fixed effects models noted in the supplemental info. Secondly, the description of the group identities is standard, characterizing pastoralists as overwhelmingly Fulani and Muslim etc. There might be little reason to question this, but I noticed that individual characteristics are dropped from the survey analysis in the supplemental index...if I am understanding that reference properly.

**Response**
In appendix, add exploratory regression that also uses individual’s demographic characteristics?
table showing demographic characteristics of fulani vs farmers: (1) overall, (2) benue, (3) nasarawa
Potentially add something about site selection or clarify the anti-grazing policies were implemented after site selection. 

```{r}
# table showing demographic characteristics of fulani vs farmers: (1) overall, (2) benue, (3) nasarawa
## make variables
rand.df$survey <- ifelse(rand.df$survey %in% 0, "baseline", "endline")
rand.df$christian <- ifelse(rand.df$religion %in% "christian", 1, 0)
rand.df$muslim <- ifelse(rand.df$religion %in% "muslim", 1, 0)
rand.df$farming <- ifelse(rand.df$occupation %in% c("farm","both"), 1, 0)
rand.df$pastoralism <- ifelse(rand.df$occupation %in% c("pastor","both"), 1, 0)
rand.df$trading <- ifelse(rand.df$occupation %in% "trade", 1, 0)
rand.df$fulani <- rand.df$ethnic2fulani

## List of group variables and summary variables
group_vars <- c("farm_pastor", "state", "survey")
summary_vars <- c("age", "female", "income_month", 
                  "fulani", "christian", "muslim",
                  "farming", "pastoralism", "trading",
                  "radio")

#show: age, gender, income, house_size, ethnic, religion, occupation, radio
# overall
demo_tab_overall <- rand.df %>% dplyr::select(farm_pastor,summary_vars) %>%
  group_by(farm_pastor) %>%
  summarise(across(everything(), mean, na.rm=T))

# by state
demo_tab_state <- rand.df %>% dplyr::select(farm_pastor, state,summary_vars) %>%
  group_by(farm_pastor, state) %>%
  summarise(across(everything(), mean, na.rm=T))

# farm_pastor,state, survey -- too complex
#rand.df %>% dplyr::select(group_vars,summary_vars) %>%
#  group_by(farm_pastor, survey, state) %>%
#  summarise(across(everything(), mean, na.rm=T))

# tables
demo_tab_overall1 <- knitr::kable(demo_tab_overall, format="latex")
demo_tab_state1 <- knitr::kable(demo_tab_state, format="latex")
```

\begin{table}[H]
\begin{center}
\label{tab:demo_tab_overall1}
\caption{\textbf{Farmer and Pastoralist Demographics} This table shows demographic characteristics for farming groups and pastoralist groups}
\smallskip
`r demo_tab_overall1`
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\label{tab:demo_tab_state1}
\caption{\textbf{Farmer and Pastoralist Demographics by State} This table shows demographic characteristics for farming groups and pastoralist groups, separating respondents from Nasarawa and Benue}
\smallskip
`r demo_tab_state1`
\end{center}
\end{table}







# Misc

## Power analysis

Chris: I tried to run a randomization inference power analysis.  It takes too long to run.

But that will probably be conservative because it does not use randomization inference, so here it is with the rand inference function we used for p-values, but with tau added to endline outcomes.
- simulate an effect: 
    - make new treatment variable by shuffling site-level TR within states.
    - SD scale real baseline outcome
    - make new endline outcome by shuffling baseline outcome (within state) & adding tau
- get true p-value
    - get sim_coef from lm(endline_outcome~newtr+baseline_outcome+state)
    - get null distribution
        - make null_tr by shuffling newtr at site-level, within states.
        - do nsims (e.g. 3000) regressions to make null distribution
    - compare sim_coef to null distribution: what % of coefs are bigger?
        - save true p-value: % of larger coefs
- get power: how many true p-vals are below 0.05?
- run true p-val function over several taus

```{r, eval=F}

var=outcome_list_qip[2]; tr="treatment"
big_truePow.fn <-function(nsims, var=outcome_list_qip[2], tau){

truePow.fn <- function(var,tr,nsims=1000, dat=ag.df, tau=0)
{
  #(1) simulate an effect
  
  #make new treatment variable by shuffling site-level TR within states.
  ## real exp had 6 TR sites from Nas, 4 from Ben
  newtr_nas <- sample(unique(dat$psu[dat$state %in% "nas"]), size=6)
  newtr_ben <- sample(unique(dat$psu[dat$state %in% "ben"]), size=4)
  newtr <- c(as.character(newtr_nas), as.character(newtr_ben))
  dat[,"newtr"] <- ifelse(dat$psu %in% newtr, 1, 0)
  
  #SD scale real baseline outcome
  dat[, paste0(var,"_base")] <- (dat[,paste0(var,"_base")]-mean(dat[,paste0(var,"_base")]))/sd(dat[,paste0(var,"_base")])
  
  #make new endline outcome by shuffling baseline outcome (within state) & adding tau
  dat <- dat %>% dplyr::group_by(state) %>%
    mutate(newout = sample(dat[, paste0(var,"_base")], replace=F)) %>%
    as.data.frame(.)
  dat$newout <- dat$newout + tau
  
  #(2) get true p-value
  
  #get sim_coef from lm(endline_outcome~newtr+baseline_outcome+state)
  thelm <- lm(newout~newtr+dat[, paste0(var,"_base")]+state, data=dat)
  thecoef <-coef(thelm)[2]
  
  #(2a) get null distribution
  null_dist = rep(NA,nsims)
  
  #make null_tr by shuffling newtr at site-level, within states.
  for(i in 1:nsims){
    nulltr_nas <- sample(unique(dat$psu[dat$state %in% "nas"]), size=6)
    nulltr_ben <- sample(unique(dat$psu[dat$state %in% "ben"]), size=4)
    nulltr <- c(as.character(nulltr_nas), as.character(nulltr_ben))
    dat[,"nulltr"] <- ifelse(dat$psu %in% nulltr, 1, 0)
    
    #do nsims (e.g. 3000) regressions to make null distribution
    null_lm <- lm(newout~nulltr+dat[, paste0(var,"_base")]+state, data=dat)
    null_dist[i] <- coef(null_lm)[2]
  }
  
  #compare sim_coef to null distribution: what % of coefs are bigger?
  thep <- mean(null_dist<thecoef)
  #true p-value == % of larger coefs
  return(thep)
}

  # get power: how many true p-vals are below 0.05?
  check <- do(nsims)*truePow.fn(var=var, tau=tau)
  pval <- mean(check<0.05)
  return(pval)

}

```

Run over taus. chris: nevermind, this didn't run in 3 hours. Based on how long it takes to run 10 times, if time scales linearly it will run for 166 hours. Non randomization inference power analysis is fine.

```{r, eval=F}
possibleTaus <- seq(0,1,0.1)
possibleTaus <- as.data.frame(possibleTaus)
system.time(
for(i in 1:nrow(possibleTaus))
{
  possibleTaus[i, "pow"] <- big_truePow.fn(nsims=1000, tau=possibleTaus[i,1])
}
)
possibleTaus

#save
save(possibleTaus, file="new_power_truep.Rdata")
```
```{r, eval=F}
load("new_power_truep.Rdata")
```